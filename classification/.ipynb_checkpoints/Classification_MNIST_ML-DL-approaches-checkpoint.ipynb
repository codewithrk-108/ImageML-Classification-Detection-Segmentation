{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.cluster import KMeans\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART I : SIFT-BoVW-SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating seed for reproducibility\n",
    "torch.manual_seed = 16\n",
    "np.random.seed = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfunc(data):\n",
    "    image,label = data[0]\n",
    "    return np.array(image),label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load the MNIST training dataset\n",
    "train_dataset = MNIST(root='./data', train=True, download=True, transform=None)\n",
    "\n",
    "# Download and load the MNIST test dataset\n",
    "test_dataset = MNIST(root='./data', train=False, download=True, transform=None)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False,collate_fn = myfunc)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False , collate_fn = myfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extracts the keypoints and descriptors for each image\n",
    "\"\"\"\n",
    "\n",
    "def SIFT_FEATURE_EXTRACTOR(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "    return keypoints, descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Performs K Means clustering on the features (descriptors)\n",
    "\"\"\"\n",
    "def K_MEANS_CLUSTERING(descriptors, num_clusters):\n",
    "    kmeans = KMeans(n_clusters=num_clusters)\n",
    "    kmeans.fit(descriptors)\n",
    "    return kmeans, kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BoVW(image,clusterCenter, numClusters):\n",
    "    keypoints, descriptors = SIFT_FEATURE_EXTRACTOR(image)\n",
    "    bovw_histogram = np.zeros(num_clusters)\n",
    "\n",
    "    try:\n",
    "        for descriptor in descriptors:\n",
    "            # calculate l1 distance\n",
    "            distances = np.linalg.norm(clusterCenter - descriptor, axis=1)\n",
    "            nearest_vw = np.argmin(distances)\n",
    "            bovw_histogram[nearest_vw] += 1\n",
    "        return bovw_histogram\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extracting features from training images\n",
    "\"\"\"\n",
    "set_of_descriptors = np.array([])\n",
    "for image, label in train_loader:\n",
    "    keypoints, descriptors = SIFT_FEATURE_EXTRACTOR(image)\n",
    "    if descriptors is not None:\n",
    "        try:\n",
    "            set_of_descriptors = np.concatenate([set_of_descriptors,descriptors],axis=0)\n",
    "        except:\n",
    "            set_of_descriptors = descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/rkada/miniconda3/envs/deepfont/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Perform clustering on the set of descriptors\n",
    "\"\"\"\n",
    "num_clusters=50\n",
    "_, cluster_centers = K_MEANS_CLUSTERING(set_of_descriptors, num_clusters = num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_of_histograms = []\n",
    "for image, label in train_dataset:\n",
    "    histogram = BoVW(np.array(image),clusterCenter=cluster_centers,numClusters=num_clusters)\n",
    "    set_of_histograms.append(histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = []\n",
    "set_of_all_good = []\n",
    "for idx,(x,y) in enumerate(train_loader):\n",
    "    if set_of_histograms[idx] is not None:\n",
    "        set_of_all_good.append(set_of_histograms[idx])\n",
    "        y_train.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58623\n",
      "58623\n"
     ]
    }
   ],
   "source": [
    "print(len(set_of_all_good))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_of_all_good = np.array(set_of_all_good)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(58623, 50)\n",
      "(58623,)\n"
     ]
    }
   ],
   "source": [
    "print(set_of_all_good.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;linearsvc&#x27;, LinearSVC(dual=&#x27;auto&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;linearsvc&#x27;, LinearSVC(dual=&#x27;auto&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(dual=&#x27;auto&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('linearsvc', LinearSVC(dual='auto'))])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_ = make_pipeline(StandardScaler(), svm.LinearSVC(dual = 'auto'))\n",
    "svm_.fit(set_of_all_good, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_of_test_histograms = []\n",
    "for (image,label) in test_loader:\n",
    "    histogram = BoVW(image,clusterCenter=cluster_centers,numClusters=num_clusters)\n",
    "    collection_of_test_histograms.append(histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_of_good_test = []\n",
    "y_test = []\n",
    "for idx,(x,y) in enumerate(test_loader):\n",
    "    if collection_of_test_histograms[idx] is not None:\n",
    "        set_of_good_test.append(collection_of_test_histograms[idx])\n",
    "        y_test.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_of_good_test = np.array(set_of_good_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9792, 50)\n",
      "(9792,)\n"
     ]
    }
   ],
   "source": [
    "print(set_of_good_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6584967320261438"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_labels = svm_.predict(set_of_good_test)\n",
    "accuracy_score(y_test, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cluster_list = [1, 2, 5, 10, 20, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Clusters = 1\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/rkada/miniconda3/envs/deepfont/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.1857638888888889\n",
      "Number of Clusters = 2\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/rkada/miniconda3/envs/deepfont/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.21027369281045752\n",
      "Number of Clusters = 5\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/rkada/miniconda3/envs/deepfont/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.32169117647058826\n",
      "Number of Clusters = 10\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/rkada/miniconda3/envs/deepfont/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.39501633986928103\n",
      "Number of Clusters = 20\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/rkada/miniconda3/envs/deepfont/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.505718954248366\n",
      "Number of Clusters = 50\t"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/rkada/miniconda3/envs/deepfont/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6513480392156863\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "list_of_accuracy = []\n",
    "for k in num_cluster_list:\n",
    "    print(f\"Number of Clusters = {k}\", end = '\\t')\n",
    "    \n",
    "    _, cluster_centers = K_MEANS_CLUSTERING(np.array(set_of_descriptors), k)\n",
    "    \n",
    "    svm_train = []\n",
    "    y_train = []\n",
    "    for (images,labels) in train_loader:\n",
    "        histogram = BoVW(images,clusterCenter=cluster_centers,numClusters=k)\n",
    "        if histogram is not None:\n",
    "            y_train.append(labels)\n",
    "            svm_train.append(histogram)\n",
    "\n",
    "    svm_train = np.array(svm_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    svm_ = make_pipeline(StandardScaler(), svm.LinearSVC(dual = 'auto'))\n",
    "    svm_.fit(svm_train, y_train)\n",
    "\n",
    "    # Represent Test images as histograms\n",
    "    svm_test = []\n",
    "    y_test = []\n",
    "    for (images,labels) in test_loader:\n",
    "        histogram = BoVW(images,clusterCenter=cluster_centers,numClusters=k)\n",
    "        if histogram is not None:\n",
    "            y_test.append(labels)\n",
    "            svm_test.append(histogram)\n",
    "\n",
    "    svm_test = np.array(svm_test)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    # Find out the Classification Accuracy of the Model\n",
    "    predicted_labels = svm_.predict(svm_test)\n",
    "    accuracy = accuracy_score(y_test, predicted_labels)\n",
    "\n",
    "    list_of_accuracy.append(accuracy)\n",
    "    print(f\"Accuracy = {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f0e483c2620>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Creating plot for the accuracy vs the number of clusters,\n",
    "The accuracy rate of increase decreases with num clusters, therefore it may achieve max accuracy at some point. \n",
    "(near 50 clusters)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "plt.scatter(num_cluster_list,list_of_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SIFT feature detector and descriptor method can at max give 65-70% accuracy on the MNIST test dataset. The limitations belong to the SVM seperating the many clusters formed by KMEANS. Thus, these traditional ML based methods are unable to capture the minute features as captured by Neural networks. THe Bag of Words method deployed just uses cluster centers as its visual words , also the training uses the  bucket sized histograms for each image, which are basically histograms on the bag of visual words.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/rkada/miniconda3/envs/deepfont/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters : C = 0.25 and Loss Function = squared_hinge Accuracy = 0.6609477124183006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/rkada/miniconda3/envs/deepfont/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/home2/rkada/miniconda3/envs/deepfont/lib/python3.10/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters : C = 0.25 and Loss Function = hinge Accuracy = 0.6019199346405228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/rkada/miniconda3/envs/deepfont/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters : C = 1 and Loss Function = squared_hinge Accuracy = 0.6595179738562091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/rkada/miniconda3/envs/deepfont/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/home2/rkada/miniconda3/envs/deepfont/lib/python3.10/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters : C = 1 and Loss Function = hinge Accuracy = 0.6102941176470589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/rkada/miniconda3/envs/deepfont/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters : C = 1.75 and Loss Function = squared_hinge Accuracy = 0.6446078431372549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/rkada/miniconda3/envs/deepfont/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "/home2/rkada/miniconda3/envs/deepfont/lib/python3.10/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters : C = 1.75 and Loss Function = hinge Accuracy = 0.6067197712418301\n"
     ]
    }
   ],
   "source": [
    "def train_svm(descriptors, k, train_loader, test_loader, c, loss_function):\n",
    "    _, cluster_centers = K_MEANS_CLUSTERING(np.array(descriptors), k)\n",
    "\n",
    "    svm_train = []\n",
    "    y_train = []\n",
    "    for (image,labels) in train_loader:\n",
    "        histogram = BoVW(image,clusterCenter=cluster_centers,numClusters=k)\n",
    "        if histogram is not None:\n",
    "            svm_train.append(histogram)\n",
    "            y_train.append(labels)\n",
    "\n",
    "    svm_train = np.array(svm_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    svm_ = make_pipeline(StandardScaler(), svm.LinearSVC(dual='auto', C=c, loss=loss_function))\n",
    "    svm_.fit(svm_train, y_train)\n",
    "\n",
    "    svm_test = []\n",
    "    y_test = []\n",
    "    for (image,labels) in test_loader:\n",
    "        histogram = BoVW(image,clusterCenter=cluster_centers,numClusters=k)\n",
    "        if histogram is not None:\n",
    "            svm_test.append(histogram)\n",
    "            y_test.append(labels)\n",
    "\n",
    "    svm_test = np.array(svm_test)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    predicted_labels = svm_.predict(svm_test)\n",
    "    accuracy = accuracy_score(y_test, predicted_labels)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "k = 50\n",
    "accuracies = []\n",
    "\n",
    "for c in [0.25,1, 1.75]:\n",
    "    for loss_function in ['squared_hinge', 'hinge']:\n",
    "        accuracy = train_svm(set_of_descriptors, k, train_loader, test_loader,c, loss_function)\n",
    "        print(f\"Hyperparameters : C = {c} and Loss Function = {loss_function} Accuracy = {accuracy}\")\n",
    "        accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the accuracies obtained by varying the Loss Function and Regularisation Parameter are almost the same when the Number of Clusters (k = 50) is held constant. In essence, it shows that the Number of Clusters (k) is the key hyperparameter in this method. As the value of k increases, the capacity of the Linear SVM and K-means Clustering to locate the local regions of distinct features in the images leads to improved classification accuracy. Nevertheless, we observe that in almost all circumstances, the sklearn default implementation of the universal squared_hinge loss function outperforms the hinge loss function. The accuracy obtained from the hinge loss function is approximately 55–60%, whereas the accuracy obtained from the squared_hinge loss function is nearly 65%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART II : CNN AND TRANSFORMERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.optim import Adam,lr_scheduler,SGD\n",
    "import wandb\n",
    "import numpy as np\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "\"\"\"\n",
    "Take batch_size as 500\n",
    "\"\"\"\n",
    "batch_size=500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MNIST('./',train=True,transform = ToTensor() , download=True) \n",
    "test_set = MNIST('./',train=False,transform = ToTensor() , download=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set,batch_size=batch_size,shuffle=True,num_workers=8)\n",
    "test_loader = DataLoader(test_set,batch_size=batch_size,shuffle=True,num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a CNN model class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet,self).__init__()\n",
    "        self.conv_layer_1 = nn.Conv2d(in_channels=1,out_channels=6,kernel_size=(5,5),padding=2)\n",
    "        self.avg_pool_layer = nn.AvgPool2d(kernel_size=(2,2),stride=2) \n",
    "        self.conv_layer_2 = nn.Conv2d(in_channels=6,out_channels=16,kernel_size=(5,5),padding=0)\n",
    "        self.fc1 = nn.Linear(400,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "\n",
    "    def forward(self,input):\n",
    "      \n",
    "        output = torch.sigmoid(self.conv_layer_1(input))\n",
    "        output = self.avg_pool_layer(output)\n",
    "        \n",
    "        output = torch.sigmoid(self.conv_layer_2(output))\n",
    "        output = self.avg_pool_layer(output)\n",
    "        \n",
    "        output = output.view(-1,16*5*5)\n",
    "        output = torch.sigmoid(self.fc1(output))\n",
    "        output = torch.sigmoid(self.fc2(output))\n",
    "        output = self.fc3(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Model Train and Test class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_test:\n",
    "    def __init__(self,model,train_loader,test_loader,project_name=\"nil\",run_name=\"nil\",optimizer=\"Adam-vanilla\",lr=0.001,iswandb=0):\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.iswandb = iswandb\n",
    "        self.run_name = run_name\n",
    "        self.project_name = project_name\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        if optimizer==\"Adam-vanilla\":\n",
    "            self.optimizer = Adam(self.model.parameters(),lr=self.lr)\n",
    "        else:\n",
    "            self.optimizer = SGD(self.model.parameters(),lr=self.lr)\n",
    "        \n",
    "        self.scheduler = lr_scheduler.ReduceLROnPlateau(self.optimizer,mode='min',factor=0.1,patience=3,min_lr=0.0001,verbose=True)\n",
    "    \n",
    "    def train_loop(self):\n",
    "        train_loss = 0\n",
    "        for (images,labels) in self.train_loader:\n",
    "            # zero out the remaining grads\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            output = self.model(images)\n",
    "            loss = self.criterion(output,labels)\n",
    "            #calculate gradients\n",
    "            loss.backward()\n",
    "            for k,v in model.named_parameters():\n",
    "                if v.grad is None:\n",
    "                    print(\"Yes\")\n",
    "            train_loss+=loss.item()\n",
    "            \n",
    "            #update weights\n",
    "            self.optimizer.step()\n",
    "\n",
    "\n",
    "        # avg loss per batch\n",
    "        train_loss = train_loss/len(self.train_loader)\n",
    "        return train_loss\n",
    "\n",
    "    def evaluate(self,data_loader):\n",
    "\n",
    "        accuracy = 0\n",
    "        samples_evaluated = 0\n",
    "        loss = 0\n",
    "        \n",
    "        for (images,labels) in data_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            output = self.model(images)\n",
    "            \n",
    "            l = self.criterion(output,labels)\n",
    "            loss+=l.item()\n",
    "            \n",
    "            predicted_labels = torch.argmax(output,dim=1)\n",
    "            accuracy += torch.sum(predicted_labels==labels)\n",
    "            samples_evaluated+= images.size(0)\n",
    "\n",
    "        # loss averaged over per batch\n",
    "        loss = loss / len(data_loader)\n",
    "        accuracy = accuracy/samples_evaluated\n",
    "        return loss,accuracy\n",
    "\n",
    "    def train(self,num_epochs):\n",
    "        if self.iswandb:\n",
    "            wandb.init(\n",
    "            project=self.project_name,\n",
    "            name=self.run_name,\n",
    "            \n",
    "            config={\n",
    "            \"architecture\": \"LeNet\",\n",
    "            \"dataset\": \"MNIST\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            train_loss = self.train_loop()\n",
    "            _,train_accuracy = self.evaluate(self.train_loader)\n",
    "            print(f\"Epoch {epoch+1} - train_loss : {train_loss} and train_accuracy : {train_accuracy}\")\n",
    "            test_loss, test_accuracy = self.test()\n",
    "\n",
    "            self.scheduler.step(train_loss)\n",
    "            \n",
    "            if self.iswandb:\n",
    "                wandb.log({\"train_loss\":train_loss, \"train_accuracy\" : train_accuracy , \"test_loss\" : test_loss ,\"test_accuracy\" : test_accuracy})\n",
    "        if self.iswandb:\n",
    "            wandb.finish()\n",
    "            \n",
    "            \n",
    "    def test(self):\n",
    "        test_loss,test_accuracy = self.evaluate(self.test_loader)\n",
    "        print(f\"Evaluation : test_loss : {test_loss} and test_accuracy : {test_accuracy}\")\n",
    "        return test_loss,test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnable code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "model = LeNet()\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "train_test_kit = train_test(model = model , train_loader = train_loader, test_loader = test_loader ,project_name=\"CV-assignment-2\",run_name=\"LeNet-1\",lr = 0.001,optimizer=\"Adam-vanilla\",iswandb=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrohan-victorious108\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/rkada/wandb/run-20240307_230648-nhgx3fbm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/nhgx3fbm' target=\"_blank\">LeNet-1</a></strong> to <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/nhgx3fbm' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/nhgx3fbm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - train_loss : 2.3027629633744557 and train_accuracy : 0.1718166619539261\n",
      "Evaluation : test_loss : 2.2934046268463133 and test_accuracy : 0.1678999960422516\n",
      "Epoch 2 - train_loss : 1.6228123957912126 and train_accuracy : 0.7590500116348267\n",
      "Evaluation : test_loss : 0.8720373123884201 and test_accuracy : 0.763700008392334\n",
      "Epoch 3 - train_loss : 0.6494706777234872 and train_accuracy : 0.8628333210945129\n",
      "Evaluation : test_loss : 0.4786845460534096 and test_accuracy : 0.8675000071525574\n",
      "Epoch 4 - train_loss : 0.41775435308615366 and train_accuracy : 0.8990333676338196\n",
      "Evaluation : test_loss : 0.34431324899196625 and test_accuracy : 0.9016000032424927\n",
      "Epoch 5 - train_loss : 0.32145126921435196 and train_accuracy : 0.9139666557312012\n",
      "Evaluation : test_loss : 0.2884376622736454 and test_accuracy : 0.9168999791145325\n",
      "Epoch 6 - train_loss : 0.26751742598911127 and train_accuracy : 0.9281333684921265\n",
      "Evaluation : test_loss : 0.23531895205378534 and test_accuracy : 0.9311999678611755\n",
      "Epoch 7 - train_loss : 0.23154416419565677 and train_accuracy : 0.9373666644096375\n",
      "Evaluation : test_loss : 0.20804821103811263 and test_accuracy : 0.9372999668121338\n",
      "Epoch 8 - train_loss : 0.20338060123225052 and train_accuracy : 0.9429000020027161\n",
      "Evaluation : test_loss : 0.18414791077375411 and test_accuracy : 0.9453999996185303\n",
      "Epoch 9 - train_loss : 0.18087122092644373 and train_accuracy : 0.9492499828338623\n",
      "Evaluation : test_loss : 0.16459087170660497 and test_accuracy : 0.950499951839447\n",
      "Epoch 10 - train_loss : 0.1644103890284896 and train_accuracy : 0.9535166621208191\n",
      "Evaluation : test_loss : 0.14990207515656948 and test_accuracy : 0.9550999999046326\n",
      "Epoch 11 - train_loss : 0.14926049454758564 and train_accuracy : 0.9581000208854675\n",
      "Evaluation : test_loss : 0.13621089942753314 and test_accuracy : 0.9587000012397766\n",
      "Epoch 12 - train_loss : 0.1367032992343108 and train_accuracy : 0.9595666527748108\n",
      "Evaluation : test_loss : 0.1310646403580904 and test_accuracy : 0.9595999717712402\n",
      "Epoch 13 - train_loss : 0.12596569942931335 and train_accuracy : 0.9641000032424927\n",
      "Evaluation : test_loss : 0.11379143036901951 and test_accuracy : 0.9648999571800232\n",
      "Epoch 14 - train_loss : 0.11885495446622371 and train_accuracy : 0.9644333720207214\n",
      "Evaluation : test_loss : 0.11657331101596355 and test_accuracy : 0.9628999829292297\n",
      "Epoch 15 - train_loss : 0.11008631500105064 and train_accuracy : 0.9691500067710876\n",
      "Evaluation : test_loss : 0.10064435862004757 and test_accuracy : 0.9695000052452087\n",
      "Epoch 16 - train_loss : 0.10281936330720783 and train_accuracy : 0.9710167050361633\n",
      "Evaluation : test_loss : 0.09590972159057856 and test_accuracy : 0.9681999683380127\n",
      "Epoch 17 - train_loss : 0.09511483917012811 and train_accuracy : 0.9729000329971313\n",
      "Evaluation : test_loss : 0.09006414748728275 and test_accuracy : 0.9715999960899353\n",
      "Epoch 18 - train_loss : 0.08947933359692493 and train_accuracy : 0.9746333360671997\n",
      "Evaluation : test_loss : 0.08570110742002726 and test_accuracy : 0.9735999703407288\n",
      "Epoch 19 - train_loss : 0.08557214988395571 and train_accuracy : 0.9762833714485168\n",
      "Evaluation : test_loss : 0.08047764375805855 and test_accuracy : 0.9745999574661255\n",
      "Epoch 20 - train_loss : 0.08047584497059385 and train_accuracy : 0.9767667055130005\n",
      "Evaluation : test_loss : 0.07803381402045488 and test_accuracy : 0.9753999710083008\n",
      "Epoch 21 - train_loss : 0.07706038070221742 and train_accuracy : 0.9780666828155518\n",
      "Evaluation : test_loss : 0.07355063054710627 and test_accuracy : 0.976099967956543\n",
      "Epoch 22 - train_loss : 0.0729730110305051 and train_accuracy : 0.9795833230018616\n",
      "Evaluation : test_loss : 0.06807099599391223 and test_accuracy : 0.9785999655723572\n",
      "Epoch 23 - train_loss : 0.06852962085977196 and train_accuracy : 0.9809333682060242\n",
      "Evaluation : test_loss : 0.06591510092839599 and test_accuracy : 0.9802999496459961\n",
      "Epoch 24 - train_loss : 0.06565393876905243 and train_accuracy : 0.9814000129699707\n",
      "Evaluation : test_loss : 0.06544401682913303 and test_accuracy : 0.9794999957084656\n",
      "Epoch 25 - train_loss : 0.06406179613744219 and train_accuracy : 0.982200026512146\n",
      "Evaluation : test_loss : 0.06334164794534444 and test_accuracy : 0.98089998960495\n",
      "Epoch 26 - train_loss : 0.06077303684627016 and train_accuracy : 0.9823499917984009\n",
      "Evaluation : test_loss : 0.06065129917114973 and test_accuracy : 0.9803999662399292\n",
      "Epoch 27 - train_loss : 0.05846428059351941 and train_accuracy : 0.983916699886322\n",
      "Evaluation : test_loss : 0.05857391683384776 and test_accuracy : 0.9817000031471252\n",
      "Epoch 28 - train_loss : 0.056230818511297305 and train_accuracy : 0.9837166666984558\n",
      "Evaluation : test_loss : 0.056525330804288385 and test_accuracy : 0.9822999835014343\n",
      "Epoch 29 - train_loss : 0.0532339499797672 and train_accuracy : 0.9849333167076111\n",
      "Evaluation : test_loss : 0.05575101189315319 and test_accuracy : 0.9824999570846558\n",
      "Epoch 30 - train_loss : 0.05156443826854229 and train_accuracy : 0.9848333597183228\n",
      "Evaluation : test_loss : 0.05522182881832123 and test_accuracy : 0.9828999638557434\n",
      "Epoch 31 - train_loss : 0.04963592677377164 and train_accuracy : 0.986133337020874\n",
      "Evaluation : test_loss : 0.05040288642048836 and test_accuracy : 0.9837999939918518\n",
      "Epoch 32 - train_loss : 0.04812144171446562 and train_accuracy : 0.9855499863624573\n",
      "Evaluation : test_loss : 0.051507731340825556 and test_accuracy : 0.9829999804496765\n",
      "Epoch 33 - train_loss : 0.04570569670759141 and train_accuracy : 0.9867500066757202\n",
      "Evaluation : test_loss : 0.05344105856493116 and test_accuracy : 0.9845999479293823\n",
      "Epoch 34 - train_loss : 0.044981583999469874 and train_accuracy : 0.9858999848365784\n",
      "Evaluation : test_loss : 0.05067910235375166 and test_accuracy : 0.9842999577522278\n",
      "Epoch 35 - train_loss : 0.043232468484590454 and train_accuracy : 0.9884333610534668\n",
      "Evaluation : test_loss : 0.047236031480133535 and test_accuracy : 0.9853999614715576\n",
      "Epoch 36 - train_loss : 0.04209064729511738 and train_accuracy : 0.9891166687011719\n",
      "Evaluation : test_loss : 0.04665283281356096 and test_accuracy : 0.9848999977111816\n",
      "Epoch 37 - train_loss : 0.040351257550840576 and train_accuracy : 0.9875167012214661\n",
      "Evaluation : test_loss : 0.04833680307492614 and test_accuracy : 0.9839999675750732\n",
      "Epoch 38 - train_loss : 0.041189683321863416 and train_accuracy : 0.9888833165168762\n",
      "Evaluation : test_loss : 0.04557780269533396 and test_accuracy : 0.9853000044822693\n",
      "Epoch 39 - train_loss : 0.03842868690844625 and train_accuracy : 0.9881333708763123\n",
      "Evaluation : test_loss : 0.049123301170766354 and test_accuracy : 0.9837999939918518\n",
      "Epoch 40 - train_loss : 0.0367106825656568 and train_accuracy : 0.9890666604042053\n",
      "Evaluation : test_loss : 0.04662434766069055 and test_accuracy : 0.9853000044822693\n",
      "Epoch 41 - train_loss : 0.035649262461811305 and train_accuracy : 0.989633321762085\n",
      "Evaluation : test_loss : 0.04527549054473638 and test_accuracy : 0.9865999817848206\n",
      "Epoch 42 - train_loss : 0.03481089095585048 and train_accuracy : 0.9906833171844482\n",
      "Evaluation : test_loss : 0.04104103101417422 and test_accuracy : 0.986799955368042\n",
      "Epoch 43 - train_loss : 0.03370676067036887 and train_accuracy : 0.9903833270072937\n",
      "Evaluation : test_loss : 0.04184032715857029 and test_accuracy : 0.9860999584197998\n",
      "Epoch 44 - train_loss : 0.03346473423298448 and train_accuracy : 0.9915000200271606\n",
      "Evaluation : test_loss : 0.04141226205974817 and test_accuracy : 0.9864999651908875\n",
      "Epoch 45 - train_loss : 0.03209886736391733 and train_accuracy : 0.9914667010307312\n",
      "Evaluation : test_loss : 0.03907808540388942 and test_accuracy : 0.9876999855041504\n",
      "Epoch 46 - train_loss : 0.031994842124792436 and train_accuracy : 0.9918166995048523\n",
      "Evaluation : test_loss : 0.040997502580285075 and test_accuracy : 0.9865999817848206\n",
      "Epoch 47 - train_loss : 0.030592443076117585 and train_accuracy : 0.9923333525657654\n",
      "Evaluation : test_loss : 0.039851707965135576 and test_accuracy : 0.9872999787330627\n",
      "Epoch 48 - train_loss : 0.028676477544164906 and train_accuracy : 0.9921166896820068\n",
      "Evaluation : test_loss : 0.041306350659579036 and test_accuracy : 0.9866999983787537\n",
      "Epoch 49 - train_loss : 0.027879320934880526 and train_accuracy : 0.9919500350952148\n",
      "Evaluation : test_loss : 0.04136431468650699 and test_accuracy : 0.9872999787330627\n",
      "Epoch 50 - train_loss : 0.02800094790291041 and train_accuracy : 0.9920666813850403\n",
      "Evaluation : test_loss : 0.04018896101042628 and test_accuracy : 0.9861999750137329\n",
      "Epoch 51 - train_loss : 0.02732373958763977 and train_accuracy : 0.9919833540916443\n",
      "Evaluation : test_loss : 0.0398655456956476 and test_accuracy : 0.9868999719619751\n",
      "Epoch 52 - train_loss : 0.02689709059583644 and train_accuracy : 0.9928666949272156\n",
      "Evaluation : test_loss : 0.03981378357857466 and test_accuracy : 0.9870999455451965\n",
      "Epoch 53 - train_loss : 0.024849308476162454 and train_accuracy : 0.9927666783332825\n",
      "Evaluation : test_loss : 0.039843504782766104 and test_accuracy : 0.9869999885559082\n",
      "Epoch 54 - train_loss : 0.02641930878162384 and train_accuracy : 0.9932166934013367\n",
      "Evaluation : test_loss : 0.03788326852954924 and test_accuracy : 0.9873999953269958\n",
      "Epoch 55 - train_loss : 0.023303720847858738 and train_accuracy : 0.9926833510398865\n",
      "Evaluation : test_loss : 0.04086996642872691 and test_accuracy : 0.9876999855041504\n",
      "Epoch 56 - train_loss : 0.024431187325778106 and train_accuracy : 0.9937333464622498\n",
      "Evaluation : test_loss : 0.03947792714461684 and test_accuracy : 0.9875999689102173\n",
      "Epoch 57 - train_loss : 0.02348957455251366 and train_accuracy : 0.9948000311851501\n",
      "Evaluation : test_loss : 0.036148292291909453 and test_accuracy : 0.9873999953269958\n",
      "Epoch 58 - train_loss : 0.021375865555213144 and train_accuracy : 0.9948000311851501\n",
      "Evaluation : test_loss : 0.037107566837221384 and test_accuracy : 0.9876999855041504\n",
      "Epoch 59 - train_loss : 0.02115047649325182 and train_accuracy : 0.9944333434104919\n",
      "Evaluation : test_loss : 0.03673252202570439 and test_accuracy : 0.9878999590873718\n",
      "Epoch 60 - train_loss : 0.02083586739609018 and train_accuracy : 0.994783341884613\n",
      "Evaluation : test_loss : 0.037653506454080346 and test_accuracy : 0.9870999455451965\n",
      "Epoch 61 - train_loss : 0.02065471642029782 and train_accuracy : 0.9943667054176331\n",
      "Evaluation : test_loss : 0.037307795323431495 and test_accuracy : 0.9866999983787537\n",
      "Epoch 62 - train_loss : 0.02004423670005053 and train_accuracy : 0.9948333501815796\n",
      "Evaluation : test_loss : 0.037213162425905465 and test_accuracy : 0.9866999983787537\n",
      "Epoch 63 - train_loss : 0.01964371061961477 and train_accuracy : 0.9959666728973389\n",
      "Evaluation : test_loss : 0.03403573571704328 and test_accuracy : 0.9878000020980835\n",
      "Epoch 64 - train_loss : 0.01841599300969392 and train_accuracy : 0.9955166578292847\n",
      "Evaluation : test_loss : 0.03661964498460293 and test_accuracy : 0.9879999756813049\n",
      "Epoch 65 - train_loss : 0.018396165342225382 and train_accuracy : 0.995116651058197\n",
      "Evaluation : test_loss : 0.037600720720365646 and test_accuracy : 0.9883999824523926\n",
      "Epoch 66 - train_loss : 0.018047574383672327 and train_accuracy : 0.9948999881744385\n",
      "Evaluation : test_loss : 0.037276160810142754 and test_accuracy : 0.988099992275238\n",
      "Epoch 67 - train_loss : 0.018204080561796825 and train_accuracy : 0.9955833554267883\n",
      "Evaluation : test_loss : 0.036096302513033154 and test_accuracy : 0.9884999990463257\n",
      "Epoch 68 - train_loss : 0.016193908033892514 and train_accuracy : 0.9946500062942505\n",
      "Evaluation : test_loss : 0.037869987171143295 and test_accuracy : 0.9886999726295471\n",
      "Epoch 69 - train_loss : 0.01622155578418945 and train_accuracy : 0.9961333274841309\n",
      "Evaluation : test_loss : 0.03640742329880595 and test_accuracy : 0.9873999953269958\n",
      "Epoch 70 - train_loss : 0.015733503395070632 and train_accuracy : 0.9964666962623596\n",
      "Evaluation : test_loss : 0.03580037234351039 and test_accuracy : 0.9882999658584595\n",
      "Epoch 71 - train_loss : 0.01540464513624708 and train_accuracy : 0.99590003490448\n",
      "Evaluation : test_loss : 0.03812346472404897 and test_accuracy : 0.9874999523162842\n",
      "Epoch 72 - train_loss : 0.015180500162144502 and train_accuracy : 0.9960833191871643\n",
      "Evaluation : test_loss : 0.036411962611600755 and test_accuracy : 0.9872999787330627\n",
      "Epoch 73 - train_loss : 0.014941600015542159 and train_accuracy : 0.9964333176612854\n",
      "Evaluation : test_loss : 0.03631567796692252 and test_accuracy : 0.9886999726295471\n",
      "Epoch 74 - train_loss : 0.013871622050646692 and train_accuracy : 0.9957666993141174\n",
      "Evaluation : test_loss : 0.03738239826634526 and test_accuracy : 0.9882999658584595\n",
      "Epoch 75 - train_loss : 0.013854760765874137 and train_accuracy : 0.9968500137329102\n",
      "Evaluation : test_loss : 0.037590708630159494 and test_accuracy : 0.9883999824523926\n",
      "Epoch 76 - train_loss : 0.013238125090720133 and train_accuracy : 0.9970499873161316\n",
      "Evaluation : test_loss : 0.03416773620992899 and test_accuracy : 0.9892999529838562\n",
      "Epoch 77 - train_loss : 0.01274926943782096 and train_accuracy : 0.9971166849136353\n",
      "Evaluation : test_loss : 0.03675433062016964 and test_accuracy : 0.9879999756813049\n",
      "Epoch 78 - train_loss : 0.012476028472883626 and train_accuracy : 0.9962000250816345\n",
      "Evaluation : test_loss : 0.03758139433339238 and test_accuracy : 0.9869999885559082\n",
      "Epoch 79 - train_loss : 0.013223874029548218 and train_accuracy : 0.996916651725769\n",
      "Evaluation : test_loss : 0.03703391877934337 and test_accuracy : 0.9881999492645264\n",
      "Epoch 80 - train_loss : 0.011931087358000999 and train_accuracy : 0.9970000386238098\n",
      "Evaluation : test_loss : 0.03734224126674235 and test_accuracy : 0.9884999990463257\n",
      "Epoch 81 - train_loss : 0.012363543297396973 and train_accuracy : 0.9977333545684814\n",
      "Evaluation : test_loss : 0.03556577581912279 and test_accuracy : 0.9889999628067017\n",
      "Epoch 82 - train_loss : 0.01092919172369875 and train_accuracy : 0.9976500272750854\n",
      "Evaluation : test_loss : 0.03615393890067935 and test_accuracy : 0.9883999824523926\n",
      "Epoch 83 - train_loss : 0.011410592519678176 and train_accuracy : 0.9972666501998901\n",
      "Evaluation : test_loss : 0.03959910226985812 and test_accuracy : 0.9884999990463257\n",
      "Epoch 84 - train_loss : 0.010458169363361473 and train_accuracy : 0.9980666637420654\n",
      "Evaluation : test_loss : 0.036014497047290206 and test_accuracy : 0.988099992275238\n",
      "Epoch 85 - train_loss : 0.009969604607128228 and train_accuracy : 0.9979333281517029\n",
      "Evaluation : test_loss : 0.035572138521820305 and test_accuracy : 0.9891999959945679\n",
      "Epoch 86 - train_loss : 0.010077103987957041 and train_accuracy : 0.9971666932106018\n",
      "Evaluation : test_loss : 0.04004637198522687 and test_accuracy : 0.9876999855041504\n",
      "Epoch 87 - train_loss : 0.010192712357578178 and train_accuracy : 0.9961333274841309\n",
      "Evaluation : test_loss : 0.04342247825115919 and test_accuracy : 0.9878999590873718\n",
      "Epoch 88 - train_loss : 0.010175117969629355 and train_accuracy : 0.9976000189781189\n",
      "Evaluation : test_loss : 0.037391016352921726 and test_accuracy : 0.9886999726295471\n",
      "Epoch 89 - train_loss : 0.0091297717532143 and train_accuracy : 0.998033344745636\n",
      "Evaluation : test_loss : 0.037984178448095915 and test_accuracy : 0.9889999628067017\n",
      "Epoch 90 - train_loss : 0.008762164471166518 and train_accuracy : 0.9973333477973938\n",
      "Evaluation : test_loss : 0.04049883685074747 and test_accuracy : 0.9889999628067017\n",
      "Epoch 91 - train_loss : 0.008687963271707606 and train_accuracy : 0.9985833168029785\n",
      "Evaluation : test_loss : 0.03519355105236173 and test_accuracy : 0.9890999794006348\n",
      "Epoch 92 - train_loss : 0.008734344384477784 and train_accuracy : 0.9987000226974487\n",
      "Evaluation : test_loss : 0.03761438266374171 and test_accuracy : 0.9891999959945679\n",
      "Epoch 93 - train_loss : 0.008252686563840447 and train_accuracy : 0.9991000294685364\n",
      "Evaluation : test_loss : 0.03551894058473408 and test_accuracy : 0.9891999959945679\n",
      "Epoch 94 - train_loss : 0.00769618846825324 and train_accuracy : 0.9984166622161865\n",
      "Evaluation : test_loss : 0.03746292637661099 and test_accuracy : 0.9887999892234802\n",
      "Epoch 95 - train_loss : 0.007320918572562126 and train_accuracy : 0.9983000159263611\n",
      "Evaluation : test_loss : 0.03659919609781355 and test_accuracy : 0.9876999855041504\n",
      "Epoch 96 - train_loss : 0.0073936279901924236 and train_accuracy : 0.9977333545684814\n",
      "Evaluation : test_loss : 0.03880499869119376 and test_accuracy : 0.988099992275238\n",
      "Epoch 97 - train_loss : 0.0072778085411603875 and train_accuracy : 0.9986166954040527\n",
      "Evaluation : test_loss : 0.03654728294350207 and test_accuracy : 0.9894999861717224\n",
      "Epoch 98 - train_loss : 0.00691868885284445 and train_accuracy : 0.9987833499908447\n",
      "Evaluation : test_loss : 0.039008438540622595 and test_accuracy : 0.9886999726295471\n",
      "Epoch 99 - train_loss : 0.006977097855027144 and train_accuracy : 0.9992499947547913\n",
      "Evaluation : test_loss : 0.03594915550202131 and test_accuracy : 0.9893999695777893\n",
      "Epoch 100 - train_loss : 0.005936228184145876 and train_accuracy : 0.9993333220481873\n",
      "Evaluation : test_loss : 0.03703157631680369 and test_accuracy : 0.9892999529838562\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>test_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▇▇█████████████████████████████████████</td></tr><tr><td>train_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.9893</td></tr><tr><td>test_loss</td><td>0.03703</td></tr><tr><td>train_accuracy</td><td>0.99933</td></tr><tr><td>train_loss</td><td>0.00594</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LeNet-1</strong> at: <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/nhgx3fbm' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/nhgx3fbm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240307_230648-nhgx3fbm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_test_kit.train(num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The above is the base model for a LeNet giving 99.93 % train accuracy and 98.93 % as test accuracy in 100 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_choices = [\"Adam-vanilla\",\"SGD-vanilla\"]\n",
    "batch_sizes = [250,500]\n",
    "learning_rate = [0.01,0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/rkada/wandb/run-20240307_231601-plojsngj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/plojsngj' target=\"_blank\">LeNet-1-Adam-vanilla-250-0.01-run</a></strong> to <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/plojsngj' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/plojsngj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - train_loss : 2.304461274544398 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301290434598923 and test_accuracy : 0.11349999904632568\n",
      "Epoch 2 - train_loss : 2.3017318626244863 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3013121485710144 and test_accuracy : 0.11349999904632568\n",
      "Epoch 3 - train_loss : 2.301631819208463 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010940551757812 and test_accuracy : 0.11349999904632568\n",
      "Epoch 4 - train_loss : 2.301687945922216 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3018168568611146 and test_accuracy : 0.11349999904632568\n",
      "Epoch 5 - train_loss : 2.1584844425320626 and train_accuracy : 0.43461668491363525\n",
      "Evaluation : test_loss : 1.4453031480312348 and test_accuracy : 0.42549997568130493\n",
      "Epoch 6 - train_loss : 0.5892591670776407 and train_accuracy : 0.9257833361625671\n",
      "Evaluation : test_loss : 0.24078160300850868 and test_accuracy : 0.9257999658584595\n",
      "Epoch 7 - train_loss : 0.20315160208071273 and train_accuracy : 0.9488333463668823\n",
      "Evaluation : test_loss : 0.16248186454176902 and test_accuracy : 0.9478999972343445\n",
      "Epoch 8 - train_loss : 0.15325469607487321 and train_accuracy : 0.956683337688446\n",
      "Evaluation : test_loss : 0.13773857820779084 and test_accuracy : 0.9576999545097351\n",
      "Epoch 9 - train_loss : 0.13279273660543064 and train_accuracy : 0.9613833427429199\n",
      "Evaluation : test_loss : 0.12794127110391856 and test_accuracy : 0.9575999975204468\n",
      "Epoch 10 - train_loss : 0.11548916059546173 and train_accuracy : 0.9671000242233276\n",
      "Evaluation : test_loss : 0.10642901817336678 and test_accuracy : 0.9642999768257141\n",
      "Epoch 11 - train_loss : 0.10271104084483038 and train_accuracy : 0.9720333218574524\n",
      "Evaluation : test_loss : 0.09426907887682319 and test_accuracy : 0.9697999954223633\n",
      "Epoch 12 - train_loss : 0.09353762222453951 and train_accuracy : 0.972516655921936\n",
      "Evaluation : test_loss : 0.09563469337299466 and test_accuracy : 0.9692999720573425\n",
      "Epoch 13 - train_loss : 0.085434325854294 and train_accuracy : 0.9704499840736389\n",
      "Evaluation : test_loss : 0.10151005517691374 and test_accuracy : 0.9667999744415283\n",
      "Epoch 14 - train_loss : 0.07934891417777787 and train_accuracy : 0.9740000367164612\n",
      "Evaluation : test_loss : 0.08625052329152823 and test_accuracy : 0.9722999930381775\n",
      "Epoch 15 - train_loss : 0.07385019219946116 and train_accuracy : 0.9801333546638489\n",
      "Evaluation : test_loss : 0.07744637171272188 and test_accuracy : 0.9746999740600586\n",
      "Epoch 16 - train_loss : 0.0666829086917763 and train_accuracy : 0.9790000319480896\n",
      "Evaluation : test_loss : 0.08014312386512756 and test_accuracy : 0.9731999635696411\n",
      "Epoch 17 - train_loss : 0.0625943760930871 and train_accuracy : 0.9839000105857849\n",
      "Evaluation : test_loss : 0.0708251487929374 and test_accuracy : 0.9782999753952026\n",
      "Epoch 18 - train_loss : 0.05913161882199347 and train_accuracy : 0.9841333627700806\n",
      "Evaluation : test_loss : 0.07059230878949166 and test_accuracy : 0.9765999913215637\n",
      "Epoch 19 - train_loss : 0.05604380071163177 and train_accuracy : 0.9847333431243896\n",
      "Evaluation : test_loss : 0.0679252496920526 and test_accuracy : 0.9786999821662903\n",
      "Epoch 20 - train_loss : 0.05235841279306139 and train_accuracy : 0.9848166704177856\n",
      "Evaluation : test_loss : 0.07261250894516706 and test_accuracy : 0.9772999882698059\n",
      "Epoch 21 - train_loss : 0.05113094544891889 and train_accuracy : 0.9832833409309387\n",
      "Evaluation : test_loss : 0.0782401988748461 and test_accuracy : 0.9758999943733215\n",
      "Epoch 22 - train_loss : 0.04882363656070084 and train_accuracy : 0.9852333664894104\n",
      "Evaluation : test_loss : 0.07079593767412007 and test_accuracy : 0.9781999588012695\n",
      "Epoch 23 - train_loss : 0.04512175721271584 and train_accuracy : 0.9873999953269958\n",
      "Evaluation : test_loss : 0.07058131259400398 and test_accuracy : 0.9784999489784241\n",
      "Epoch 24 - train_loss : 0.04304053703478227 and train_accuracy : 0.9892666935920715\n",
      "Evaluation : test_loss : 0.06726005338132382 and test_accuracy : 0.9795999526977539\n",
      "Epoch 25 - train_loss : 0.042222908251763634 and train_accuracy : 0.9837333559989929\n",
      "Evaluation : test_loss : 0.08038303921930492 and test_accuracy : 0.9757999777793884\n",
      "Epoch 26 - train_loss : 0.040041804627981036 and train_accuracy : 0.9896500110626221\n",
      "Evaluation : test_loss : 0.0664861193858087 and test_accuracy : 0.9803999662399292\n",
      "Epoch 27 - train_loss : 0.04053026707454895 and train_accuracy : 0.9888666868209839\n",
      "Evaluation : test_loss : 0.07074306472204625 and test_accuracy : 0.9782999753952026\n",
      "Epoch 28 - train_loss : 0.03650813691007594 and train_accuracy : 0.9906666874885559\n",
      "Evaluation : test_loss : 0.06614952818490565 and test_accuracy : 0.9787999987602234\n",
      "Epoch 29 - train_loss : 0.03474711068362619 and train_accuracy : 0.9869666695594788\n",
      "Evaluation : test_loss : 0.07324138940311968 and test_accuracy : 0.9770999550819397\n",
      "Epoch 30 - train_loss : 0.03356994310937201 and train_accuracy : 0.9918833374977112\n",
      "Evaluation : test_loss : 0.0698236943804659 and test_accuracy : 0.9801999926567078\n",
      "Epoch 31 - train_loss : 0.03288443871618559 and train_accuracy : 0.9904167056083679\n",
      "Evaluation : test_loss : 0.0703595511149615 and test_accuracy : 0.9791999459266663\n",
      "Epoch 32 - train_loss : 0.029916100514431793 and train_accuracy : 0.9933833479881287\n",
      "Evaluation : test_loss : 0.06915259179659188 and test_accuracy : 0.979699969291687\n",
      "Epoch 33 - train_loss : 0.028621658905952547 and train_accuracy : 0.9893500208854675\n",
      "Evaluation : test_loss : 0.07500045280903578 and test_accuracy : 0.9769999980926514\n",
      "Epoch 34 - train_loss : 0.029112632947120194 and train_accuracy : 0.9919333457946777\n",
      "Evaluation : test_loss : 0.0694377097999677 and test_accuracy : 0.9776999950408936\n",
      "Epoch 35 - train_loss : 0.028344847252204392 and train_accuracy : 0.9916833639144897\n",
      "Evaluation : test_loss : 0.07302813944406808 and test_accuracy : 0.9795999526977539\n",
      "Epoch 36 - train_loss : 0.027071843407854127 and train_accuracy : 0.9933833479881287\n",
      "Evaluation : test_loss : 0.06839925642125308 and test_accuracy : 0.979699969291687\n",
      "Epoch 37 - train_loss : 0.02519324476015754 and train_accuracy : 0.9925500154495239\n",
      "Evaluation : test_loss : 0.07256571119651198 and test_accuracy : 0.977400004863739\n",
      "Epoch 38 - train_loss : 0.02273616000796513 and train_accuracy : 0.9926833510398865\n",
      "Evaluation : test_loss : 0.07396659728838131 and test_accuracy : 0.9800999760627747\n",
      "Epoch 39 - train_loss : 0.02452372662955895 and train_accuracy : 0.9934499859809875\n",
      "Evaluation : test_loss : 0.07275632407981902 and test_accuracy : 0.9790999889373779\n",
      "Epoch 40 - train_loss : 0.023025695294685043 and train_accuracy : 0.9949666857719421\n",
      "Evaluation : test_loss : 0.06788569604977965 and test_accuracy : 0.98089998960495\n",
      "Epoch 41 - train_loss : 0.022541078887297773 and train_accuracy : 0.9947167038917542\n",
      "Evaluation : test_loss : 0.06859305601101369 and test_accuracy : 0.9789999723434448\n",
      "Epoch 42 - train_loss : 0.020551122911274432 and train_accuracy : 0.992733359336853\n",
      "Evaluation : test_loss : 0.07449896051548421 and test_accuracy : 0.9800999760627747\n",
      "Epoch 43 - train_loss : 0.019976760687616963 and train_accuracy : 0.9952333569526672\n",
      "Evaluation : test_loss : 0.07295070253312588 and test_accuracy : 0.9790999889373779\n",
      "Epoch 44 - train_loss : 0.017833854928418682 and train_accuracy : 0.992650032043457\n",
      "Evaluation : test_loss : 0.08195854453369975 and test_accuracy : 0.977400004863739\n",
      "Epoch 45 - train_loss : 0.01987101790922073 and train_accuracy : 0.9951000213623047\n",
      "Evaluation : test_loss : 0.0744245040928945 and test_accuracy : 0.9789999723434448\n",
      "Epoch 46 - train_loss : 0.02035956860636361 and train_accuracy : 0.9947167038917542\n",
      "Evaluation : test_loss : 0.07571535678580403 and test_accuracy : 0.9795999526977539\n",
      "Epoch 47 - train_loss : 0.01645561587647535 and train_accuracy : 0.9951000213623047\n",
      "Evaluation : test_loss : 0.08111731682438403 and test_accuracy : 0.9779999852180481\n",
      "Epoch 48 - train_loss : 0.014504897339793387 and train_accuracy : 0.9958333373069763\n",
      "Evaluation : test_loss : 0.07705576587468385 and test_accuracy : 0.9795999526977539\n",
      "Epoch 49 - train_loss : 0.015032414111677403 and train_accuracy : 0.994866669178009\n",
      "Evaluation : test_loss : 0.08139402167871594 and test_accuracy : 0.9785999655723572\n",
      "Epoch 50 - train_loss : 0.013551431126203776 and train_accuracy : 0.9972000122070312\n",
      "Evaluation : test_loss : 0.07922319006174802 and test_accuracy : 0.9793999791145325\n",
      "Epoch 51 - train_loss : 0.014712333420902723 and train_accuracy : 0.9953666925430298\n",
      "Evaluation : test_loss : 0.08699899856001139 and test_accuracy : 0.977400004863739\n",
      "Epoch 52 - train_loss : 0.01417090743634617 and train_accuracy : 0.9943000078201294\n",
      "Evaluation : test_loss : 0.09076584549620748 and test_accuracy : 0.9790999889373779\n",
      "Epoch 53 - train_loss : 0.01592815199959053 and train_accuracy : 0.9950166940689087\n",
      "Evaluation : test_loss : 0.08694191481918097 and test_accuracy : 0.976699948310852\n",
      "Epoch 54 - train_loss : 0.014173398340062704 and train_accuracy : 0.9952666759490967\n",
      "Evaluation : test_loss : 0.09048941110959277 and test_accuracy : 0.9781999588012695\n",
      "Epoch 00054: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 55 - train_loss : 0.006707089533544301 and train_accuracy : 0.9990500211715698\n",
      "Evaluation : test_loss : 0.0721667732577771 and test_accuracy : 0.9803999662399292\n",
      "Epoch 56 - train_loss : 0.004878385899792193 and train_accuracy : 0.9992333650588989\n",
      "Evaluation : test_loss : 0.07149515121709556 and test_accuracy : 0.9803999662399292\n",
      "Epoch 57 - train_loss : 0.0044993234076779725 and train_accuracy : 0.9993500113487244\n",
      "Evaluation : test_loss : 0.07136640795506537 and test_accuracy : 0.9813999533653259\n",
      "Epoch 58 - train_loss : 0.004250270853663096 and train_accuracy : 0.9993333220481873\n",
      "Evaluation : test_loss : 0.07160328049212694 and test_accuracy : 0.981499969959259\n",
      "Epoch 59 - train_loss : 0.004112260495700563 and train_accuracy : 0.9993166923522949\n",
      "Evaluation : test_loss : 0.07165746577084064 and test_accuracy : 0.9819999933242798\n",
      "Epoch 60 - train_loss : 0.0040438585019728635 and train_accuracy : 0.9994166493415833\n",
      "Evaluation : test_loss : 0.07214423490222543 and test_accuracy : 0.98089998960495\n",
      "Epoch 61 - train_loss : 0.003813443813608804 and train_accuracy : 0.9994666576385498\n",
      "Evaluation : test_loss : 0.07224677854683251 and test_accuracy : 0.9810999631881714\n",
      "Epoch 62 - train_loss : 0.0037403825862080946 and train_accuracy : 0.9994500279426575\n",
      "Evaluation : test_loss : 0.07208096469985321 and test_accuracy : 0.98089998960495\n",
      "Epoch 63 - train_loss : 0.0036465177986732063 and train_accuracy : 0.9994666576385498\n",
      "Evaluation : test_loss : 0.07178617266472428 and test_accuracy : 0.9821999669075012\n",
      "Epoch 64 - train_loss : 0.003542230968014337 and train_accuracy : 0.9995166659355164\n",
      "Evaluation : test_loss : 0.07316750902682542 and test_accuracy : 0.981499969959259\n",
      "Epoch 65 - train_loss : 0.003443940648988549 and train_accuracy : 0.9994833469390869\n",
      "Evaluation : test_loss : 0.0730222954414785 and test_accuracy : 0.9819999933242798\n",
      "Epoch 66 - train_loss : 0.0033260178280518932 and train_accuracy : 0.9995166659355164\n",
      "Evaluation : test_loss : 0.07277695675147697 and test_accuracy : 0.9817000031471252\n",
      "Epoch 67 - train_loss : 0.003212788106854229 and train_accuracy : 0.9995166659355164\n",
      "Evaluation : test_loss : 0.07252644342370332 and test_accuracy : 0.9828999638557434\n",
      "Epoch 68 - train_loss : 0.003104907076218903 and train_accuracy : 0.9994000196456909\n",
      "Evaluation : test_loss : 0.07666332521475852 and test_accuracy : 0.9803999662399292\n",
      "Epoch 69 - train_loss : 0.003114844922432288 and train_accuracy : 0.9995166659355164\n",
      "Evaluation : test_loss : 0.07379312029806898 and test_accuracy : 0.9820999503135681\n",
      "Epoch 70 - train_loss : 0.002993353275451227 and train_accuracy : 0.99958336353302\n",
      "Evaluation : test_loss : 0.07520560664124787 and test_accuracy : 0.9805999994277954\n",
      "Epoch 71 - train_loss : 0.0029027676696083897 and train_accuracy : 0.9995666742324829\n",
      "Evaluation : test_loss : 0.07540698871016502 and test_accuracy : 0.9818999767303467\n",
      "Epoch 72 - train_loss : 0.002860478430375224 and train_accuracy : 0.9995499849319458\n",
      "Evaluation : test_loss : 0.07595434414688498 and test_accuracy : 0.9817000031471252\n",
      "Epoch 73 - train_loss : 0.0027172357964445836 and train_accuracy : 0.9996166825294495\n",
      "Evaluation : test_loss : 0.07533388673327863 and test_accuracy : 0.9817999601364136\n",
      "Epoch 74 - train_loss : 0.002640035439496084 and train_accuracy : 0.9996500015258789\n",
      "Evaluation : test_loss : 0.07429685988463461 and test_accuracy : 0.9821999669075012\n",
      "Epoch 75 - train_loss : 0.002564036580042739 and train_accuracy : 0.9997000098228455\n",
      "Evaluation : test_loss : 0.07606646120548248 and test_accuracy : 0.9817999601364136\n",
      "Epoch 76 - train_loss : 0.002485753495420795 and train_accuracy : 0.9996833205223083\n",
      "Evaluation : test_loss : 0.07568538391496986 and test_accuracy : 0.9819999933242798\n",
      "Epoch 77 - train_loss : 0.002375835774000734 and train_accuracy : 0.9997000098228455\n",
      "Evaluation : test_loss : 0.07556779051665216 and test_accuracy : 0.9817000031471252\n",
      "Epoch 78 - train_loss : 0.002301728523464893 and train_accuracy : 0.9997166991233826\n",
      "Evaluation : test_loss : 0.07610294052865356 and test_accuracy : 0.9822999835014343\n",
      "Epoch 79 - train_loss : 0.0023096830233043874 and train_accuracy : 0.999750018119812\n",
      "Evaluation : test_loss : 0.07747614005347714 and test_accuracy : 0.9812999963760376\n",
      "Epoch 80 - train_loss : 0.0022350400343081373 and train_accuracy : 0.9997166991233826\n",
      "Evaluation : test_loss : 0.07652614874532446 and test_accuracy : 0.9820999503135681\n",
      "Epoch 81 - train_loss : 0.002142177416438547 and train_accuracy : 0.9997166991233826\n",
      "Evaluation : test_loss : 0.07939576087519526 and test_accuracy : 0.9811999797821045\n",
      "Epoch 82 - train_loss : 0.00205686471684506 and train_accuracy : 0.9997667074203491\n",
      "Evaluation : test_loss : 0.07804263210855425 and test_accuracy : 0.981499969959259\n",
      "Epoch 83 - train_loss : 0.001975927056931444 and train_accuracy : 0.9997667074203491\n",
      "Evaluation : test_loss : 0.07724823884200305 and test_accuracy : 0.9813999533653259\n",
      "Epoch 84 - train_loss : 0.0018450223786203423 and train_accuracy : 0.9997166991233826\n",
      "Evaluation : test_loss : 0.0768145343172364 and test_accuracy : 0.9827999472618103\n",
      "Epoch 85 - train_loss : 0.0017871522849721563 and train_accuracy : 0.999750018119812\n",
      "Evaluation : test_loss : 0.07801328194327653 and test_accuracy : 0.9822999835014343\n",
      "Epoch 86 - train_loss : 0.0017650370273258886 and train_accuracy : 0.9997333288192749\n",
      "Evaluation : test_loss : 0.07793613739777357 and test_accuracy : 0.9821999669075012\n",
      "Epoch 87 - train_loss : 0.0017226619359765512 and train_accuracy : 0.999750018119812\n",
      "Evaluation : test_loss : 0.07935054251429392 and test_accuracy : 0.9817999601364136\n",
      "Epoch 88 - train_loss : 0.001661195090127876 and train_accuracy : 0.9998500347137451\n",
      "Evaluation : test_loss : 0.07866841282229871 and test_accuracy : 0.9817000031471252\n",
      "Epoch 89 - train_loss : 0.00162400817850236 and train_accuracy : 0.999833345413208\n",
      "Evaluation : test_loss : 0.07775013293139636 and test_accuracy : 0.9828999638557434\n",
      "Epoch 90 - train_loss : 0.0015690751898849462 and train_accuracy : 0.9998500347137451\n",
      "Evaluation : test_loss : 0.07771310459356755 and test_accuracy : 0.9818999767303467\n",
      "Epoch 91 - train_loss : 0.00151356088808825 and train_accuracy : 0.9997667074203491\n",
      "Evaluation : test_loss : 0.07943435143679381 and test_accuracy : 0.9811999797821045\n",
      "Epoch 92 - train_loss : 0.0014467114586295792 and train_accuracy : 0.9998000264167786\n",
      "Evaluation : test_loss : 0.07892189644044265 and test_accuracy : 0.983299970626831\n",
      "Epoch 93 - train_loss : 0.0014810991711783571 and train_accuracy : 0.9998166561126709\n",
      "Evaluation : test_loss : 0.07995184250175953 and test_accuracy : 0.981499969959259\n",
      "Epoch 94 - train_loss : 0.001442070835219056 and train_accuracy : 0.9998999834060669\n",
      "Evaluation : test_loss : 0.07861264956882223 and test_accuracy : 0.9818999767303467\n",
      "Epoch 95 - train_loss : 0.0013242534820165019 and train_accuracy : 0.9998666644096375\n",
      "Evaluation : test_loss : 0.07909004386747256 and test_accuracy : 0.9829999804496765\n",
      "Epoch 96 - train_loss : 0.0013288674344948959 and train_accuracy : 0.9998833537101746\n",
      "Evaluation : test_loss : 0.08059582128189505 and test_accuracy : 0.9813999533653259\n",
      "Epoch 97 - train_loss : 0.0012228777581488734 and train_accuracy : 0.999833345413208\n",
      "Evaluation : test_loss : 0.07899438999593258 and test_accuracy : 0.9829999804496765\n",
      "Epoch 98 - train_loss : 0.001204353510790194 and train_accuracy : 0.9998666644096375\n",
      "Evaluation : test_loss : 0.07964485264383256 and test_accuracy : 0.9820999503135681\n",
      "Epoch 99 - train_loss : 0.0012031797192927722 and train_accuracy : 0.9998666644096375\n",
      "Evaluation : test_loss : 0.08015015893615782 and test_accuracy : 0.9828999638557434\n",
      "Epoch 100 - train_loss : 0.001083609854504175 and train_accuracy : 0.999916672706604\n",
      "Evaluation : test_loss : 0.07990856192773207 and test_accuracy : 0.9825999736785889\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁▁██████████████████████████████████████</td></tr><tr><td>test_loss</td><td>██▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▇█████████████████████████████████████</td></tr><tr><td>train_loss</td><td>██▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.9826</td></tr><tr><td>test_loss</td><td>0.07991</td></tr><tr><td>train_accuracy</td><td>0.99992</td></tr><tr><td>train_loss</td><td>0.00108</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LeNet-1-Adam-vanilla-250-0.01-run</strong> at: <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/plojsngj' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/plojsngj</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240307_231601-plojsngj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/rkada/wandb/run-20240307_232431-tl0n2r3a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/tl0n2r3a' target=\"_blank\">LeNet-1-Adam-vanilla-250-0.001-run</a></strong> to <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/tl0n2r3a' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/tl0n2r3a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - train_loss : 2.041732647518317 and train_accuracy : 0.6950166821479797\n",
      "Evaluation : test_loss : 1.071414904296398 and test_accuracy : 0.703000009059906\n",
      "Epoch 2 - train_loss : 0.6616711590439082 and train_accuracy : 0.8836666941642761\n",
      "Evaluation : test_loss : 0.41601992920041087 and test_accuracy : 0.8870999813079834\n",
      "Epoch 3 - train_loss : 0.35102351419627664 and train_accuracy : 0.914900004863739\n",
      "Evaluation : test_loss : 0.2819466572254896 and test_accuracy : 0.9186999797821045\n",
      "Epoch 4 - train_loss : 0.26313611802955467 and train_accuracy : 0.9293166995048523\n",
      "Evaluation : test_loss : 0.22648528330028056 and test_accuracy : 0.9322999715805054\n",
      "Epoch 5 - train_loss : 0.21373945691933235 and train_accuracy : 0.9404333233833313\n",
      "Evaluation : test_loss : 0.19481660649180413 and test_accuracy : 0.9409999847412109\n",
      "Epoch 6 - train_loss : 0.18118168745810787 and train_accuracy : 0.9509333372116089\n",
      "Evaluation : test_loss : 0.16058665774762632 and test_accuracy : 0.9497999548912048\n",
      "Epoch 7 - train_loss : 0.15665051424875856 and train_accuracy : 0.9561499953269958\n",
      "Evaluation : test_loss : 0.14712922032922507 and test_accuracy : 0.9575999975204468\n",
      "Epoch 8 - train_loss : 0.1386419299679498 and train_accuracy : 0.9602500200271606\n",
      "Evaluation : test_loss : 0.1266232119873166 and test_accuracy : 0.9598000049591064\n",
      "Epoch 9 - train_loss : 0.12433594741548101 and train_accuracy : 0.9648500084877014\n",
      "Evaluation : test_loss : 0.11424110857769847 and test_accuracy : 0.9661999940872192\n",
      "Epoch 10 - train_loss : 0.11281104893423617 and train_accuracy : 0.9686000347137451\n",
      "Evaluation : test_loss : 0.10332752484828234 and test_accuracy : 0.9699999690055847\n",
      "Epoch 11 - train_loss : 0.10278130990142624 and train_accuracy : 0.9704333543777466\n",
      "Evaluation : test_loss : 0.09485163651406765 and test_accuracy : 0.972599983215332\n",
      "Epoch 12 - train_loss : 0.09492061609247078 and train_accuracy : 0.9729166626930237\n",
      "Evaluation : test_loss : 0.08705181013792754 and test_accuracy : 0.972000002861023\n",
      "Epoch 13 - train_loss : 0.08663969224629303 and train_accuracy : 0.9761500358581543\n",
      "Evaluation : test_loss : 0.08026911364868283 and test_accuracy : 0.974299967288971\n",
      "Epoch 14 - train_loss : 0.08109692943592867 and train_accuracy : 0.9763833284378052\n",
      "Evaluation : test_loss : 0.07771298573352396 and test_accuracy : 0.976699948310852\n",
      "Epoch 15 - train_loss : 0.07662148715462536 and train_accuracy : 0.9783666729927063\n",
      "Evaluation : test_loss : 0.07395017393864692 and test_accuracy : 0.9781000018119812\n",
      "Epoch 16 - train_loss : 0.07144912248477339 and train_accuracy : 0.9804500341415405\n",
      "Evaluation : test_loss : 0.06936470521613955 and test_accuracy : 0.9791999459266663\n",
      "Epoch 17 - train_loss : 0.0664143628673628 and train_accuracy : 0.9814500212669373\n",
      "Evaluation : test_loss : 0.06257667262107133 and test_accuracy : 0.9812999963760376\n",
      "Epoch 18 - train_loss : 0.06398369238401452 and train_accuracy : 0.9818000197410583\n",
      "Evaluation : test_loss : 0.06319230417720974 and test_accuracy : 0.9799000024795532\n",
      "Epoch 19 - train_loss : 0.059428182026992245 and train_accuracy : 0.98253333568573\n",
      "Evaluation : test_loss : 0.058706776285544035 and test_accuracy : 0.9813999533653259\n",
      "Epoch 20 - train_loss : 0.056995149744519344 and train_accuracy : 0.9846000075340271\n",
      "Evaluation : test_loss : 0.05638671237975359 and test_accuracy : 0.9824000000953674\n",
      "Epoch 21 - train_loss : 0.05441954080403472 and train_accuracy : 0.9815000295639038\n",
      "Evaluation : test_loss : 0.06272133779712022 and test_accuracy : 0.9800999760627747\n",
      "Epoch 22 - train_loss : 0.051688981242477894 and train_accuracy : 0.9849833250045776\n",
      "Evaluation : test_loss : 0.054767007986083624 and test_accuracy : 0.983199954032898\n",
      "Epoch 23 - train_loss : 0.0504125462883773 and train_accuracy : 0.9862000346183777\n",
      "Evaluation : test_loss : 0.05318711646832526 and test_accuracy : 0.983299970626831\n",
      "Epoch 24 - train_loss : 0.04781021259647484 and train_accuracy : 0.9874666929244995\n",
      "Evaluation : test_loss : 0.05110346572473645 and test_accuracy : 0.984499990940094\n",
      "Epoch 25 - train_loss : 0.045605315811311206 and train_accuracy : 0.9872666597366333\n",
      "Evaluation : test_loss : 0.04875469603575766 and test_accuracy : 0.9850999712944031\n",
      "Epoch 26 - train_loss : 0.044440161937382074 and train_accuracy : 0.987766683101654\n",
      "Evaluation : test_loss : 0.04861108507029712 and test_accuracy : 0.9860000014305115\n",
      "Epoch 27 - train_loss : 0.041735514695756135 and train_accuracy : 0.9886500239372253\n",
      "Evaluation : test_loss : 0.04515115427784622 and test_accuracy : 0.9864999651908875\n",
      "Epoch 28 - train_loss : 0.03982682613035043 and train_accuracy : 0.9853333234786987\n",
      "Evaluation : test_loss : 0.05433323085308075 and test_accuracy : 0.9830999970436096\n",
      "Epoch 29 - train_loss : 0.039671572751831266 and train_accuracy : 0.9895666837692261\n",
      "Evaluation : test_loss : 0.04328989393543452 and test_accuracy : 0.9868999719619751\n",
      "Epoch 30 - train_loss : 0.03826853399320195 and train_accuracy : 0.9895833730697632\n",
      "Evaluation : test_loss : 0.048308079852722584 and test_accuracy : 0.9846999645233154\n",
      "Epoch 31 - train_loss : 0.0371983320665701 and train_accuracy : 0.9904167056083679\n",
      "Evaluation : test_loss : 0.04229108018334955 and test_accuracy : 0.9878999590873718\n",
      "Epoch 32 - train_loss : 0.0341367208379476 and train_accuracy : 0.9911333322525024\n",
      "Evaluation : test_loss : 0.04146210814360529 and test_accuracy : 0.9878999590873718\n",
      "Epoch 33 - train_loss : 0.03355039818173585 and train_accuracy : 0.9903833270072937\n",
      "Evaluation : test_loss : 0.045055313128978015 and test_accuracy : 0.9858999848365784\n",
      "Epoch 34 - train_loss : 0.0331497978962337 and train_accuracy : 0.9915000200271606\n",
      "Evaluation : test_loss : 0.0393989757169038 and test_accuracy : 0.9866999983787537\n",
      "Epoch 35 - train_loss : 0.03185644892510027 and train_accuracy : 0.9919000267982483\n",
      "Evaluation : test_loss : 0.040487393457442525 and test_accuracy : 0.9869999885559082\n",
      "Epoch 36 - train_loss : 0.03209160486779486 and train_accuracy : 0.9925000071525574\n",
      "Evaluation : test_loss : 0.03866301663219929 and test_accuracy : 0.9878000020980835\n",
      "Epoch 37 - train_loss : 0.030419890924046438 and train_accuracy : 0.9917166829109192\n",
      "Evaluation : test_loss : 0.04116733352420852 and test_accuracy : 0.9865999817848206\n",
      "Epoch 38 - train_loss : 0.029145543674045864 and train_accuracy : 0.9924666881561279\n",
      "Evaluation : test_loss : 0.04030824346700683 and test_accuracy : 0.9874999523162842\n",
      "Epoch 39 - train_loss : 0.027967714310701317 and train_accuracy : 0.992650032043457\n",
      "Evaluation : test_loss : 0.04063550448045135 and test_accuracy : 0.9871999621391296\n",
      "Epoch 40 - train_loss : 0.026023592559310298 and train_accuracy : 0.9927499890327454\n",
      "Evaluation : test_loss : 0.04335325369611383 and test_accuracy : 0.9864999651908875\n",
      "Epoch 41 - train_loss : 0.026854731439379977 and train_accuracy : 0.9911666512489319\n",
      "Evaluation : test_loss : 0.04319532685913145 and test_accuracy : 0.986299991607666\n",
      "Epoch 42 - train_loss : 0.024542901158565656 and train_accuracy : 0.9935333728790283\n",
      "Evaluation : test_loss : 0.03770785110536963 and test_accuracy : 0.9888999462127686\n",
      "Epoch 43 - train_loss : 0.02494357351679355 and train_accuracy : 0.9930166602134705\n",
      "Evaluation : test_loss : 0.04240022605517879 and test_accuracy : 0.986799955368042\n",
      "Epoch 44 - train_loss : 0.02325574438533901 and train_accuracy : 0.9917333722114563\n",
      "Evaluation : test_loss : 0.040501752169802785 and test_accuracy : 0.9873999953269958\n",
      "Epoch 45 - train_loss : 0.023535113606097488 and train_accuracy : 0.9942666888237\n",
      "Evaluation : test_loss : 0.037622459675185384 and test_accuracy : 0.9888999462127686\n",
      "Epoch 46 - train_loss : 0.022563441609963774 and train_accuracy : 0.993066668510437\n",
      "Evaluation : test_loss : 0.03988923338474706 and test_accuracy : 0.9879999756813049\n",
      "Epoch 47 - train_loss : 0.022225154545352174 and train_accuracy : 0.9926833510398865\n",
      "Evaluation : test_loss : 0.04327658934053034 and test_accuracy : 0.9856999516487122\n",
      "Epoch 48 - train_loss : 0.020907313982024788 and train_accuracy : 0.9936333298683167\n",
      "Evaluation : test_loss : 0.0403062439057976 and test_accuracy : 0.9868999719619751\n",
      "Epoch 49 - train_loss : 0.020790763295372015 and train_accuracy : 0.9929666519165039\n",
      "Evaluation : test_loss : 0.0456300700083375 and test_accuracy : 0.9863999485969543\n",
      "Epoch 50 - train_loss : 0.020024660501318674 and train_accuracy : 0.9952666759490967\n",
      "Evaluation : test_loss : 0.03628549830755219 and test_accuracy : 0.988099992275238\n",
      "Epoch 51 - train_loss : 0.018665488337865098 and train_accuracy : 0.9952000379562378\n",
      "Evaluation : test_loss : 0.03631650561001152 and test_accuracy : 0.988099992275238\n",
      "Epoch 52 - train_loss : 0.01847420382012691 and train_accuracy : 0.9953166842460632\n",
      "Evaluation : test_loss : 0.03698794271331281 and test_accuracy : 0.9889999628067017\n",
      "Epoch 53 - train_loss : 0.018486726883566007 and train_accuracy : 0.9952499866485596\n",
      "Evaluation : test_loss : 0.040707502549048515 and test_accuracy : 0.9873999953269958\n",
      "Epoch 54 - train_loss : 0.017397508329789466 and train_accuracy : 0.9942499995231628\n",
      "Evaluation : test_loss : 0.044116951036266984 and test_accuracy : 0.9864999651908875\n",
      "Epoch 55 - train_loss : 0.01671110031408413 and train_accuracy : 0.995116651058197\n",
      "Evaluation : test_loss : 0.04022463432047516 and test_accuracy : 0.9878000020980835\n",
      "Epoch 56 - train_loss : 0.015910945814296914 and train_accuracy : 0.9955333471298218\n",
      "Evaluation : test_loss : 0.04077235532458871 and test_accuracy : 0.9871999621391296\n",
      "Epoch 57 - train_loss : 0.015148852249937287 and train_accuracy : 0.9966000318527222\n",
      "Evaluation : test_loss : 0.038896373833995315 and test_accuracy : 0.9878000020980835\n",
      "Epoch 58 - train_loss : 0.01478218788834056 and train_accuracy : 0.9956333637237549\n",
      "Evaluation : test_loss : 0.04199614859535359 and test_accuracy : 0.988099992275238\n",
      "Epoch 59 - train_loss : 0.013726704700578315 and train_accuracy : 0.995983362197876\n",
      "Evaluation : test_loss : 0.041492609365377575 and test_accuracy : 0.9878000020980835\n",
      "Epoch 60 - train_loss : 0.013782253468525596 and train_accuracy : 0.9960333704948425\n",
      "Evaluation : test_loss : 0.040033143351320175 and test_accuracy : 0.9878999590873718\n",
      "Epoch 61 - train_loss : 0.0135245311166121 and train_accuracy : 0.9970499873161316\n",
      "Evaluation : test_loss : 0.03878161970060319 and test_accuracy : 0.988099992275238\n",
      "Epoch 62 - train_loss : 0.012589560361326827 and train_accuracy : 0.9954666495323181\n",
      "Evaluation : test_loss : 0.04614305497379974 and test_accuracy : 0.9864999651908875\n",
      "Epoch 63 - train_loss : 0.012418361508268087 and train_accuracy : 0.9965333342552185\n",
      "Evaluation : test_loss : 0.03768514246330597 and test_accuracy : 0.9887999892234802\n",
      "Epoch 64 - train_loss : 0.013544132981041911 and train_accuracy : 0.9976000189781189\n",
      "Evaluation : test_loss : 0.04058609397616238 and test_accuracy : 0.9879999756813049\n",
      "Epoch 65 - train_loss : 0.011659755358899323 and train_accuracy : 0.9971833229064941\n",
      "Evaluation : test_loss : 0.04192289196071215 and test_accuracy : 0.9882999658584595\n",
      "Epoch 66 - train_loss : 0.011447164800483734 and train_accuracy : 0.9980500340461731\n",
      "Evaluation : test_loss : 0.03796349829062819 and test_accuracy : 0.9879999756813049\n",
      "Epoch 67 - train_loss : 0.010819785226582704 and train_accuracy : 0.9976166486740112\n",
      "Evaluation : test_loss : 0.039754909710609354 and test_accuracy : 0.9887999892234802\n",
      "Epoch 68 - train_loss : 0.010539447769406251 and train_accuracy : 0.9969000220298767\n",
      "Evaluation : test_loss : 0.038988515397068116 and test_accuracy : 0.9882999658584595\n",
      "Epoch 69 - train_loss : 0.009502763862595505 and train_accuracy : 0.9979166984558105\n",
      "Evaluation : test_loss : 0.03860991887631826 and test_accuracy : 0.9878000020980835\n",
      "Epoch 70 - train_loss : 0.01040370230184635 and train_accuracy : 0.9984500408172607\n",
      "Evaluation : test_loss : 0.036603667389135806 and test_accuracy : 0.9891999959945679\n",
      "Epoch 71 - train_loss : 0.01018639963925428 and train_accuracy : 0.9982500076293945\n",
      "Evaluation : test_loss : 0.03956730393692851 and test_accuracy : 0.9889999628067017\n",
      "Epoch 72 - train_loss : 0.010167162262708493 and train_accuracy : 0.9979333281517029\n",
      "Evaluation : test_loss : 0.038960032202885485 and test_accuracy : 0.9881999492645264\n",
      "Epoch 73 - train_loss : 0.008485061476919024 and train_accuracy : 0.9977499842643738\n",
      "Evaluation : test_loss : 0.038864064309746024 and test_accuracy : 0.9891999959945679\n",
      "Epoch 74 - train_loss : 0.00870636070879603 and train_accuracy : 0.998199999332428\n",
      "Evaluation : test_loss : 0.04206836418015882 and test_accuracy : 0.988099992275238\n",
      "Epoch 75 - train_loss : 0.007584919472962307 and train_accuracy : 0.9982333183288574\n",
      "Evaluation : test_loss : 0.040390951273730026 and test_accuracy : 0.9881999492645264\n",
      "Epoch 76 - train_loss : 0.00797163961227246 and train_accuracy : 0.9980833530426025\n",
      "Evaluation : test_loss : 0.04397245867876336 and test_accuracy : 0.9866999983787537\n",
      "Epoch 77 - train_loss : 0.008137241248429442 and train_accuracy : 0.9987833499908447\n",
      "Evaluation : test_loss : 0.04246073309332132 and test_accuracy : 0.9887999892234802\n",
      "Epoch 78 - train_loss : 0.00745621594445159 and train_accuracy : 0.9977999925613403\n",
      "Evaluation : test_loss : 0.043733908468857406 and test_accuracy : 0.9883999824523926\n",
      "Epoch 79 - train_loss : 0.006960193807632701 and train_accuracy : 0.9980999827384949\n",
      "Evaluation : test_loss : 0.04456116737565026 and test_accuracy : 0.9873999953269958\n",
      "Epoch 80 - train_loss : 0.007670892845878067 and train_accuracy : 0.9980666637420654\n",
      "Evaluation : test_loss : 0.044713274104287846 and test_accuracy : 0.9883999824523926\n",
      "Epoch 81 - train_loss : 0.0062526419848533505 and train_accuracy : 0.9985666871070862\n",
      "Evaluation : test_loss : 0.04364299743901938 and test_accuracy : 0.9873999953269958\n",
      "Epoch 82 - train_loss : 0.0076848374223724624 and train_accuracy : 0.9977333545684814\n",
      "Evaluation : test_loss : 0.04740551760769449 and test_accuracy : 0.9878999590873718\n",
      "Epoch 83 - train_loss : 0.006346217726604664 and train_accuracy : 0.9980999827384949\n",
      "Evaluation : test_loss : 0.04662033861968666 and test_accuracy : 0.9881999492645264\n",
      "Epoch 84 - train_loss : 0.006684817535278853 and train_accuracy : 0.99836665391922\n",
      "Evaluation : test_loss : 0.04220069419825449 and test_accuracy : 0.9884999990463257\n",
      "Epoch 85 - train_loss : 0.005825082427084756 and train_accuracy : 0.9987500309944153\n",
      "Evaluation : test_loss : 0.04519394926901441 and test_accuracy : 0.9879999756813049\n",
      "Epoch 86 - train_loss : 0.00552072888725282 and train_accuracy : 0.9983167052268982\n",
      "Evaluation : test_loss : 0.04584150348091498 and test_accuracy : 0.9881999492645264\n",
      "Epoch 87 - train_loss : 0.004920676372906504 and train_accuracy : 0.9992499947547913\n",
      "Evaluation : test_loss : 0.04249595226137899 and test_accuracy : 0.9886999726295471\n",
      "Epoch 88 - train_loss : 0.005295394149046236 and train_accuracy : 0.9986166954040527\n",
      "Evaluation : test_loss : 0.042147712083533406 and test_accuracy : 0.9891999959945679\n",
      "Epoch 89 - train_loss : 0.006482280826579275 and train_accuracy : 0.996833324432373\n",
      "Evaluation : test_loss : 0.051208434929139915 and test_accuracy : 0.9858999848365784\n",
      "Epoch 90 - train_loss : 0.006723991890612524 and train_accuracy : 0.9980833530426025\n",
      "Evaluation : test_loss : 0.045604865945642815 and test_accuracy : 0.9878999590873718\n",
      "Epoch 91 - train_loss : 0.0053198334980455305 and train_accuracy : 0.9989500045776367\n",
      "Evaluation : test_loss : 0.0451574326492846 and test_accuracy : 0.9881999492645264\n",
      "Epoch 00091: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 92 - train_loss : 0.0027276252535860597 and train_accuracy : 0.9995666742324829\n",
      "Evaluation : test_loss : 0.04226282379240729 and test_accuracy : 0.9887999892234802\n",
      "Epoch 93 - train_loss : 0.00236520007802028 and train_accuracy : 0.9995999932289124\n",
      "Evaluation : test_loss : 0.04162412654841319 and test_accuracy : 0.9893999695777893\n",
      "Epoch 94 - train_loss : 0.002286752248983248 and train_accuracy : 0.999666690826416\n",
      "Evaluation : test_loss : 0.04154816128357197 and test_accuracy : 0.9889999628067017\n",
      "Epoch 95 - train_loss : 0.002212788392777535 and train_accuracy : 0.9996833205223083\n",
      "Evaluation : test_loss : 0.04228731183975469 and test_accuracy : 0.9887999892234802\n",
      "Epoch 96 - train_loss : 0.0021614713319043706 and train_accuracy : 0.9997166991233826\n",
      "Evaluation : test_loss : 0.04153914757480379 and test_accuracy : 0.9890999794006348\n",
      "Epoch 97 - train_loss : 0.002159722905950427 and train_accuracy : 0.999666690826416\n",
      "Evaluation : test_loss : 0.04125406285747886 and test_accuracy : 0.9889999628067017\n",
      "Epoch 98 - train_loss : 0.0021334533078819127 and train_accuracy : 0.9996500015258789\n",
      "Evaluation : test_loss : 0.04148313258883718 and test_accuracy : 0.9888999462127686\n",
      "Epoch 99 - train_loss : 0.0021140037334892742 and train_accuracy : 0.9997166991233826\n",
      "Evaluation : test_loss : 0.041397657862398775 and test_accuracy : 0.9890999794006348\n",
      "Epoch 100 - train_loss : 0.0020762423943475974 and train_accuracy : 0.9997166991233826\n",
      "Evaluation : test_loss : 0.041829523904016244 and test_accuracy : 0.9887999892234802\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁▆▇▇████████████████████████████████████</td></tr><tr><td>test_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▆▇▇▇▇██████████████████████████████████</td></tr><tr><td>train_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.9888</td></tr><tr><td>test_loss</td><td>0.04183</td></tr><tr><td>train_accuracy</td><td>0.99972</td></tr><tr><td>train_loss</td><td>0.00208</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LeNet-1-Adam-vanilla-250-0.001-run</strong> at: <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/tl0n2r3a' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/tl0n2r3a</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240307_232431-tl0n2r3a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/rkada/wandb/run-20240307_233247-wmrwv8go</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/wmrwv8go' target=\"_blank\">LeNet-1-Adam-vanilla-500-0.01-run</a></strong> to <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/wmrwv8go' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/wmrwv8go</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - train_loss : 2.305462207396825 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.30126006603241 and test_accuracy : 0.11349999904632568\n",
      "Epoch 2 - train_loss : 2.301559309164683 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3013842940330504 and test_accuracy : 0.11349999904632568\n",
      "Epoch 3 - train_loss : 2.3016059339046477 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3011163234710694 and test_accuracy : 0.11349999904632568\n",
      "Epoch 4 - train_loss : 2.3014965891838073 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3014137744903564 and test_accuracy : 0.11349999904632568\n",
      "Epoch 5 - train_loss : 2.3014594356218976 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3013473033905028 and test_accuracy : 0.11349999904632568\n",
      "Epoch 6 - train_loss : 2.3017013947168987 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3011870861053465 and test_accuracy : 0.11349999904632568\n",
      "Epoch 00006: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 7 - train_loss : 2.301332022746404 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010329484939573 and test_accuracy : 0.11349999904632568\n",
      "Epoch 8 - train_loss : 2.3012179990609485 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010236978530885 and test_accuracy : 0.11349999904632568\n",
      "Epoch 9 - train_loss : 2.301212110122045 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010116696357725 and test_accuracy : 0.11349999904632568\n",
      "Epoch 10 - train_loss : 2.301211581627528 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301029896736145 and test_accuracy : 0.11349999904632568\n",
      "Epoch 11 - train_loss : 2.3012164692083994 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.300997793674469 and test_accuracy : 0.11349999904632568\n",
      "Epoch 12 - train_loss : 2.301217536131541 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010229587554933 and test_accuracy : 0.11349999904632568\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 13 - train_loss : 2.3011670211950936 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301020562648773 and test_accuracy : 0.11349999904632568\n",
      "Epoch 14 - train_loss : 2.30116579135259 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010228514671325 and test_accuracy : 0.11349999904632568\n",
      "Epoch 15 - train_loss : 2.301166127125422 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010194420814516 and test_accuracy : 0.11349999904632568\n",
      "Epoch 16 - train_loss : 2.3011653224627175 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010199308395385 and test_accuracy : 0.11349999904632568\n",
      "Epoch 17 - train_loss : 2.301165149609248 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010182619094848 and test_accuracy : 0.11349999904632568\n",
      "Epoch 18 - train_loss : 2.3011664907137552 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301021134853363 and test_accuracy : 0.11349999904632568\n",
      "Epoch 19 - train_loss : 2.301166041692098 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010204672813415 and test_accuracy : 0.11349999904632568\n",
      "Epoch 20 - train_loss : 2.301165376106898 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301019775867462 and test_accuracy : 0.11349999904632568\n",
      "Epoch 21 - train_loss : 2.3011655112107596 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010202407836915 and test_accuracy : 0.11349999904632568\n",
      "Epoch 22 - train_loss : 2.301165674130122 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010185241699217 and test_accuracy : 0.11349999904632568\n",
      "Epoch 23 - train_loss : 2.30116712252299 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010189294815064 and test_accuracy : 0.11349999904632568\n",
      "Epoch 24 - train_loss : 2.301165537039439 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010196805000307 and test_accuracy : 0.11349999904632568\n",
      "Epoch 25 - train_loss : 2.3011664827664693 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301020157337189 and test_accuracy : 0.11349999904632568\n",
      "Epoch 26 - train_loss : 2.301166347662608 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301018488407135 and test_accuracy : 0.11349999904632568\n",
      "Epoch 27 - train_loss : 2.301165090004603 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301018178462982 and test_accuracy : 0.11349999904632568\n",
      "Epoch 28 - train_loss : 2.3011656483014424 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010175108909605 and test_accuracy : 0.11349999904632568\n",
      "Epoch 29 - train_loss : 2.301166357596715 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010178208351135 and test_accuracy : 0.11349999904632568\n",
      "Epoch 30 - train_loss : 2.3011655429999034 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301018011569977 and test_accuracy : 0.11349999904632568\n",
      "Epoch 31 - train_loss : 2.3011654714743295 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010182976722717 and test_accuracy : 0.11349999904632568\n",
      "Epoch 32 - train_loss : 2.3011666516462963 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301019561290741 and test_accuracy : 0.11349999904632568\n",
      "Epoch 33 - train_loss : 2.301165215174357 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010195016860964 and test_accuracy : 0.11349999904632568\n",
      "Epoch 34 - train_loss : 2.3011680404345194 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301019525527954 and test_accuracy : 0.11349999904632568\n",
      "Epoch 35 - train_loss : 2.30116632382075 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010203361511232 and test_accuracy : 0.11349999904632568\n",
      "Epoch 36 - train_loss : 2.301164921124776 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010223627090456 and test_accuracy : 0.11349999904632568\n",
      "Epoch 37 - train_loss : 2.301165451606115 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301021456718445 and test_accuracy : 0.11349999904632568\n",
      "Epoch 38 - train_loss : 2.3011648217837015 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010183930397035 and test_accuracy : 0.11349999904632568\n",
      "Epoch 39 - train_loss : 2.3011661887168886 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301020014286041 and test_accuracy : 0.11349999904632568\n",
      "Epoch 40 - train_loss : 2.3011653165022534 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301017963886261 and test_accuracy : 0.11349999904632568\n",
      "Epoch 41 - train_loss : 2.301164722442627 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301017236709595 and test_accuracy : 0.11349999904632568\n",
      "Epoch 42 - train_loss : 2.3011667331059775 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301018214225769 and test_accuracy : 0.11349999904632568\n",
      "Epoch 43 - train_loss : 2.3011669635772707 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010192632675173 and test_accuracy : 0.11349999904632568\n",
      "Epoch 44 - train_loss : 2.301164424419403 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010203361511232 and test_accuracy : 0.11349999904632568\n",
      "Epoch 45 - train_loss : 2.301166409254074 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010172247886658 and test_accuracy : 0.11349999904632568\n",
      "Epoch 46 - train_loss : 2.301164609193802 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010173201560975 and test_accuracy : 0.11349999904632568\n",
      "Epoch 47 - train_loss : 2.3011663337548574 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301019752025604 and test_accuracy : 0.11349999904632568\n",
      "Epoch 48 - train_loss : 2.3011662483215334 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010190606117247 and test_accuracy : 0.11349999904632568\n",
      "Epoch 49 - train_loss : 2.301166186730067 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301018500328064 and test_accuracy : 0.11349999904632568\n",
      "Epoch 50 - train_loss : 2.301166216532389 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010176062583922 and test_accuracy : 0.11349999904632568\n",
      "Epoch 51 - train_loss : 2.301168777545293 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010178923606874 and test_accuracy : 0.11349999904632568\n",
      "Epoch 52 - train_loss : 2.301165556907654 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301020157337189 and test_accuracy : 0.11349999904632568\n",
      "Epoch 53 - train_loss : 2.3011665383974713 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301019036769867 and test_accuracy : 0.11349999904632568\n",
      "Epoch 54 - train_loss : 2.301166029771169 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010212898254396 and test_accuracy : 0.11349999904632568\n",
      "Epoch 55 - train_loss : 2.3011657019456226 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.30102059841156 and test_accuracy : 0.11349999904632568\n",
      "Epoch 56 - train_loss : 2.301164968808492 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010181903839113 and test_accuracy : 0.11349999904632568\n",
      "Epoch 57 - train_loss : 2.301166468858719 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010194182395933 and test_accuracy : 0.11349999904632568\n",
      "Epoch 58 - train_loss : 2.3011651933193207 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010178804397583 and test_accuracy : 0.11349999904632568\n",
      "Epoch 59 - train_loss : 2.3011684020360312 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301015305519104 and test_accuracy : 0.11349999904632568\n",
      "Epoch 60 - train_loss : 2.30116756161054 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010207295417784 and test_accuracy : 0.11349999904632568\n",
      "Epoch 61 - train_loss : 2.30116619070371 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301019287109375 and test_accuracy : 0.11349999904632568\n",
      "Epoch 62 - train_loss : 2.3011660675207772 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301018404960632 and test_accuracy : 0.11349999904632568\n",
      "Epoch 63 - train_loss : 2.301166522502899 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010175228118896 and test_accuracy : 0.11349999904632568\n",
      "Epoch 64 - train_loss : 2.3011669516563416 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301020109653473 and test_accuracy : 0.11349999904632568\n",
      "Epoch 65 - train_loss : 2.3011663138866423 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301017475128174 and test_accuracy : 0.11349999904632568\n",
      "Epoch 66 - train_loss : 2.301166997353236 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301017189025879 and test_accuracy : 0.11349999904632568\n",
      "Epoch 67 - train_loss : 2.301168590784073 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301020073890686 and test_accuracy : 0.11349999904632568\n",
      "Epoch 68 - train_loss : 2.3011669357617697 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301020121574402 and test_accuracy : 0.11349999904632568\n",
      "Epoch 69 - train_loss : 2.3011670053005218 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301015245914459 and test_accuracy : 0.11349999904632568\n",
      "Epoch 70 - train_loss : 2.301166460911433 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010191798210142 and test_accuracy : 0.11349999904632568\n",
      "Epoch 71 - train_loss : 2.3011659224828085 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010202288627624 and test_accuracy : 0.11349999904632568\n",
      "Epoch 72 - train_loss : 2.3011659661928814 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301019537448883 and test_accuracy : 0.11349999904632568\n",
      "Epoch 73 - train_loss : 2.3011666774749755 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010191202163695 and test_accuracy : 0.11349999904632568\n",
      "Epoch 74 - train_loss : 2.3011678139368694 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010200023651124 and test_accuracy : 0.11349999904632568\n",
      "Epoch 75 - train_loss : 2.3011674841245013 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010192632675173 and test_accuracy : 0.11349999904632568\n",
      "Epoch 76 - train_loss : 2.301166836420695 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301017427444458 and test_accuracy : 0.11349999904632568\n",
      "Epoch 77 - train_loss : 2.3011667748292286 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010171175003054 and test_accuracy : 0.11349999904632568\n",
      "Epoch 78 - train_loss : 2.3011676828066507 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010181427001952 and test_accuracy : 0.11349999904632568\n",
      "Epoch 79 - train_loss : 2.301168598731359 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010191559791564 and test_accuracy : 0.11349999904632568\n",
      "Epoch 80 - train_loss : 2.301166808605194 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301020061969757 and test_accuracy : 0.11349999904632568\n",
      "Epoch 81 - train_loss : 2.3011667986710864 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301013243198395 and test_accuracy : 0.11349999904632568\n",
      "Epoch 82 - train_loss : 2.301167639096578 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301019012928009 and test_accuracy : 0.11349999904632568\n",
      "Epoch 83 - train_loss : 2.301165888706843 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301017928123474 and test_accuracy : 0.11349999904632568\n",
      "Epoch 84 - train_loss : 2.3011691788832347 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010212659835814 and test_accuracy : 0.11349999904632568\n",
      "Epoch 85 - train_loss : 2.301166609923045 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010164856910706 and test_accuracy : 0.11349999904632568\n",
      "Epoch 86 - train_loss : 2.3011665284633636 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010151624679565 and test_accuracy : 0.11349999904632568\n",
      "Epoch 87 - train_loss : 2.3011659185091653 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010146260261535 and test_accuracy : 0.11349999904632568\n",
      "Epoch 88 - train_loss : 2.3011667907238005 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301013457775116 and test_accuracy : 0.11349999904632568\n",
      "Epoch 89 - train_loss : 2.3011678298314413 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010193705558777 and test_accuracy : 0.11349999904632568\n",
      "Epoch 90 - train_loss : 2.301166752974192 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301016688346863 and test_accuracy : 0.11349999904632568\n",
      "Epoch 91 - train_loss : 2.3011659423510236 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010120034217834 and test_accuracy : 0.11349999904632568\n",
      "Epoch 92 - train_loss : 2.3011488755544027 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.300883615016937 and test_accuracy : 0.11349999904632568\n",
      "Epoch 93 - train_loss : 2.283889412879944 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.250309777259827 and test_accuracy : 0.11349999904632568\n",
      "Epoch 94 - train_loss : 2.216804438829422 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.182310700416565 and test_accuracy : 0.11349999904632568\n",
      "Epoch 95 - train_loss : 2.1682840804258983 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.145496356487274 and test_accuracy : 0.11349999904632568\n",
      "Epoch 96 - train_loss : 2.13947833776474 and train_accuracy : 0.11926666647195816\n",
      "Evaluation : test_loss : 2.1212737798690795 and test_accuracy : 0.120899997651577\n",
      "Epoch 97 - train_loss : 2.118892745176951 and train_accuracy : 0.13875000178813934\n",
      "Evaluation : test_loss : 2.1026160597801207 and test_accuracy : 0.14259999990463257\n",
      "Epoch 98 - train_loss : 2.101841163635254 and train_accuracy : 0.16286666691303253\n",
      "Evaluation : test_loss : 2.0861151814460754 and test_accuracy : 0.16839998960494995\n",
      "Epoch 99 - train_loss : 2.086238215366999 and train_accuracy : 0.1857166737318039\n",
      "Evaluation : test_loss : 2.070526456832886 and test_accuracy : 0.18949998915195465\n",
      "Epoch 100 - train_loss : 2.0714329640070597 and train_accuracy : 0.20945000648498535\n",
      "Evaluation : test_loss : 2.056228220462799 and test_accuracy : 0.2125999927520752\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃█</td></tr><tr><td>test_loss</td><td>█████████████████████████████████████▅▂▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃█</td></tr><tr><td>train_loss</td><td>█████████████████████████████████████▅▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.2126</td></tr><tr><td>test_loss</td><td>2.05623</td></tr><tr><td>train_accuracy</td><td>0.20945</td></tr><tr><td>train_loss</td><td>2.07143</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LeNet-1-Adam-vanilla-500-0.01-run</strong> at: <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/wmrwv8go' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/wmrwv8go</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240307_233247-wmrwv8go/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/rkada/wandb/run-20240307_234018-dt4vgenn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/dt4vgenn' target=\"_blank\">LeNet-1-Adam-vanilla-500-0.001-run</a></strong> to <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/dt4vgenn' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/dt4vgenn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - train_loss : 2.297073620557785 and train_accuracy : 0.21106666326522827\n",
      "Evaluation : test_loss : 2.2259733080863953 and test_accuracy : 0.2126999944448471\n",
      "Epoch 2 - train_loss : 1.4745457316438357 and train_accuracy : 0.7492333650588989\n",
      "Evaluation : test_loss : 0.8516142129898071 and test_accuracy : 0.7590999603271484\n",
      "Epoch 3 - train_loss : 0.6656148297091325 and train_accuracy : 0.8512666821479797\n",
      "Evaluation : test_loss : 0.5102118164300918 and test_accuracy : 0.8575999736785889\n",
      "Epoch 4 - train_loss : 0.4431036392847697 and train_accuracy : 0.8917500376701355\n",
      "Evaluation : test_loss : 0.3687558829784393 and test_accuracy : 0.8959999680519104\n",
      "Epoch 5 - train_loss : 0.3420918534199397 and train_accuracy : 0.907633364200592\n",
      "Evaluation : test_loss : 0.30114936679601667 and test_accuracy : 0.9134999513626099\n",
      "Epoch 6 - train_loss : 0.2886920979867379 and train_accuracy : 0.9213166832923889\n",
      "Evaluation : test_loss : 0.2564591780304909 and test_accuracy : 0.9225999712944031\n",
      "Epoch 7 - train_loss : 0.24945736527442933 and train_accuracy : 0.9313166737556458\n",
      "Evaluation : test_loss : 0.22219859808683395 and test_accuracy : 0.9350999593734741\n",
      "Epoch 8 - train_loss : 0.21927453204989433 and train_accuracy : 0.9395833611488342\n",
      "Evaluation : test_loss : 0.1979689821600914 and test_accuracy : 0.94159996509552\n",
      "Epoch 9 - train_loss : 0.19590752919514973 and train_accuracy : 0.9423166513442993\n",
      "Evaluation : test_loss : 0.18238325715065 and test_accuracy : 0.9469999670982361\n",
      "Epoch 10 - train_loss : 0.17758504481365284 and train_accuracy : 0.94964998960495\n",
      "Evaluation : test_loss : 0.16135273091495037 and test_accuracy : 0.949999988079071\n",
      "Epoch 11 - train_loss : 0.16107943089058002 and train_accuracy : 0.9553833603858948\n",
      "Evaluation : test_loss : 0.14385883882641792 and test_accuracy : 0.9560999870300293\n",
      "Epoch 12 - train_loss : 0.14672782824685177 and train_accuracy : 0.9578999876976013\n",
      "Evaluation : test_loss : 0.13513254784047604 and test_accuracy : 0.9596999883651733\n",
      "Epoch 13 - train_loss : 0.1358269680912296 and train_accuracy : 0.9611833691596985\n",
      "Evaluation : test_loss : 0.12632728107273578 and test_accuracy : 0.9612999558448792\n",
      "Epoch 14 - train_loss : 0.1265049897134304 and train_accuracy : 0.9653333425521851\n",
      "Evaluation : test_loss : 0.11493352800607681 and test_accuracy : 0.9650999903678894\n",
      "Epoch 15 - train_loss : 0.11797069441527128 and train_accuracy : 0.96711665391922\n",
      "Evaluation : test_loss : 0.10634933151304722 and test_accuracy : 0.9668999910354614\n",
      "Epoch 16 - train_loss : 0.11170533498128256 and train_accuracy : 0.9682666659355164\n",
      "Evaluation : test_loss : 0.10168101526796818 and test_accuracy : 0.9691999554634094\n",
      "Epoch 17 - train_loss : 0.10365366407980521 and train_accuracy : 0.970300018787384\n",
      "Evaluation : test_loss : 0.0962025597691536 and test_accuracy : 0.9713999629020691\n",
      "Epoch 18 - train_loss : 0.09943467893948157 and train_accuracy : 0.9698500037193298\n",
      "Evaluation : test_loss : 0.09928040690720082 and test_accuracy : 0.9704999923706055\n",
      "Epoch 19 - train_loss : 0.093798249711593 and train_accuracy : 0.9734166860580444\n",
      "Evaluation : test_loss : 0.08546123113483191 and test_accuracy : 0.9741999506950378\n",
      "Epoch 20 - train_loss : 0.08898748299106955 and train_accuracy : 0.9736999869346619\n",
      "Evaluation : test_loss : 0.08391110431402922 and test_accuracy : 0.9738999605178833\n",
      "Epoch 21 - train_loss : 0.08405231929694613 and train_accuracy : 0.9761999845504761\n",
      "Evaluation : test_loss : 0.07707137651741505 and test_accuracy : 0.976099967956543\n",
      "Epoch 22 - train_loss : 0.08025898669535915 and train_accuracy : 0.9771666526794434\n",
      "Evaluation : test_loss : 0.07565464824438095 and test_accuracy : 0.9770999550819397\n",
      "Epoch 23 - train_loss : 0.0780335129549106 and train_accuracy : 0.9784666895866394\n",
      "Evaluation : test_loss : 0.07195605859160423 and test_accuracy : 0.9781000018119812\n",
      "Epoch 24 - train_loss : 0.07587233676264683 and train_accuracy : 0.9787333607673645\n",
      "Evaluation : test_loss : 0.07502339482307434 and test_accuracy : 0.9775999784469604\n",
      "Epoch 25 - train_loss : 0.07057736009980241 and train_accuracy : 0.9797833561897278\n",
      "Evaluation : test_loss : 0.07049258947372436 and test_accuracy : 0.9787999987602234\n",
      "Epoch 26 - train_loss : 0.06806995424752434 and train_accuracy : 0.980816662311554\n",
      "Evaluation : test_loss : 0.06547192130237818 and test_accuracy : 0.9789999723434448\n",
      "Epoch 27 - train_loss : 0.06623940961435437 and train_accuracy : 0.9817166924476624\n",
      "Evaluation : test_loss : 0.0606183273717761 and test_accuracy : 0.98089998960495\n",
      "Epoch 28 - train_loss : 0.06275554937310517 and train_accuracy : 0.9820500016212463\n",
      "Evaluation : test_loss : 0.061802655644714835 and test_accuracy : 0.9802999496459961\n",
      "Epoch 29 - train_loss : 0.06040709316730499 and train_accuracy : 0.9833000302314758\n",
      "Evaluation : test_loss : 0.058321881480515 and test_accuracy : 0.9813999533653259\n",
      "Epoch 30 - train_loss : 0.05872044308731953 and train_accuracy : 0.9838166832923889\n",
      "Evaluation : test_loss : 0.05788084641098976 and test_accuracy : 0.9817999601364136\n",
      "Epoch 31 - train_loss : 0.056281830572212733 and train_accuracy : 0.9830833673477173\n",
      "Evaluation : test_loss : 0.05798413725569844 and test_accuracy : 0.9809999465942383\n",
      "Epoch 32 - train_loss : 0.055724552273750304 and train_accuracy : 0.983833372592926\n",
      "Evaluation : test_loss : 0.05843370743095875 and test_accuracy : 0.9817999601364136\n",
      "Epoch 33 - train_loss : 0.053382721232871216 and train_accuracy : 0.9845499992370605\n",
      "Evaluation : test_loss : 0.0545027369633317 and test_accuracy : 0.9833999872207642\n",
      "Epoch 34 - train_loss : 0.05111128829109172 and train_accuracy : 0.9850833415985107\n",
      "Evaluation : test_loss : 0.052963017113506795 and test_accuracy : 0.9821999669075012\n",
      "Epoch 35 - train_loss : 0.05001697038921217 and train_accuracy : 0.9850000143051147\n",
      "Evaluation : test_loss : 0.052855591662228106 and test_accuracy : 0.9829999804496765\n",
      "Epoch 36 - train_loss : 0.04804736298198501 and train_accuracy : 0.9857833385467529\n",
      "Evaluation : test_loss : 0.0519963352009654 and test_accuracy : 0.9838999509811401\n",
      "Epoch 37 - train_loss : 0.04769235068621735 and train_accuracy : 0.9870666861534119\n",
      "Evaluation : test_loss : 0.050040002912282944 and test_accuracy : 0.9825999736785889\n",
      "Epoch 38 - train_loss : 0.04643376901124915 and train_accuracy : 0.9862499833106995\n",
      "Evaluation : test_loss : 0.049503290373831985 and test_accuracy : 0.9825999736785889\n",
      "Epoch 39 - train_loss : 0.04388747915315131 and train_accuracy : 0.9883166551589966\n",
      "Evaluation : test_loss : 0.047346637956798075 and test_accuracy : 0.9837999939918518\n",
      "Epoch 40 - train_loss : 0.042441806150600316 and train_accuracy : 0.9878666996955872\n",
      "Evaluation : test_loss : 0.046816513128578666 and test_accuracy : 0.984499990940094\n",
      "Epoch 41 - train_loss : 0.043130406411364675 and train_accuracy : 0.987500011920929\n",
      "Evaluation : test_loss : 0.04852069616317749 and test_accuracy : 0.9835999608039856\n",
      "Epoch 42 - train_loss : 0.04060331500756244 and train_accuracy : 0.9889000058174133\n",
      "Evaluation : test_loss : 0.04750287905335426 and test_accuracy : 0.9840999841690063\n",
      "Epoch 43 - train_loss : 0.04064270178011308 and train_accuracy : 0.988183319568634\n",
      "Evaluation : test_loss : 0.04810106381773949 and test_accuracy : 0.9835999608039856\n",
      "Epoch 44 - train_loss : 0.03924589466769248 and train_accuracy : 0.9894000291824341\n",
      "Evaluation : test_loss : 0.0449145152233541 and test_accuracy : 0.9856999516487122\n",
      "Epoch 45 - train_loss : 0.03779706695737938 and train_accuracy : 0.9885833263397217\n",
      "Evaluation : test_loss : 0.04497103793546557 and test_accuracy : 0.9860000014305115\n",
      "Epoch 46 - train_loss : 0.03929793564602733 and train_accuracy : 0.9903666973114014\n",
      "Evaluation : test_loss : 0.04248593477532268 and test_accuracy : 0.9856999516487122\n",
      "Epoch 47 - train_loss : 0.035306117474101485 and train_accuracy : 0.9900667071342468\n",
      "Evaluation : test_loss : 0.04340737164020538 and test_accuracy : 0.9856999516487122\n",
      "Epoch 48 - train_loss : 0.03451986161526292 and train_accuracy : 0.9905833601951599\n",
      "Evaluation : test_loss : 0.042929323576390746 and test_accuracy : 0.9860999584197998\n",
      "Epoch 49 - train_loss : 0.03554265311298271 and train_accuracy : 0.9911500215530396\n",
      "Evaluation : test_loss : 0.041078248713165524 and test_accuracy : 0.9869999885559082\n",
      "Epoch 50 - train_loss : 0.033008806368646525 and train_accuracy : 0.991100013256073\n",
      "Evaluation : test_loss : 0.041403908468782905 and test_accuracy : 0.9864999651908875\n",
      "Epoch 51 - train_loss : 0.03275568552780896 and train_accuracy : 0.9915833473205566\n",
      "Evaluation : test_loss : 0.042027123365551235 and test_accuracy : 0.9853000044822693\n",
      "Epoch 52 - train_loss : 0.03177252425812185 and train_accuracy : 0.9910333156585693\n",
      "Evaluation : test_loss : 0.04395492263138294 and test_accuracy : 0.9860000014305115\n",
      "Epoch 53 - train_loss : 0.030799956705110768 and train_accuracy : 0.9902666807174683\n",
      "Evaluation : test_loss : 0.045588625594973564 and test_accuracy : 0.9861999750137329\n",
      "Epoch 54 - train_loss : 0.029165083542466164 and train_accuracy : 0.9916833639144897\n",
      "Evaluation : test_loss : 0.04359338497743011 and test_accuracy : 0.9860999584197998\n",
      "Epoch 55 - train_loss : 0.027956067056705555 and train_accuracy : 0.9919500350952148\n",
      "Evaluation : test_loss : 0.040139782987535 and test_accuracy : 0.9866999983787537\n",
      "Epoch 56 - train_loss : 0.028687827149406077 and train_accuracy : 0.9905833601951599\n",
      "Evaluation : test_loss : 0.043564436584711076 and test_accuracy : 0.9851999878883362\n",
      "Epoch 57 - train_loss : 0.027091300495279334 and train_accuracy : 0.9918333292007446\n",
      "Evaluation : test_loss : 0.04155252450145781 and test_accuracy : 0.9850999712944031\n",
      "Epoch 58 - train_loss : 0.027357945028537264 and train_accuracy : 0.992900013923645\n",
      "Evaluation : test_loss : 0.0389515345916152 and test_accuracy : 0.9881999492645264\n",
      "Epoch 59 - train_loss : 0.026859227567911148 and train_accuracy : 0.9930500388145447\n",
      "Evaluation : test_loss : 0.03992589903064072 and test_accuracy : 0.9876999855041504\n",
      "Epoch 60 - train_loss : 0.026026684162206947 and train_accuracy : 0.9937166571617126\n",
      "Evaluation : test_loss : 0.03877714183181524 and test_accuracy : 0.9878999590873718\n",
      "Epoch 61 - train_loss : 0.025472759851254523 and train_accuracy : 0.9927000403404236\n",
      "Evaluation : test_loss : 0.04201153116300702 and test_accuracy : 0.9875999689102173\n",
      "Epoch 62 - train_loss : 0.0248932988770927 and train_accuracy : 0.9940333366394043\n",
      "Evaluation : test_loss : 0.03842234332114458 and test_accuracy : 0.9878999590873718\n",
      "Epoch 63 - train_loss : 0.024156402330845594 and train_accuracy : 0.9936167001724243\n",
      "Evaluation : test_loss : 0.039201690489426254 and test_accuracy : 0.9865999817848206\n",
      "Epoch 64 - train_loss : 0.023607148206792772 and train_accuracy : 0.9925333261489868\n",
      "Evaluation : test_loss : 0.04338780879043043 and test_accuracy : 0.9866999983787537\n",
      "Epoch 65 - train_loss : 0.024013615601385634 and train_accuracy : 0.9939166903495789\n",
      "Evaluation : test_loss : 0.03884343234822154 and test_accuracy : 0.9875999689102173\n",
      "Epoch 66 - train_loss : 0.02278325737376387 and train_accuracy : 0.9932667016983032\n",
      "Evaluation : test_loss : 0.03965505212545395 and test_accuracy : 0.9883999824523926\n",
      "Epoch 67 - train_loss : 0.022178657236509025 and train_accuracy : 0.9941666722297668\n",
      "Evaluation : test_loss : 0.039359351806342605 and test_accuracy : 0.9872999787330627\n",
      "Epoch 68 - train_loss : 0.021668754428780326 and train_accuracy : 0.9948333501815796\n",
      "Evaluation : test_loss : 0.03897063741460442 and test_accuracy : 0.9864999651908875\n",
      "Epoch 69 - train_loss : 0.02135570371368279 and train_accuracy : 0.9942833185195923\n",
      "Evaluation : test_loss : 0.039111760817468165 and test_accuracy : 0.9878999590873718\n",
      "Epoch 70 - train_loss : 0.0210518104955554 and train_accuracy : 0.9939333200454712\n",
      "Evaluation : test_loss : 0.041648204624652865 and test_accuracy : 0.9865999817848206\n",
      "Epoch 71 - train_loss : 0.021493117841115843 and train_accuracy : 0.9945666790008545\n",
      "Evaluation : test_loss : 0.03958998015150428 and test_accuracy : 0.9869999885559082\n",
      "Epoch 72 - train_loss : 0.019505682168528438 and train_accuracy : 0.9954000115394592\n",
      "Evaluation : test_loss : 0.03838952919468284 and test_accuracy : 0.9871999621391296\n",
      "Epoch 73 - train_loss : 0.019762196760469426 and train_accuracy : 0.9945166707038879\n",
      "Evaluation : test_loss : 0.03794193509966135 and test_accuracy : 0.9887999892234802\n",
      "Epoch 74 - train_loss : 0.019685241925374915 and train_accuracy : 0.9954500198364258\n",
      "Evaluation : test_loss : 0.03765170397236943 and test_accuracy : 0.9871999621391296\n",
      "Epoch 75 - train_loss : 0.018345551607975116 and train_accuracy : 0.9943166971206665\n",
      "Evaluation : test_loss : 0.04092338802292943 and test_accuracy : 0.9875999689102173\n",
      "Epoch 76 - train_loss : 0.01767746150144376 and train_accuracy : 0.9951333403587341\n",
      "Evaluation : test_loss : 0.04030663063749671 and test_accuracy : 0.9863999485969543\n",
      "Epoch 77 - train_loss : 0.017956089065410196 and train_accuracy : 0.9959499835968018\n",
      "Evaluation : test_loss : 0.038748187199234965 and test_accuracy : 0.9883999824523926\n",
      "Epoch 78 - train_loss : 0.017416277359006926 and train_accuracy : 0.9944999814033508\n",
      "Evaluation : test_loss : 0.0399816214106977 and test_accuracy : 0.9876999855041504\n",
      "Epoch 79 - train_loss : 0.01696356197935529 and train_accuracy : 0.9959333539009094\n",
      "Evaluation : test_loss : 0.04063774393871426 and test_accuracy : 0.9865999817848206\n",
      "Epoch 80 - train_loss : 0.01591322134093692 and train_accuracy : 0.996666669845581\n",
      "Evaluation : test_loss : 0.03649590511340648 and test_accuracy : 0.9887999892234802\n",
      "Epoch 81 - train_loss : 0.015574515758392712 and train_accuracy : 0.9950833320617676\n",
      "Evaluation : test_loss : 0.040532996086403726 and test_accuracy : 0.9873999953269958\n",
      "Epoch 82 - train_loss : 0.015920767634330937 and train_accuracy : 0.9948999881744385\n",
      "Evaluation : test_loss : 0.043142983224242926 and test_accuracy : 0.9860000014305115\n",
      "Epoch 83 - train_loss : 0.014823870236674945 and train_accuracy : 0.9967166781425476\n",
      "Evaluation : test_loss : 0.039484699442982676 and test_accuracy : 0.9878000020980835\n",
      "Epoch 84 - train_loss : 0.014784118065532918 and train_accuracy : 0.9967666864395142\n",
      "Evaluation : test_loss : 0.03869235590100288 and test_accuracy : 0.9879999756813049\n",
      "Epoch 85 - train_loss : 0.013469359839412694 and train_accuracy : 0.9948999881744385\n",
      "Evaluation : test_loss : 0.04365371149033308 and test_accuracy : 0.9860999584197998\n",
      "Epoch 86 - train_loss : 0.013692495950575296 and train_accuracy : 0.9970166683197021\n",
      "Evaluation : test_loss : 0.037791902851313355 and test_accuracy : 0.9881999492645264\n",
      "Epoch 87 - train_loss : 0.01400621465096871 and train_accuracy : 0.995033323764801\n",
      "Evaluation : test_loss : 0.04339536740444601 and test_accuracy : 0.9870999455451965\n",
      "Epoch 88 - train_loss : 0.013466484103507053 and train_accuracy : 0.9963833689689636\n",
      "Evaluation : test_loss : 0.03963607614859939 and test_accuracy : 0.9886999726295471\n",
      "Epoch 89 - train_loss : 0.013048882617537554 and train_accuracy : 0.9955333471298218\n",
      "Evaluation : test_loss : 0.04193327850662172 and test_accuracy : 0.9861999750137329\n",
      "Epoch 90 - train_loss : 0.012280731743279224 and train_accuracy : 0.9964166879653931\n",
      "Evaluation : test_loss : 0.04065709356218576 and test_accuracy : 0.9872999787330627\n",
      "Epoch 91 - train_loss : 0.011929030091656993 and train_accuracy : 0.9974166750907898\n",
      "Evaluation : test_loss : 0.03766352660022676 and test_accuracy : 0.9884999990463257\n",
      "Epoch 92 - train_loss : 0.012986990458254391 and train_accuracy : 0.9971666932106018\n",
      "Evaluation : test_loss : 0.03916338961571455 and test_accuracy : 0.9869999885559082\n",
      "Epoch 93 - train_loss : 0.011553762666881084 and train_accuracy : 0.9973000288009644\n",
      "Evaluation : test_loss : 0.03910226817242801 and test_accuracy : 0.9886999726295471\n",
      "Epoch 94 - train_loss : 0.01187972776630583 and train_accuracy : 0.9972666501998901\n",
      "Evaluation : test_loss : 0.042231503129005435 and test_accuracy : 0.9876999855041504\n",
      "Epoch 95 - train_loss : 0.011169805480555321 and train_accuracy : 0.9969500303268433\n",
      "Evaluation : test_loss : 0.04101398941129446 and test_accuracy : 0.9878999590873718\n",
      "Epoch 96 - train_loss : 0.011250277965640028 and train_accuracy : 0.9978333711624146\n",
      "Evaluation : test_loss : 0.039460137113928796 and test_accuracy : 0.9874999523162842\n",
      "Epoch 97 - train_loss : 0.01089157405270574 and train_accuracy : 0.9978500008583069\n",
      "Evaluation : test_loss : 0.03786966730840504 and test_accuracy : 0.9883999824523926\n",
      "Epoch 98 - train_loss : 0.01060510766110383 and train_accuracy : 0.9977166652679443\n",
      "Evaluation : test_loss : 0.038575945608317855 and test_accuracy : 0.9896000027656555\n",
      "Epoch 99 - train_loss : 0.010127403689936424 and train_accuracy : 0.9968833327293396\n",
      "Evaluation : test_loss : 0.03975378964096308 and test_accuracy : 0.9874999523162842\n",
      "Epoch 100 - train_loss : 0.009938985951400052 and train_accuracy : 0.9976500272750854\n",
      "Evaluation : test_loss : 0.041308794915676114 and test_accuracy : 0.9881999492645264\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁▇▇█████████████████████████████████████</td></tr><tr><td>test_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▇▇▇████████████████████████████████████</td></tr><tr><td>train_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.9882</td></tr><tr><td>test_loss</td><td>0.04131</td></tr><tr><td>train_accuracy</td><td>0.99765</td></tr><tr><td>train_loss</td><td>0.00994</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LeNet-1-Adam-vanilla-500-0.001-run</strong> at: <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/dt4vgenn' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/dt4vgenn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240307_234018-dt4vgenn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/rkada/wandb/run-20240307_234746-va9xsmbq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/va9xsmbq' target=\"_blank\">LeNet-1-SGD-vanilla-250-0.01-run</a></strong> to <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/va9xsmbq' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/va9xsmbq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - train_loss : 2.303156387805939 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301204651594162 and test_accuracy : 0.11349999904632568\n",
      "Epoch 2 - train_loss : 2.3014036337534587 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010697245597838 and test_accuracy : 0.11349999904632568\n",
      "Epoch 3 - train_loss : 2.301500137646993 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3011069536209106 and test_accuracy : 0.11349999904632568\n",
      "Epoch 4 - train_loss : 2.3014475295941037 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.300962543487549 and test_accuracy : 0.11349999904632568\n",
      "Epoch 5 - train_loss : 2.301390627026558 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3011301517486573 and test_accuracy : 0.11349999904632568\n",
      "Epoch 6 - train_loss : 2.3014056235551834 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3011085391044617 and test_accuracy : 0.11349999904632568\n",
      "Epoch 00006: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 7 - train_loss : 2.301276265581449 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010259449481962 and test_accuracy : 0.11349999904632568\n",
      "Epoch 8 - train_loss : 2.3012185394763947 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010036289691924 and test_accuracy : 0.11349999904632568\n",
      "Epoch 9 - train_loss : 2.3011980950832367 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010018706321715 and test_accuracy : 0.11349999904632568\n",
      "Epoch 10 - train_loss : 2.3011962751547497 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010126769542696 and test_accuracy : 0.11349999904632568\n",
      "Epoch 00010: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 11 - train_loss : 2.301159120599429 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010126113891602 and test_accuracy : 0.11349999904632568\n",
      "Epoch 12 - train_loss : 2.3011590937773385 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012420654297 and test_accuracy : 0.11349999904632568\n",
      "Epoch 13 - train_loss : 2.3011585722366967 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010123550891874 and test_accuracy : 0.11349999904632568\n",
      "Epoch 14 - train_loss : 2.301158563296 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010121285915375 and test_accuracy : 0.11349999904632568\n",
      "Epoch 15 - train_loss : 2.301158180832863 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010121464729307 and test_accuracy : 0.11349999904632568\n",
      "Epoch 16 - train_loss : 2.3011579473813373 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010121285915375 and test_accuracy : 0.11349999904632568\n",
      "Epoch 17 - train_loss : 2.301157621542613 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010121464729307 and test_accuracy : 0.11349999904632568\n",
      "Epoch 18 - train_loss : 2.3011577477057776 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010122060775755 and test_accuracy : 0.11349999904632568\n",
      "Epoch 19 - train_loss : 2.301157529155413 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010121524333953 and test_accuracy : 0.11349999904632568\n",
      "Epoch 20 - train_loss : 2.3011575897534686 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010121166706083 and test_accuracy : 0.11349999904632568\n",
      "Epoch 21 - train_loss : 2.3011571844418843 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010121881961823 and test_accuracy : 0.11349999904632568\n",
      "Epoch 22 - train_loss : 2.3011571288108827 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010122537612916 and test_accuracy : 0.11349999904632568\n",
      "Epoch 23 - train_loss : 2.301156994700432 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012372970581 and test_accuracy : 0.11349999904632568\n",
      "Epoch 24 - train_loss : 2.30115692615509 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010122179985046 and test_accuracy : 0.11349999904632568\n",
      "Epoch 25 - train_loss : 2.3011569291353227 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012271642685 and test_accuracy : 0.11349999904632568\n",
      "Epoch 26 - train_loss : 2.3011568268140157 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012319326401 and test_accuracy : 0.11349999904632568\n",
      "Epoch 27 - train_loss : 2.3011567264795305 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.30101238489151 and test_accuracy : 0.11349999904632568\n",
      "Epoch 28 - train_loss : 2.3011567453543345 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010123491287233 and test_accuracy : 0.11349999904632568\n",
      "Epoch 29 - train_loss : 2.301156756281853 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012271642685 and test_accuracy : 0.11349999904632568\n",
      "Epoch 30 - train_loss : 2.3011566708485285 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010122418403625 and test_accuracy : 0.11349999904632568\n",
      "Epoch 31 - train_loss : 2.3011566013097764 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012337207794 and test_accuracy : 0.11349999904632568\n",
      "Epoch 32 - train_loss : 2.301156673828761 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012414693832 and test_accuracy : 0.11349999904632568\n",
      "Epoch 33 - train_loss : 2.301156453291575 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012545824051 and test_accuracy : 0.11349999904632568\n",
      "Epoch 34 - train_loss : 2.301156504948934 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010126113891602 and test_accuracy : 0.11349999904632568\n",
      "Epoch 35 - train_loss : 2.3011562794446947 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010125398635863 and test_accuracy : 0.11349999904632568\n",
      "Epoch 36 - train_loss : 2.3011562009652455 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010125756263733 and test_accuracy : 0.11349999904632568\n",
      "Epoch 37 - train_loss : 2.3011562238136927 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010126888751983 and test_accuracy : 0.11349999904632568\n",
      "Epoch 38 - train_loss : 2.3011563241481783 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010126829147337 and test_accuracy : 0.11349999904632568\n",
      "Epoch 39 - train_loss : 2.301156294345856 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010127902030946 and test_accuracy : 0.11349999904632568\n",
      "Epoch 40 - train_loss : 2.3011564284563066 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010127902030946 and test_accuracy : 0.11349999904632568\n",
      "Epoch 41 - train_loss : 2.30115634004275 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012712717056 and test_accuracy : 0.11349999904632568\n",
      "Epoch 42 - train_loss : 2.301156234741211 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012706756592 and test_accuracy : 0.11349999904632568\n",
      "Epoch 43 - train_loss : 2.3011562635501224 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012820005417 and test_accuracy : 0.11349999904632568\n",
      "Epoch 44 - train_loss : 2.301156304279963 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012861728668 and test_accuracy : 0.11349999904632568\n",
      "Epoch 45 - train_loss : 2.301156176129977 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012820005417 and test_accuracy : 0.11349999904632568\n",
      "Epoch 46 - train_loss : 2.3011561493078867 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012969017029 and test_accuracy : 0.11349999904632568\n",
      "Epoch 47 - train_loss : 2.3011562834183374 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010129153728487 and test_accuracy : 0.11349999904632568\n",
      "Epoch 48 - train_loss : 2.3011561383803687 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010129272937774 and test_accuracy : 0.11349999904632568\n",
      "Epoch 49 - train_loss : 2.3011564989884694 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010129570960998 and test_accuracy : 0.11349999904632568\n",
      "Epoch 50 - train_loss : 2.301156397660573 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010131061077117 and test_accuracy : 0.11349999904632568\n",
      "Epoch 51 - train_loss : 2.3011563648780187 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010131299495695 and test_accuracy : 0.11349999904632568\n",
      "Epoch 52 - train_loss : 2.3011563311020535 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301013100147247 and test_accuracy : 0.11349999904632568\n",
      "Epoch 53 - train_loss : 2.30115624666214 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012897491455 and test_accuracy : 0.11349999904632568\n",
      "Epoch 54 - train_loss : 2.3011563807725905 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010129749774935 and test_accuracy : 0.11349999904632568\n",
      "Epoch 55 - train_loss : 2.3011562158664067 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010129749774935 and test_accuracy : 0.11349999904632568\n",
      "Epoch 56 - train_loss : 2.3011561294396716 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010130763053893 and test_accuracy : 0.11349999904632568\n",
      "Epoch 57 - train_loss : 2.301156062881152 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010129392147065 and test_accuracy : 0.11349999904632568\n",
      "Epoch 58 - train_loss : 2.3011560837427774 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010128796100617 and test_accuracy : 0.11349999904632568\n",
      "Epoch 59 - train_loss : 2.301156207919121 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010128319263456 and test_accuracy : 0.11349999904632568\n",
      "Epoch 60 - train_loss : 2.301156012217204 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010128319263456 and test_accuracy : 0.11349999904632568\n",
      "Epoch 61 - train_loss : 2.301156276464462 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.30101278424263 and test_accuracy : 0.11349999904632568\n",
      "Epoch 62 - train_loss : 2.3011563887198765 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010127663612367 and test_accuracy : 0.11349999904632568\n",
      "Epoch 63 - train_loss : 2.301156019171079 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010127186775207 and test_accuracy : 0.11349999904632568\n",
      "Epoch 64 - train_loss : 2.3011562059322994 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010127186775207 and test_accuracy : 0.11349999904632568\n",
      "Epoch 65 - train_loss : 2.3011562407016752 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010127186775207 and test_accuracy : 0.11349999904632568\n",
      "Epoch 66 - train_loss : 2.30115608672301 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.30101273059845 and test_accuracy : 0.11349999904632568\n",
      "Epoch 67 - train_loss : 2.3011562556028364 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012748479843 and test_accuracy : 0.11349999904632568\n",
      "Epoch 68 - train_loss : 2.3011559824148815 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010128319263456 and test_accuracy : 0.11349999904632568\n",
      "Epoch 69 - train_loss : 2.301156097650528 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012855768204 and test_accuracy : 0.11349999904632568\n",
      "Epoch 70 - train_loss : 2.301156151294708 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012861728668 and test_accuracy : 0.11349999904632568\n",
      "Epoch 71 - train_loss : 2.3011558691660565 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.30101283788681 and test_accuracy : 0.11349999904632568\n",
      "Epoch 72 - train_loss : 2.301156302293142 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012861728668 and test_accuracy : 0.11349999904632568\n",
      "Epoch 73 - train_loss : 2.3011562754710515 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012945175171 and test_accuracy : 0.11349999904632568\n",
      "Epoch 74 - train_loss : 2.301156242688497 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010129749774935 and test_accuracy : 0.11349999904632568\n",
      "Epoch 75 - train_loss : 2.3011562248071034 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010129034519196 and test_accuracy : 0.11349999904632568\n",
      "Epoch 76 - train_loss : 2.3011562367280325 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010128140449524 and test_accuracy : 0.11349999904632568\n",
      "Epoch 77 - train_loss : 2.301156019171079 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012760400772 and test_accuracy : 0.11349999904632568\n",
      "Epoch 78 - train_loss : 2.3011561185121536 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010127365589144 and test_accuracy : 0.11349999904632568\n",
      "Epoch 79 - train_loss : 2.301156023144722 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010128021240233 and test_accuracy : 0.11349999904632568\n",
      "Epoch 80 - train_loss : 2.3011561503012974 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010128259658815 and test_accuracy : 0.11349999904632568\n",
      "Epoch 81 - train_loss : 2.3011560599009195 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010125935077665 and test_accuracy : 0.11349999904632568\n",
      "Epoch 82 - train_loss : 2.3011560956637065 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010124921798707 and test_accuracy : 0.11349999904632568\n",
      "Epoch 83 - train_loss : 2.30115599433581 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012486219406 and test_accuracy : 0.11349999904632568\n",
      "Epoch 84 - train_loss : 2.3011562575896582 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012670993805 and test_accuracy : 0.11349999904632568\n",
      "Epoch 85 - train_loss : 2.3011559655268985 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010125517845155 and test_accuracy : 0.11349999904632568\n",
      "Epoch 86 - train_loss : 2.301156128446261 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012521982193 and test_accuracy : 0.11349999904632568\n",
      "Epoch 87 - train_loss : 2.3011560906966526 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010124564170837 and test_accuracy : 0.11349999904632568\n",
      "Epoch 88 - train_loss : 2.3011559933423995 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010123789310457 and test_accuracy : 0.11349999904632568\n",
      "Epoch 89 - train_loss : 2.3011560092369714 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010123789310457 and test_accuracy : 0.11349999904632568\n",
      "Epoch 90 - train_loss : 2.3011560400327045 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010123670101166 and test_accuracy : 0.11349999904632568\n",
      "Epoch 91 - train_loss : 2.3011561582485833 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012474298477 and test_accuracy : 0.11349999904632568\n",
      "Epoch 92 - train_loss : 2.3011559059222537 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010124564170837 and test_accuracy : 0.11349999904632568\n",
      "Epoch 93 - train_loss : 2.301156081755956 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012510061264 and test_accuracy : 0.11349999904632568\n",
      "Epoch 94 - train_loss : 2.3011558949947357 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010125756263733 and test_accuracy : 0.11349999904632568\n",
      "Epoch 95 - train_loss : 2.301156050960223 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012623310089 and test_accuracy : 0.11349999904632568\n",
      "Epoch 96 - train_loss : 2.301155858238538 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010126054286957 and test_accuracy : 0.11349999904632568\n",
      "Epoch 97 - train_loss : 2.301155956586202 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012581586838 and test_accuracy : 0.11349999904632568\n",
      "Epoch 98 - train_loss : 2.3011560261249544 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010125756263733 and test_accuracy : 0.11349999904632568\n",
      "Epoch 99 - train_loss : 2.301156145334244 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010125160217285 and test_accuracy : 0.11349999904632568\n",
      "Epoch 100 - train_loss : 2.3011560052633286 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012623310089 and test_accuracy : 0.11349999904632568\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_loss</td><td>█▅▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.1135</td></tr><tr><td>test_loss</td><td>2.30101</td></tr><tr><td>train_accuracy</td><td>0.11237</td></tr><tr><td>train_loss</td><td>2.30116</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LeNet-1-SGD-vanilla-250-0.01-run</strong> at: <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/va9xsmbq' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/va9xsmbq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240307_234746-va9xsmbq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/rkada/wandb/run-20240307_235533-bnm9rqs4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/bnm9rqs4' target=\"_blank\">LeNet-1-SGD-vanilla-250-0.001-run</a></strong> to <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/bnm9rqs4' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/bnm9rqs4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - train_loss : 2.3238526423772177 and train_accuracy : 0.09751667082309723\n",
      "Evaluation : test_loss : 2.3150070190429686 and test_accuracy : 0.0973999947309494\n",
      "Epoch 2 - train_loss : 2.3086220850547154 and train_accuracy : 0.09751667082309723\n",
      "Evaluation : test_loss : 2.305953973531723 and test_accuracy : 0.0973999947309494\n",
      "Epoch 3 - train_loss : 2.303578339020411 and train_accuracy : 0.10218333452939987\n",
      "Evaluation : test_loss : 2.3028283596038817 and test_accuracy : 0.10099999606609344\n",
      "Epoch 4 - train_loss : 2.3019504944483438 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3017223954200743 and test_accuracy : 0.11349999904632568\n",
      "Epoch 5 - train_loss : 2.301439489920934 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3013175666332244 and test_accuracy : 0.11349999904632568\n",
      "Epoch 6 - train_loss : 2.301276054978371 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.30115430355072 and test_accuracy : 0.11349999904632568\n",
      "Epoch 7 - train_loss : 2.3012264798084896 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010854363441466 and test_accuracy : 0.11349999904632568\n",
      "Epoch 8 - train_loss : 2.301212468743324 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010559558868406 and test_accuracy : 0.11349999904632568\n",
      "Epoch 9 - train_loss : 2.3012060364087423 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301050716638565 and test_accuracy : 0.11349999904632568\n",
      "Epoch 10 - train_loss : 2.301205727458 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010346710681917 and test_accuracy : 0.11349999904632568\n",
      "Epoch 11 - train_loss : 2.3012075583140055 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010275781154634 and test_accuracy : 0.11349999904632568\n",
      "Epoch 12 - train_loss : 2.301208029190699 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301031529903412 and test_accuracy : 0.11349999904632568\n",
      "Epoch 13 - train_loss : 2.301206656297048 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010231494903564 and test_accuracy : 0.11349999904632568\n",
      "Epoch 00013: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 14 - train_loss : 2.3011721551418303 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010233998298646 and test_accuracy : 0.11349999904632568\n",
      "Epoch 15 - train_loss : 2.301172215739886 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301023703813553 and test_accuracy : 0.11349999904632568\n",
      "Epoch 16 - train_loss : 2.301172126332919 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301023906469345 and test_accuracy : 0.11349999904632568\n",
      "Epoch 17 - train_loss : 2.3011723389228185 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301024132966995 and test_accuracy : 0.11349999904632568\n",
      "Epoch 18 - train_loss : 2.3011720279852548 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301024299860001 and test_accuracy : 0.11349999904632568\n",
      "Epoch 19 - train_loss : 2.3011718064546587 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010245084762575 and test_accuracy : 0.11349999904632568\n",
      "Epoch 20 - train_loss : 2.301172085603078 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301024615764618 and test_accuracy : 0.11349999904632568\n",
      "Epoch 21 - train_loss : 2.301172011097272 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301024740934372 and test_accuracy : 0.11349999904632568\n",
      "Epoch 22 - train_loss : 2.3011720647414524 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010249197483064 and test_accuracy : 0.11349999904632568\n",
      "Epoch 23 - train_loss : 2.3011718541383743 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010250866413116 and test_accuracy : 0.11349999904632568\n",
      "Epoch 24 - train_loss : 2.301171972354253 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.30102533698082 and test_accuracy : 0.11349999904632568\n",
      "Epoch 25 - train_loss : 2.301172046860059 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010254383087156 and test_accuracy : 0.11349999904632568\n",
      "Epoch 26 - train_loss : 2.30117198129495 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301025468111038 and test_accuracy : 0.11349999904632568\n",
      "Epoch 27 - train_loss : 2.301171977321307 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301025462150574 and test_accuracy : 0.11349999904632568\n",
      "Epoch 28 - train_loss : 2.30117167532444 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010255873203276 and test_accuracy : 0.11349999904632568\n",
      "Epoch 29 - train_loss : 2.3011719465255736 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010256230831145 and test_accuracy : 0.11349999904632568\n",
      "Epoch 30 - train_loss : 2.3011718382438024 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301025754213333 and test_accuracy : 0.11349999904632568\n",
      "Epoch 31 - train_loss : 2.3011718074480694 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010257959365843 and test_accuracy : 0.11349999904632568\n",
      "Epoch 32 - train_loss : 2.301171890894572 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010259330272675 and test_accuracy : 0.11349999904632568\n",
      "Epoch 33 - train_loss : 2.301171745856603 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010260224342347 and test_accuracy : 0.11349999904632568\n",
      "Epoch 34 - train_loss : 2.301171773672104 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010260581970217 and test_accuracy : 0.11349999904632568\n",
      "Epoch 35 - train_loss : 2.3011718203624087 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010262489318847 and test_accuracy : 0.11349999904632568\n",
      "Epoch 36 - train_loss : 2.3011718650658923 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301026201248169 and test_accuracy : 0.11349999904632568\n",
      "Epoch 37 - train_loss : 2.301171711087227 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010262727737425 and test_accuracy : 0.11349999904632568\n",
      "Epoch 38 - train_loss : 2.301171733935674 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010262966156008 and test_accuracy : 0.11349999904632568\n",
      "Epoch 39 - train_loss : 2.3011717826128004 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010263562202455 and test_accuracy : 0.11349999904632568\n",
      "Epoch 40 - train_loss : 2.3011716196934384 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301026481389999 and test_accuracy : 0.11349999904632568\n",
      "Epoch 41 - train_loss : 2.301171647508939 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010265588760377 and test_accuracy : 0.11349999904632568\n",
      "Epoch 42 - train_loss : 2.3011718104283014 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010266423225403 and test_accuracy : 0.11349999904632568\n",
      "Epoch 43 - train_loss : 2.3011717836062116 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301026701927185 and test_accuracy : 0.11349999904632568\n",
      "Epoch 44 - train_loss : 2.301171760757764 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301026797294617 and test_accuracy : 0.11349999904632568\n",
      "Epoch 45 - train_loss : 2.3011716812849046 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301026862859726 and test_accuracy : 0.11349999904632568\n",
      "Epoch 46 - train_loss : 2.3011716028054554 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010269522666933 and test_accuracy : 0.11349999904632568\n",
      "Epoch 47 - train_loss : 2.3011717845996222 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301026964187622 and test_accuracy : 0.11349999904632568\n",
      "Epoch 48 - train_loss : 2.3011717041333517 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010268986225126 and test_accuracy : 0.11349999904632568\n",
      "Epoch 49 - train_loss : 2.3011717915534975 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301026940345764 and test_accuracy : 0.11349999904632568\n",
      "Epoch 50 - train_loss : 2.3011714746554692 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010269165039063 and test_accuracy : 0.11349999904632568\n",
      "Epoch 51 - train_loss : 2.3011717915534975 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301026999950409 and test_accuracy : 0.11349999904632568\n",
      "Epoch 52 - train_loss : 2.301171757777532 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301027053594589 and test_accuracy : 0.11349999904632568\n",
      "Epoch 53 - train_loss : 2.301171929637591 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010269939899444 and test_accuracy : 0.11349999904632568\n",
      "Epoch 54 - train_loss : 2.301171631614367 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301026862859726 and test_accuracy : 0.11349999904632568\n",
      "Epoch 55 - train_loss : 2.3011716425418856 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010269105434418 and test_accuracy : 0.11349999904632568\n",
      "Epoch 56 - train_loss : 2.3011715044577916 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301027053594589 and test_accuracy : 0.11349999904632568\n",
      "Epoch 57 - train_loss : 2.301171667377154 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301026928424835 and test_accuracy : 0.11349999904632568\n",
      "Epoch 58 - train_loss : 2.3011715432008106 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301027077436447 and test_accuracy : 0.11349999904632568\n",
      "Epoch 59 - train_loss : 2.3011715948581695 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010271370410917 and test_accuracy : 0.11349999904632568\n",
      "Epoch 60 - train_loss : 2.3011717279752095 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301027125120163 and test_accuracy : 0.11349999904632568\n",
      "Epoch 61 - train_loss : 2.3011717150608697 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010270953178407 and test_accuracy : 0.11349999904632568\n",
      "Epoch 62 - train_loss : 2.301171773672104 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010271370410917 and test_accuracy : 0.11349999904632568\n",
      "Epoch 63 - train_loss : 2.3011716544628142 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010270953178407 and test_accuracy : 0.11349999904632568\n",
      "Epoch 64 - train_loss : 2.301171584924062 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301027327775955 and test_accuracy : 0.11349999904632568\n",
      "Epoch 65 - train_loss : 2.3011713196833927 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010273873806 and test_accuracy : 0.11349999904632568\n",
      "Epoch 66 - train_loss : 2.301171498497327 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301027202606201 and test_accuracy : 0.11349999904632568\n",
      "Epoch 67 - train_loss : 2.3011716653903327 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010271549224854 and test_accuracy : 0.11349999904632568\n",
      "Epoch 68 - train_loss : 2.301171660423279 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.30102716088295 and test_accuracy : 0.11349999904632568\n",
      "Epoch 69 - train_loss : 2.3011716157197952 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301027202606201 and test_accuracy : 0.11349999904632568\n",
      "Epoch 70 - train_loss : 2.3011715759833655 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301027184724808 and test_accuracy : 0.11349999904632568\n",
      "Epoch 71 - train_loss : 2.301171585917473 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301027297973633 and test_accuracy : 0.11349999904632568\n",
      "Epoch 72 - train_loss : 2.301171612739563 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010272800922396 and test_accuracy : 0.11349999904632568\n",
      "Epoch 73 - train_loss : 2.3011713922023773 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301027351617813 and test_accuracy : 0.11349999904632568\n",
      "Epoch 74 - train_loss : 2.3011712203423182 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010273814201354 and test_accuracy : 0.11349999904632568\n",
      "Epoch 75 - train_loss : 2.3011716256539025 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010275423526765 and test_accuracy : 0.11349999904632568\n",
      "Epoch 76 - train_loss : 2.3011718978484472 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010273873806 and test_accuracy : 0.11349999904632568\n",
      "Epoch 77 - train_loss : 2.3011714855829877 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010273456573485 and test_accuracy : 0.11349999904632568\n",
      "Epoch 78 - train_loss : 2.301171511411667 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010273575782776 and test_accuracy : 0.11349999904632568\n",
      "Epoch 79 - train_loss : 2.301171611746152 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301027327775955 and test_accuracy : 0.11349999904632568\n",
      "Epoch 80 - train_loss : 2.3011715690294903 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010273814201354 and test_accuracy : 0.11349999904632568\n",
      "Epoch 81 - train_loss : 2.301171764731407 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010272562503813 and test_accuracy : 0.11349999904632568\n",
      "Epoch 82 - train_loss : 2.301171514391899 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010272800922396 and test_accuracy : 0.11349999904632568\n",
      "Epoch 83 - train_loss : 2.301171800494194 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301027202606201 and test_accuracy : 0.11349999904632568\n",
      "Epoch 84 - train_loss : 2.3011714309453963 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010272681713104 and test_accuracy : 0.11349999904632568\n",
      "Epoch 85 - train_loss : 2.3011715511480966 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010271787643433 and test_accuracy : 0.11349999904632568\n",
      "Epoch 86 - train_loss : 2.301171691219012 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301027202606201 and test_accuracy : 0.11349999904632568\n",
      "Epoch 87 - train_loss : 2.3011714200178783 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010272324085235 and test_accuracy : 0.11349999904632568\n",
      "Epoch 88 - train_loss : 2.3011714190244676 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010270297527313 and test_accuracy : 0.11349999904632568\n",
      "Epoch 89 - train_loss : 2.3011716296275457 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301027113199234 and test_accuracy : 0.11349999904632568\n",
      "Epoch 90 - train_loss : 2.3011713713407516 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301027053594589 and test_accuracy : 0.11349999904632568\n",
      "Epoch 91 - train_loss : 2.3011717746655145 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010270595550537 and test_accuracy : 0.11349999904632568\n",
      "Epoch 92 - train_loss : 2.301171330610911 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010271966457365 and test_accuracy : 0.11349999904632568\n",
      "Epoch 93 - train_loss : 2.301171573003133 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301027202606201 and test_accuracy : 0.11349999904632568\n",
      "Epoch 94 - train_loss : 2.301171811421712 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010272920131682 and test_accuracy : 0.11349999904632568\n",
      "Epoch 95 - train_loss : 2.301171472668648 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301027309894562 and test_accuracy : 0.11349999904632568\n",
      "Epoch 96 - train_loss : 2.301171506444613 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301027250289917 and test_accuracy : 0.11349999904632568\n",
      "Epoch 97 - train_loss : 2.3011714388926823 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301027238368988 and test_accuracy : 0.11349999904632568\n",
      "Epoch 98 - train_loss : 2.3011713176965714 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010271787643433 and test_accuracy : 0.11349999904632568\n",
      "Epoch 99 - train_loss : 2.301171390215556 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010271370410917 and test_accuracy : 0.11349999904632568\n",
      "Epoch 100 - train_loss : 2.3011716226736705 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010271430015563 and test_accuracy : 0.11349999904632568\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁▃██████████████████████████████████████</td></tr><tr><td>test_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▃██████████████████████████████████████</td></tr><tr><td>train_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.1135</td></tr><tr><td>test_loss</td><td>2.30103</td></tr><tr><td>train_accuracy</td><td>0.11237</td></tr><tr><td>train_loss</td><td>2.30117</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LeNet-1-SGD-vanilla-250-0.001-run</strong> at: <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/bnm9rqs4' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/bnm9rqs4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240307_235533-bnm9rqs4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/rkada/wandb/run-20240308_000313-k4jekdn1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/k4jekdn1' target=\"_blank\">LeNet-1-SGD-vanilla-500-0.01-run</a></strong> to <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/k4jekdn1' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/k4jekdn1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - train_loss : 2.308697197834651 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301096725463867 and test_accuracy : 0.11349999904632568\n",
      "Epoch 2 - train_loss : 2.3013347049554187 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301045060157776 and test_accuracy : 0.11349999904632568\n",
      "Epoch 3 - train_loss : 2.30129238764445 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301057493686676 and test_accuracy : 0.11349999904632568\n",
      "Epoch 4 - train_loss : 2.3013058483600615 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3009814381599427 and test_accuracy : 0.11349999904632568\n",
      "Epoch 5 - train_loss : 2.301332887013753 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010546922683717 and test_accuracy : 0.11349999904632568\n",
      "Epoch 6 - train_loss : 2.301280923684438 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301050865650177 and test_accuracy : 0.11349999904632568\n",
      "Epoch 00006: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 7 - train_loss : 2.301227682828903 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010313272476197 and test_accuracy : 0.11349999904632568\n",
      "Epoch 8 - train_loss : 2.301205126444499 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301017642021179 and test_accuracy : 0.11349999904632568\n",
      "Epoch 9 - train_loss : 2.3011938790480295 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010133028030397 and test_accuracy : 0.11349999904632568\n",
      "Epoch 10 - train_loss : 2.3011852820714314 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301013731956482 and test_accuracy : 0.11349999904632568\n",
      "Epoch 00010: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 11 - train_loss : 2.3011658668518065 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010135769844053 and test_accuracy : 0.11349999904632568\n",
      "Epoch 12 - train_loss : 2.301165572802226 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010134935379027 and test_accuracy : 0.11349999904632568\n",
      "Epoch 13 - train_loss : 2.3011650224526723 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301013398170471 and test_accuracy : 0.11349999904632568\n",
      "Epoch 14 - train_loss : 2.3011646727720896 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010133147239684 and test_accuracy : 0.11349999904632568\n",
      "Epoch 15 - train_loss : 2.301164283355077 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010133624076845 and test_accuracy : 0.11349999904632568\n",
      "Epoch 16 - train_loss : 2.3011641343434652 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010130643844606 and test_accuracy : 0.11349999904632568\n",
      "Epoch 17 - train_loss : 2.3011637727419534 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010129809379576 and test_accuracy : 0.11349999904632568\n",
      "Epoch 18 - train_loss : 2.301163544257482 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012933254242 and test_accuracy : 0.11349999904632568\n",
      "Epoch 19 - train_loss : 2.301163295904795 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.30101283788681 and test_accuracy : 0.11349999904632568\n",
      "Epoch 20 - train_loss : 2.3011629223823546 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012861728668 and test_accuracy : 0.11349999904632568\n",
      "Epoch 21 - train_loss : 2.3011628965536755 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.30101283788681 and test_accuracy : 0.11349999904632568\n",
      "Epoch 22 - train_loss : 2.3011625786622365 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010128498077393 and test_accuracy : 0.11349999904632568\n",
      "Epoch 23 - train_loss : 2.3011623124281564 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.30101283788681 and test_accuracy : 0.11349999904632568\n",
      "Epoch 24 - train_loss : 2.3011621137460074 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010128855705263 and test_accuracy : 0.11349999904632568\n",
      "Epoch 25 - train_loss : 2.3011619011561075 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010127544403076 and test_accuracy : 0.11349999904632568\n",
      "Epoch 26 - train_loss : 2.301161809762319 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010127782821654 and test_accuracy : 0.11349999904632568\n",
      "Epoch 27 - train_loss : 2.3011617143948873 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010128259658815 and test_accuracy : 0.11349999904632568\n",
      "Epoch 28 - train_loss : 2.301161317030589 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.30101283788681 and test_accuracy : 0.11349999904632568\n",
      "Epoch 29 - train_loss : 2.301161332925161 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010128259658815 and test_accuracy : 0.11349999904632568\n",
      "Epoch 30 - train_loss : 2.3011611024538676 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010128021240233 and test_accuracy : 0.11349999904632568\n",
      "Epoch 31 - train_loss : 2.301160963376363 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010127902030946 and test_accuracy : 0.11349999904632568\n",
      "Epoch 32 - train_loss : 2.301160830259323 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010128259658815 and test_accuracy : 0.11349999904632568\n",
      "Epoch 33 - train_loss : 2.3011608123779297 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.30101283788681 and test_accuracy : 0.11349999904632568\n",
      "Epoch 34 - train_loss : 2.301160717010498 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012945175171 and test_accuracy : 0.11349999904632568\n",
      "Epoch 35 - train_loss : 2.3011605819066365 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010129928588867 and test_accuracy : 0.11349999904632568\n",
      "Epoch 36 - train_loss : 2.301160401105881 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010130882263184 and test_accuracy : 0.11349999904632568\n",
      "Epoch 37 - train_loss : 2.301160277922948 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010129809379576 and test_accuracy : 0.11349999904632568\n",
      "Epoch 38 - train_loss : 2.3011604229609173 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010130286216737 and test_accuracy : 0.11349999904632568\n",
      "Epoch 39 - train_loss : 2.3011601944764455 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301013100147247 and test_accuracy : 0.11349999904632568\n",
      "Epoch 40 - train_loss : 2.3011601070562997 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010131478309632 and test_accuracy : 0.11349999904632568\n",
      "Epoch 41 - train_loss : 2.3011599739392596 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301013135910034 and test_accuracy : 0.11349999904632568\n",
      "Epoch 42 - train_loss : 2.301159997781118 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010132551193236 and test_accuracy : 0.11349999904632568\n",
      "Epoch 43 - train_loss : 2.301159977912903 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301013207435608 and test_accuracy : 0.11349999904632568\n",
      "Epoch 44 - train_loss : 2.301159890492757 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301013398170471 and test_accuracy : 0.11349999904632568\n",
      "Epoch 45 - train_loss : 2.3011595805486045 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010133147239684 and test_accuracy : 0.11349999904632568\n",
      "Epoch 46 - train_loss : 2.3011595209439597 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010135531425475 and test_accuracy : 0.11349999904632568\n",
      "Epoch 47 - train_loss : 2.301159648100535 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010134220123293 and test_accuracy : 0.11349999904632568\n",
      "Epoch 48 - train_loss : 2.30115966796875 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010135769844053 and test_accuracy : 0.11349999904632568\n",
      "Epoch 49 - train_loss : 2.301159644126892 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010136008262636 and test_accuracy : 0.11349999904632568\n",
      "Epoch 50 - train_loss : 2.3011594116687775 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010136127471923 and test_accuracy : 0.11349999904632568\n",
      "Epoch 51 - train_loss : 2.3011593759059905 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301013684272766 and test_accuracy : 0.11349999904632568\n",
      "Epoch 52 - train_loss : 2.3011592884858447 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301013696193695 and test_accuracy : 0.11349999904632568\n",
      "Epoch 53 - train_loss : 2.301159373919169 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301013743877411 and test_accuracy : 0.11349999904632568\n",
      "Epoch 54 - train_loss : 2.301159300406774 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010138034820558 and test_accuracy : 0.11349999904632568\n",
      "Epoch 55 - train_loss : 2.3011592984199525 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301013779640198 and test_accuracy : 0.11349999904632568\n",
      "Epoch 56 - train_loss : 2.301159425576528 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010139226913453 and test_accuracy : 0.11349999904632568\n",
      "Epoch 57 - train_loss : 2.301159256696701 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301014006137848 and test_accuracy : 0.11349999904632568\n",
      "Epoch 58 - train_loss : 2.3011591037114463 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301013970375061 and test_accuracy : 0.11349999904632568\n",
      "Epoch 59 - train_loss : 2.3011592427889505 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010140538215635 and test_accuracy : 0.11349999904632568\n",
      "Epoch 60 - train_loss : 2.30115913550059 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010140299797057 and test_accuracy : 0.11349999904632568\n",
      "Epoch 61 - train_loss : 2.3011590520540874 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010141372680666 and test_accuracy : 0.11349999904632568\n",
      "Epoch 62 - train_loss : 2.3011590341726937 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301014173030853 and test_accuracy : 0.11349999904632568\n",
      "Epoch 63 - train_loss : 2.301159131526947 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301014232635498 and test_accuracy : 0.11349999904632568\n",
      "Epoch 64 - train_loss : 2.3011590083440145 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010141968727114 and test_accuracy : 0.11349999904632568\n",
      "Epoch 65 - train_loss : 2.3011588752269745 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010142922401426 and test_accuracy : 0.11349999904632568\n",
      "Epoch 66 - train_loss : 2.301158966620763 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301014220714569 and test_accuracy : 0.11349999904632568\n",
      "Epoch 67 - train_loss : 2.301159014304479 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301014232635498 and test_accuracy : 0.11349999904632568\n",
      "Epoch 68 - train_loss : 2.3011589030424755 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301014280319214 and test_accuracy : 0.11349999904632568\n",
      "Epoch 69 - train_loss : 2.301158833503723 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010142922401426 and test_accuracy : 0.11349999904632568\n",
      "Epoch 70 - train_loss : 2.3011589845021567 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010144233703613 and test_accuracy : 0.11349999904632568\n",
      "Epoch 71 - train_loss : 2.3011589109897614 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010142922401426 and test_accuracy : 0.11349999904632568\n",
      "Epoch 72 - train_loss : 2.3011589109897614 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010143876075744 and test_accuracy : 0.11349999904632568\n",
      "Epoch 73 - train_loss : 2.3011587778727214 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301014471054077 and test_accuracy : 0.11349999904632568\n",
      "Epoch 74 - train_loss : 2.301158686478933 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301014542579651 and test_accuracy : 0.11349999904632568\n",
      "Epoch 75 - train_loss : 2.3011588672796885 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301014542579651 and test_accuracy : 0.11349999904632568\n",
      "Epoch 76 - train_loss : 2.301158763964971 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301014614105225 and test_accuracy : 0.11349999904632568\n",
      "Epoch 77 - train_loss : 2.3011587103207907 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010146617889404 and test_accuracy : 0.11349999904632568\n",
      "Epoch 78 - train_loss : 2.3011589070161182 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301014709472656 and test_accuracy : 0.11349999904632568\n",
      "Epoch 79 - train_loss : 2.3011587103207907 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301014769077301 and test_accuracy : 0.11349999904632568\n",
      "Epoch 80 - train_loss : 2.301158724228541 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301014721393585 and test_accuracy : 0.11349999904632568\n",
      "Epoch 81 - train_loss : 2.301158728202184 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301014792919159 and test_accuracy : 0.11349999904632568\n",
      "Epoch 82 - train_loss : 2.301158668597539 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301014709472656 and test_accuracy : 0.11349999904632568\n",
      "Epoch 83 - train_loss : 2.30115869641304 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010148286819456 and test_accuracy : 0.11349999904632568\n",
      "Epoch 84 - train_loss : 2.301158692439397 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010148406028748 and test_accuracy : 0.11349999904632568\n",
      "Epoch 85 - train_loss : 2.301158692439397 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301014816761017 and test_accuracy : 0.11349999904632568\n",
      "Epoch 86 - train_loss : 2.301158676544825 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301014947891235 and test_accuracy : 0.11349999904632568\n",
      "Epoch 87 - train_loss : 2.301158817609151 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.30101500749588 and test_accuracy : 0.11349999904632568\n",
      "Epoch 88 - train_loss : 2.301158658663432 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010149955749513 and test_accuracy : 0.11349999904632568\n",
      "Epoch 89 - train_loss : 2.3011585513750714 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301014947891235 and test_accuracy : 0.11349999904632568\n",
      "Epoch 90 - train_loss : 2.3011587500572204 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301015031337738 and test_accuracy : 0.11349999904632568\n",
      "Epoch 91 - train_loss : 2.3011585394541423 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010149955749513 and test_accuracy : 0.11349999904632568\n",
      "Epoch 92 - train_loss : 2.3011584917704266 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301015055179596 and test_accuracy : 0.11349999904632568\n",
      "Epoch 93 - train_loss : 2.3011585772037506 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010151982307434 and test_accuracy : 0.11349999904632568\n",
      "Epoch 94 - train_loss : 2.3011586546897886 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010151028633117 and test_accuracy : 0.11349999904632568\n",
      "Epoch 95 - train_loss : 2.301158465941747 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301015079021454 and test_accuracy : 0.11349999904632568\n",
      "Epoch 96 - train_loss : 2.3011584877967834 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010151982307434 and test_accuracy : 0.11349999904632568\n",
      "Epoch 97 - train_loss : 2.3011585474014282 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010151982307434 and test_accuracy : 0.11349999904632568\n",
      "Epoch 98 - train_loss : 2.301158571243286 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301015257835388 and test_accuracy : 0.11349999904632568\n",
      "Epoch 99 - train_loss : 2.301158632834752 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301015257835388 and test_accuracy : 0.11349999904632568\n",
      "Epoch 100 - train_loss : 2.301158527533213 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010152697563173 and test_accuracy : 0.11349999904632568\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_loss</td><td>█▅▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.1135</td></tr><tr><td>test_loss</td><td>2.30102</td></tr><tr><td>train_accuracy</td><td>0.11237</td></tr><tr><td>train_loss</td><td>2.30116</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LeNet-1-SGD-vanilla-500-0.01-run</strong> at: <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/k4jekdn1' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/k4jekdn1</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240308_000313-k4jekdn1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/rkada/wandb/run-20240308_001029-wmnabtst</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/wmnabtst' target=\"_blank\">LeNet-1-SGD-vanilla-500-0.001-run</a></strong> to <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/wmnabtst' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/wmnabtst</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - train_loss : 2.3328197836875915 and train_accuracy : 0.09915000200271606\n",
      "Evaluation : test_loss : 2.325522947311401 and test_accuracy : 0.10089999437332153\n",
      "Epoch 2 - train_loss : 2.3196940938631694 and train_accuracy : 0.09915000200271606\n",
      "Evaluation : test_loss : 2.315490388870239 and test_accuracy : 0.10089999437332153\n",
      "Epoch 3 - train_loss : 2.3119825581709543 and train_accuracy : 0.09915000200271606\n",
      "Evaluation : test_loss : 2.3095514297485353 and test_accuracy : 0.10089999437332153\n",
      "Epoch 4 - train_loss : 2.307466506958008 and train_accuracy : 0.09915000200271606\n",
      "Evaluation : test_loss : 2.306076264381409 and test_accuracy : 0.10089999437332153\n",
      "Epoch 5 - train_loss : 2.304823424418767 and train_accuracy : 0.09915000200271606\n",
      "Evaluation : test_loss : 2.3040059089660643 and test_accuracy : 0.10089999437332153\n",
      "Epoch 6 - train_loss : 2.3032842457294462 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3028013467788697 and test_accuracy : 0.11349999904632568\n",
      "Epoch 7 - train_loss : 2.3023947258790334 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3020864367485045 and test_accuracy : 0.11349999904632568\n",
      "Epoch 8 - train_loss : 2.3018756985664366 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3016603112220766 and test_accuracy : 0.11349999904632568\n",
      "Epoch 9 - train_loss : 2.301575320959091 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301408791542053 and test_accuracy : 0.11349999904632568\n",
      "Epoch 10 - train_loss : 2.3014017422993978 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3012579441070558 and test_accuracy : 0.11349999904632568\n",
      "Epoch 11 - train_loss : 2.3013021727403005 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301164376735687 and test_accuracy : 0.11349999904632568\n",
      "Epoch 12 - train_loss : 2.3012467602888744 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3011080503463743 and test_accuracy : 0.11349999904632568\n",
      "Epoch 13 - train_loss : 2.3012128591537477 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010736107826233 and test_accuracy : 0.11349999904632568\n",
      "Epoch 14 - train_loss : 2.3011934916178385 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010527372360228 and test_accuracy : 0.11349999904632568\n",
      "Epoch 15 - train_loss : 2.3011815508206683 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010406374931334 and test_accuracy : 0.11349999904632568\n",
      "Epoch 00015: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 16 - train_loss : 2.3011600097020466 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010395050048826 and test_accuracy : 0.11349999904632568\n",
      "Epoch 17 - train_loss : 2.301159205039342 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301038360595703 and test_accuracy : 0.11349999904632568\n",
      "Epoch 18 - train_loss : 2.3011587540308636 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010372519493103 and test_accuracy : 0.11349999904632568\n",
      "Epoch 19 - train_loss : 2.3011581718921663 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301036310195923 and test_accuracy : 0.11349999904632568\n",
      "Epoch 20 - train_loss : 2.301157534122467 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010353207588197 and test_accuracy : 0.11349999904632568\n",
      "Epoch 21 - train_loss : 2.301157236099243 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010343313217163 and test_accuracy : 0.11349999904632568\n",
      "Epoch 22 - train_loss : 2.30115660627683 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301033341884613 and test_accuracy : 0.11349999904632568\n",
      "Epoch 23 - train_loss : 2.3011562625567117 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010324001312257 and test_accuracy : 0.11349999904632568\n",
      "Epoch 24 - train_loss : 2.301155823469162 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010315895080566 and test_accuracy : 0.11349999904632568\n",
      "Epoch 25 - train_loss : 2.301155396302541 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010308742523193 and test_accuracy : 0.11349999904632568\n",
      "Epoch 26 - train_loss : 2.301155134042104 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010299444198608 and test_accuracy : 0.11349999904632568\n",
      "Epoch 27 - train_loss : 2.3011547247568767 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010292530059813 and test_accuracy : 0.11349999904632568\n",
      "Epoch 28 - train_loss : 2.3011545797189075 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301028478145599 and test_accuracy : 0.11349999904632568\n",
      "Epoch 29 - train_loss : 2.30115402340889 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301027750968933 and test_accuracy : 0.11349999904632568\n",
      "Epoch 30 - train_loss : 2.3011537353197733 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010270833969115 and test_accuracy : 0.11349999904632568\n",
      "Epoch 31 - train_loss : 2.301153568426768 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.30102653503418 and test_accuracy : 0.11349999904632568\n",
      "Epoch 32 - train_loss : 2.301153071721395 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010258197784426 and test_accuracy : 0.11349999904632568\n",
      "Epoch 33 - train_loss : 2.3011528849601746 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010252594947813 and test_accuracy : 0.11349999904632568\n",
      "Epoch 34 - train_loss : 2.301152459780375 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301024651527405 and test_accuracy : 0.11349999904632568\n",
      "Epoch 35 - train_loss : 2.301152555147807 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010241746902467 and test_accuracy : 0.11349999904632568\n",
      "Epoch 36 - train_loss : 2.3011523485183716 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010234475135802 and test_accuracy : 0.11349999904632568\n",
      "Epoch 37 - train_loss : 2.3011521140734357 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301022982597351 and test_accuracy : 0.11349999904632568\n",
      "Epoch 38 - train_loss : 2.301151857773463 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010226130485534 and test_accuracy : 0.11349999904632568\n",
      "Epoch 39 - train_loss : 2.3011516451835634 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010220646858217 and test_accuracy : 0.11349999904632568\n",
      "Epoch 40 - train_loss : 2.301151500145594 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301021695137024 and test_accuracy : 0.11349999904632568\n",
      "Epoch 41 - train_loss : 2.3011513630549114 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301021134853363 and test_accuracy : 0.11349999904632568\n",
      "Epoch 42 - train_loss : 2.30115114847819 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010207295417784 and test_accuracy : 0.11349999904632568\n",
      "Epoch 43 - train_loss : 2.3011507729689282 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010203361511232 and test_accuracy : 0.11349999904632568\n",
      "Epoch 44 - train_loss : 2.301150937875112 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010199546813963 and test_accuracy : 0.11349999904632568\n",
      "Epoch 45 - train_loss : 2.3011506756146747 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.30101957321167 and test_accuracy : 0.11349999904632568\n",
      "Epoch 46 - train_loss : 2.301150538523992 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010191559791564 and test_accuracy : 0.11349999904632568\n",
      "Epoch 47 - train_loss : 2.301150453090668 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010188817977903 and test_accuracy : 0.11349999904632568\n",
      "Epoch 48 - train_loss : 2.30115021665891 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010184526443482 and test_accuracy : 0.11349999904632568\n",
      "Epoch 49 - train_loss : 2.3011501292387644 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010180473327635 and test_accuracy : 0.11349999904632568\n",
      "Epoch 50 - train_loss : 2.3011503259340924 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010178446769713 and test_accuracy : 0.11349999904632568\n",
      "Epoch 51 - train_loss : 2.301149974266688 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010174870491027 and test_accuracy : 0.11349999904632568\n",
      "Epoch 52 - train_loss : 2.30114987095197 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301017153263092 and test_accuracy : 0.11349999904632568\n",
      "Epoch 53 - train_loss : 2.3011498788992566 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301016902923584 and test_accuracy : 0.11349999904632568\n",
      "Epoch 54 - train_loss : 2.301149543126424 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010165095329285 and test_accuracy : 0.11349999904632568\n",
      "Epoch 55 - train_loss : 2.3011495530605317 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301016402244568 and test_accuracy : 0.11349999904632568\n",
      "Epoch 56 - train_loss : 2.3011495729287463 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301016092300415 and test_accuracy : 0.11349999904632568\n",
      "Epoch 57 - train_loss : 2.301149501403173 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010158061981203 and test_accuracy : 0.11349999904632568\n",
      "Epoch 58 - train_loss : 2.3011495729287463 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301015555858612 and test_accuracy : 0.11349999904632568\n",
      "Epoch 59 - train_loss : 2.3011492530504865 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301015305519104 and test_accuracy : 0.11349999904632568\n",
      "Epoch 60 - train_loss : 2.3011492431163787 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010151028633117 and test_accuracy : 0.11349999904632568\n",
      "Epoch 61 - train_loss : 2.3011493563652037 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010149121284487 and test_accuracy : 0.11349999904632568\n",
      "Epoch 62 - train_loss : 2.3011491934458417 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010146379470826 and test_accuracy : 0.11349999904632568\n",
      "Epoch 63 - train_loss : 2.301149090131124 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010143876075744 and test_accuracy : 0.11349999904632568\n",
      "Epoch 64 - train_loss : 2.301149133841197 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010142922401426 and test_accuracy : 0.11349999904632568\n",
      "Epoch 65 - train_loss : 2.301148984829585 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301014077663422 and test_accuracy : 0.11349999904632568\n",
      "Epoch 66 - train_loss : 2.3011491040388745 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301013875007629 and test_accuracy : 0.11349999904632568\n",
      "Epoch 67 - train_loss : 2.3011488735675814 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301013731956482 and test_accuracy : 0.11349999904632568\n",
      "Epoch 68 - train_loss : 2.3011488397916158 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301013505458832 and test_accuracy : 0.11349999904632568\n",
      "Epoch 69 - train_loss : 2.301148937145869 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010133266448975 and test_accuracy : 0.11349999904632568\n",
      "Epoch 70 - train_loss : 2.301148808002472 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.30101318359375 and test_accuracy : 0.11349999904632568\n",
      "Epoch 71 - train_loss : 2.301148895422618 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010130405426024 and test_accuracy : 0.11349999904632568\n",
      "Epoch 72 - train_loss : 2.301148849725723 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012933254242 and test_accuracy : 0.11349999904632568\n",
      "Epoch 73 - train_loss : 2.3011486728986106 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010128140449524 and test_accuracy : 0.11349999904632568\n",
      "Epoch 74 - train_loss : 2.3011486808458965 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010125160217285 and test_accuracy : 0.11349999904632568\n",
      "Epoch 75 - train_loss : 2.3011484762032826 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301012468338013 and test_accuracy : 0.11349999904632568\n",
      "Epoch 76 - train_loss : 2.3011488457520803 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010123014450072 and test_accuracy : 0.11349999904632568\n",
      "Epoch 77 - train_loss : 2.3011487762133283 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010122299194338 and test_accuracy : 0.11349999904632568\n",
      "Epoch 78 - train_loss : 2.3011484583218893 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.30101215839386 and test_accuracy : 0.11349999904632568\n",
      "Epoch 79 - train_loss : 2.3011487166086835 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301011872291565 and test_accuracy : 0.11349999904632568\n",
      "Epoch 80 - train_loss : 2.3011486768722533 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010118126869203 and test_accuracy : 0.11349999904632568\n",
      "Epoch 81 - train_loss : 2.301148533821106 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301011693477631 and test_accuracy : 0.11349999904632568\n",
      "Epoch 82 - train_loss : 2.301148404677709 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010116457939147 and test_accuracy : 0.11349999904632568\n",
      "Epoch 83 - train_loss : 2.3011485238869986 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010114789009095 and test_accuracy : 0.11349999904632568\n",
      "Epoch 84 - train_loss : 2.301148410638173 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010114073753356 and test_accuracy : 0.11349999904632568\n",
      "Epoch 85 - train_loss : 2.3011485159397127 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301011347770691 and test_accuracy : 0.11349999904632568\n",
      "Epoch 86 - train_loss : 2.3011485556761424 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010112047195435 and test_accuracy : 0.11349999904632568\n",
      "Epoch 87 - train_loss : 2.3011484424273174 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301011061668396 and test_accuracy : 0.11349999904632568\n",
      "Epoch 88 - train_loss : 2.301148396730423 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301011097431183 and test_accuracy : 0.11349999904632568\n",
      "Epoch 89 - train_loss : 2.301148490111033 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301010847091675 and test_accuracy : 0.11349999904632568\n",
      "Epoch 90 - train_loss : 2.3011483709017435 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301010847091675 and test_accuracy : 0.11349999904632568\n",
      "Epoch 91 - train_loss : 2.3011484066645305 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.30101078748703 and test_accuracy : 0.11349999904632568\n",
      "Epoch 92 - train_loss : 2.3011484503746034 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010106682777405 and test_accuracy : 0.11349999904632568\n",
      "Epoch 93 - train_loss : 2.301148372888565 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301010549068451 and test_accuracy : 0.11349999904632568\n",
      "Epoch 94 - train_loss : 2.3011482298374175 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301010477542877 and test_accuracy : 0.11349999904632568\n",
      "Epoch 95 - train_loss : 2.3011484225591023 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301010346412659 and test_accuracy : 0.11349999904632568\n",
      "Epoch 96 - train_loss : 2.301148384809494 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301010346412659 and test_accuracy : 0.11349999904632568\n",
      "Epoch 97 - train_loss : 2.301148209969203 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.301010322570801 and test_accuracy : 0.11349999904632568\n",
      "Epoch 98 - train_loss : 2.301148315270742 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.30101021528244 and test_accuracy : 0.11349999904632568\n",
      "Epoch 99 - train_loss : 2.3011483788490295 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010101199150084 and test_accuracy : 0.11349999904632568\n",
      "Epoch 100 - train_loss : 2.3011481881141664 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.3010100960731505 and test_accuracy : 0.11349999904632568\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁▁██████████████████████████████████████</td></tr><tr><td>test_loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁██████████████████████████████████████</td></tr><tr><td>train_loss</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.1135</td></tr><tr><td>test_loss</td><td>2.30101</td></tr><tr><td>train_accuracy</td><td>0.11237</td></tr><tr><td>train_loss</td><td>2.30115</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LeNet-1-SGD-vanilla-500-0.001-run</strong> at: <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/wmnabtst' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/wmnabtst</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240308_001029-wmnabtst/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for optim_hp in optimizer_choices:\n",
    "    for batch_hp in batch_sizes:\n",
    "        for lr_hp in learning_rate:\n",
    "            model = LeNet()\n",
    "            model = model.to(device)\n",
    "\n",
    "            train_loader = DataLoader(train_set,batch_size=batch_hp,shuffle=True,num_workers=8)\n",
    "            test_loader = DataLoader(test_set,batch_size=batch_hp,shuffle=True,num_workers=8)\n",
    "            train_test_kit = train_test(model = model , train_loader = train_loader, test_loader = test_loader ,project_name=\"CV-assignment-2\",run_name=f\"LeNet-1-{optim_hp}-{batch_hp}-{lr_hp}-run\",lr = lr_hp,optimizer=optim_hp,iswandb=1)\n",
    "            train_test_kit.train(num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison\n",
    "It is clear from the findings that the Best CNN Model performs better than the Best SIFT-SVM BoVW Model. This is because, whereas the CNN Model offers accuracy of 98.82% on test set, the SIFT Model only offers us appx 65% accuracy on test set. SIFT Detector and Descriptor is not able to capture the localised features in any given region of the image to the same extent as the CNN based Model because convolution operators with different Kernels with the entire image are able to capture the various localised regions in the image because of varied intensities and RGB values of different pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If conv layers get doubled !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet_adv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet_adv,self).__init__()\n",
    "        self.conv_layer_1 = nn.Conv2d(in_channels=1,out_channels=6,kernel_size=(5,5),padding=2)\n",
    "        self.conv_layer_1_repeated = nn.Conv2d(in_channels=6,out_channels=6,kernel_size=(5,5),padding=2)\n",
    "        \n",
    "        self.avg_pool_layer = nn.AvgPool2d(kernel_size=(2,2),stride=2) \n",
    "        self.conv_layer_2 = nn.Conv2d(in_channels=6,out_channels=16,kernel_size=(5,5),padding=0)\n",
    "        self.conv_layer_2_repeated = nn.Conv2d(in_channels=16,out_channels=16,kernel_size=(5,5),padding=2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(400,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "\n",
    "    def forward(self,input):\n",
    "      \n",
    "        output = torch.sigmoid(self.conv_layer_1(input))\n",
    "        output = torch.sigmoid(self.conv_layer_1_repeated(output))\n",
    "        \n",
    "        output = self.avg_pool_layer(output)\n",
    "        \n",
    "        output = torch.sigmoid(self.conv_layer_2(output))\n",
    "        output = torch.sigmoid(self.conv_layer_2_repeated(output))\n",
    "        \n",
    "        output = self.avg_pool_layer(output)\n",
    "        \n",
    "        output = output.view(-1,16*5*5)\n",
    "        output = torch.sigmoid(self.fc1(output))\n",
    "        output = torch.sigmoid(self.fc2(output))\n",
    "        output = self.fc3(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/rkada/wandb/run-20240308_083951-79hjkym3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/79hjkym3' target=\"_blank\">LeNet-1-double-CNlayer-run</a></strong> to <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/79hjkym3' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/79hjkym3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - train_loss : 2.3033474326133727 and train_accuracy : 0.11236666887998581\n",
      "Evaluation : test_loss : 2.302087390422821 and test_accuracy : 0.11349999904632568\n",
      "Epoch 2 - train_loss : 2.064785972237587 and train_accuracy : 0.5425000190734863\n",
      "Evaluation : test_loss : 1.4864380717277528 and test_accuracy : 0.5467000007629395\n",
      "Epoch 3 - train_loss : 1.0740616222222645 and train_accuracy : 0.7470333576202393\n",
      "Evaluation : test_loss : 0.7959192514419555 and test_accuracy : 0.7526999711990356\n",
      "Epoch 4 - train_loss : 0.6503109201788903 and train_accuracy : 0.8299000263214111\n",
      "Evaluation : test_loss : 0.5160939484834671 and test_accuracy : 0.8323999643325806\n",
      "Epoch 5 - train_loss : 0.4501268150905768 and train_accuracy : 0.8880167007446289\n",
      "Evaluation : test_loss : 0.37302061915397644 and test_accuracy : 0.8901000022888184\n",
      "Epoch 6 - train_loss : 0.3362951340774695 and train_accuracy : 0.9161166548728943\n",
      "Evaluation : test_loss : 0.28417338952422144 and test_accuracy : 0.9138000011444092\n",
      "Epoch 7 - train_loss : 0.2593327527244886 and train_accuracy : 0.9353333711624146\n",
      "Evaluation : test_loss : 0.21958323270082475 and test_accuracy : 0.9350000023841858\n",
      "Epoch 8 - train_loss : 0.2030936139325301 and train_accuracy : 0.9466166496276855\n",
      "Evaluation : test_loss : 0.1805022418498993 and test_accuracy : 0.9456999897956848\n",
      "Epoch 9 - train_loss : 0.16782064021875462 and train_accuracy : 0.9576333165168762\n",
      "Evaluation : test_loss : 0.14213751964271068 and test_accuracy : 0.9583999514579773\n",
      "Epoch 10 - train_loss : 0.13814563217262427 and train_accuracy : 0.9637166857719421\n",
      "Evaluation : test_loss : 0.12151637561619281 and test_accuracy : 0.9644999504089355\n",
      "Epoch 11 - train_loss : 0.11940209902822971 and train_accuracy : 0.968416690826416\n",
      "Evaluation : test_loss : 0.10846653878688813 and test_accuracy : 0.965999960899353\n",
      "Epoch 12 - train_loss : 0.10547327535847822 and train_accuracy : 0.971916675567627\n",
      "Evaluation : test_loss : 0.09332822896540165 and test_accuracy : 0.9724999666213989\n",
      "Epoch 13 - train_loss : 0.09455137876793743 and train_accuracy : 0.9739500284194946\n",
      "Evaluation : test_loss : 0.08802010323852301 and test_accuracy : 0.973099946975708\n",
      "Epoch 14 - train_loss : 0.08496881422276298 and train_accuracy : 0.9760833382606506\n",
      "Evaluation : test_loss : 0.08001879248768091 and test_accuracy : 0.9761999845504761\n",
      "Epoch 15 - train_loss : 0.0789484855098029 and train_accuracy : 0.9786333441734314\n",
      "Evaluation : test_loss : 0.07321002166718245 and test_accuracy : 0.9779999852180481\n",
      "Epoch 16 - train_loss : 0.07289088073497017 and train_accuracy : 0.9805833697319031\n",
      "Evaluation : test_loss : 0.0661824069917202 and test_accuracy : 0.9794999957084656\n",
      "Epoch 17 - train_loss : 0.0687434248936673 and train_accuracy : 0.9804166555404663\n",
      "Evaluation : test_loss : 0.06334215626120568 and test_accuracy : 0.9799000024795532\n",
      "Epoch 18 - train_loss : 0.06428779480047524 and train_accuracy : 0.9824666976928711\n",
      "Evaluation : test_loss : 0.060994038730859755 and test_accuracy : 0.9817999601364136\n",
      "Epoch 19 - train_loss : 0.06015952027713259 and train_accuracy : 0.9839500188827515\n",
      "Evaluation : test_loss : 0.05462764278054237 and test_accuracy : 0.9828999638557434\n",
      "Epoch 20 - train_loss : 0.05688401351993282 and train_accuracy : 0.9849666953086853\n",
      "Evaluation : test_loss : 0.05279168039560318 and test_accuracy : 0.9836999773979187\n",
      "Epoch 21 - train_loss : 0.05410334337502718 and train_accuracy : 0.9842666983604431\n",
      "Evaluation : test_loss : 0.05340587794780731 and test_accuracy : 0.983199954032898\n",
      "Epoch 22 - train_loss : 0.051568035315722224 and train_accuracy : 0.9861833453178406\n",
      "Evaluation : test_loss : 0.04859250821173191 and test_accuracy : 0.9850999712944031\n",
      "Epoch 23 - train_loss : 0.048539689447109895 and train_accuracy : 0.986383318901062\n",
      "Evaluation : test_loss : 0.049307366088032725 and test_accuracy : 0.9855999946594238\n",
      "Epoch 24 - train_loss : 0.04604293840626875 and train_accuracy : 0.9880833625793457\n",
      "Evaluation : test_loss : 0.04367419127374887 and test_accuracy : 0.9868999719619751\n",
      "Epoch 25 - train_loss : 0.04491775925271213 and train_accuracy : 0.987250030040741\n",
      "Evaluation : test_loss : 0.0455636347644031 and test_accuracy : 0.9860999584197998\n",
      "Epoch 26 - train_loss : 0.04202562559706469 and train_accuracy : 0.9885666966438293\n",
      "Evaluation : test_loss : 0.04068575487472117 and test_accuracy : 0.9878000020980835\n",
      "Epoch 27 - train_loss : 0.040645001898519696 and train_accuracy : 0.9896500110626221\n",
      "Evaluation : test_loss : 0.04212723048403859 and test_accuracy : 0.9871999621391296\n",
      "Epoch 28 - train_loss : 0.0381092751553903 and train_accuracy : 0.9897500276565552\n",
      "Evaluation : test_loss : 0.04024163316935301 and test_accuracy : 0.9881999492645264\n",
      "Epoch 29 - train_loss : 0.036647810996510086 and train_accuracy : 0.9905000329017639\n",
      "Evaluation : test_loss : 0.039992090314626694 and test_accuracy : 0.9883999824523926\n",
      "Epoch 30 - train_loss : 0.034788225024628146 and train_accuracy : 0.9906833171844482\n",
      "Evaluation : test_loss : 0.03798516532406211 and test_accuracy : 0.9878999590873718\n",
      "Epoch 31 - train_loss : 0.032640612521208826 and train_accuracy : 0.9912999868392944\n",
      "Evaluation : test_loss : 0.03789602974429727 and test_accuracy : 0.9886999726295471\n",
      "Epoch 32 - train_loss : 0.032601769912677506 and train_accuracy : 0.9912166595458984\n",
      "Evaluation : test_loss : 0.039512216299772265 and test_accuracy : 0.9881999492645264\n",
      "Epoch 33 - train_loss : 0.03118067542867114 and train_accuracy : 0.9917833209037781\n",
      "Evaluation : test_loss : 0.03804817171767354 and test_accuracy : 0.988099992275238\n",
      "Epoch 34 - train_loss : 0.030321808027413983 and train_accuracy : 0.9918833374977112\n",
      "Evaluation : test_loss : 0.03779147076420486 and test_accuracy : 0.988599956035614\n",
      "Epoch 35 - train_loss : 0.028475355333648623 and train_accuracy : 0.9919666647911072\n",
      "Evaluation : test_loss : 0.03633550088852644 and test_accuracy : 0.988099992275238\n",
      "Epoch 36 - train_loss : 0.027898536475064854 and train_accuracy : 0.992983341217041\n",
      "Evaluation : test_loss : 0.034911516262218355 and test_accuracy : 0.9891999959945679\n",
      "Epoch 37 - train_loss : 0.027072479490501185 and train_accuracy : 0.9931333661079407\n",
      "Evaluation : test_loss : 0.034700768627226354 and test_accuracy : 0.9891999959945679\n",
      "Epoch 38 - train_loss : 0.026103012395712236 and train_accuracy : 0.9936333298683167\n",
      "Evaluation : test_loss : 0.03352401610463858 and test_accuracy : 0.9896000027656555\n",
      "Epoch 39 - train_loss : 0.02450535449121768 and train_accuracy : 0.992650032043457\n",
      "Evaluation : test_loss : 0.03622496882453561 and test_accuracy : 0.988599956035614\n",
      "Epoch 40 - train_loss : 0.024671171062315502 and train_accuracy : 0.9937166571617126\n",
      "Evaluation : test_loss : 0.03385339081287384 and test_accuracy : 0.990399956703186\n",
      "Epoch 41 - train_loss : 0.023760317933435242 and train_accuracy : 0.9940833449363708\n",
      "Evaluation : test_loss : 0.03334855851717293 and test_accuracy : 0.9896000027656555\n",
      "Epoch 42 - train_loss : 0.021903884872638932 and train_accuracy : 0.9943833351135254\n",
      "Evaluation : test_loss : 0.03390170889906585 and test_accuracy : 0.9899999499320984\n",
      "Epoch 43 - train_loss : 0.02129738563283657 and train_accuracy : 0.994350016117096\n",
      "Evaluation : test_loss : 0.03333944617770612 and test_accuracy : 0.9898999929428101\n",
      "Epoch 44 - train_loss : 0.020584840428394577 and train_accuracy : 0.9942333698272705\n",
      "Evaluation : test_loss : 0.03326810486614704 and test_accuracy : 0.9894999861717224\n",
      "Epoch 45 - train_loss : 0.02010483673075214 and train_accuracy : 0.9946500062942505\n",
      "Evaluation : test_loss : 0.03418191552627832 and test_accuracy : 0.989799976348877\n",
      "Epoch 46 - train_loss : 0.019527002920707068 and train_accuracy : 0.9939833283424377\n",
      "Evaluation : test_loss : 0.03431787574663758 and test_accuracy : 0.9900999665260315\n",
      "Epoch 47 - train_loss : 0.01931048691816007 and train_accuracy : 0.9949666857719421\n",
      "Evaluation : test_loss : 0.03444972699508071 and test_accuracy : 0.9893999695777893\n",
      "Epoch 48 - train_loss : 0.018845107460704943 and train_accuracy : 0.9947167038917542\n",
      "Evaluation : test_loss : 0.03609915382694453 and test_accuracy : 0.9896000027656555\n",
      "Epoch 49 - train_loss : 0.018354676283585527 and train_accuracy : 0.9961000084877014\n",
      "Evaluation : test_loss : 0.03149032830260694 and test_accuracy : 0.9904999732971191\n",
      "Epoch 50 - train_loss : 0.016514544514939188 and train_accuracy : 0.996150016784668\n",
      "Evaluation : test_loss : 0.034266714844852685 and test_accuracy : 0.9894999861717224\n",
      "Epoch 51 - train_loss : 0.016007403652959815 and train_accuracy : 0.9946666955947876\n",
      "Evaluation : test_loss : 0.03704044921323657 and test_accuracy : 0.988599956035614\n",
      "Epoch 52 - train_loss : 0.016172208823263645 and train_accuracy : 0.9955000281333923\n",
      "Evaluation : test_loss : 0.03436093204654753 and test_accuracy : 0.9891999959945679\n",
      "Epoch 53 - train_loss : 0.015427056771780674 and train_accuracy : 0.9955333471298218\n",
      "Evaluation : test_loss : 0.03494272488169372 and test_accuracy : 0.9901999831199646\n",
      "Epoch 54 - train_loss : 0.014588185696629808 and train_accuracy : 0.9964166879653931\n",
      "Evaluation : test_loss : 0.03148164195008576 and test_accuracy : 0.9898999929428101\n",
      "Epoch 55 - train_loss : 0.013949157710885628 and train_accuracy : 0.99631667137146\n",
      "Evaluation : test_loss : 0.03291161903180182 and test_accuracy : 0.9904999732971191\n",
      "Epoch 56 - train_loss : 0.013142554871349906 and train_accuracy : 0.9973666667938232\n",
      "Evaluation : test_loss : 0.03158998917788267 and test_accuracy : 0.9901999831199646\n",
      "Epoch 57 - train_loss : 0.014429539143263052 and train_accuracy : 0.9969666600227356\n",
      "Evaluation : test_loss : 0.032217934168875216 and test_accuracy : 0.9901999831199646\n",
      "Epoch 58 - train_loss : 0.012808673954956854 and train_accuracy : 0.9971666932106018\n",
      "Evaluation : test_loss : 0.03255750816315413 and test_accuracy : 0.9893999695777893\n",
      "Epoch 59 - train_loss : 0.012295352537573004 and train_accuracy : 0.9970166683197021\n",
      "Evaluation : test_loss : 0.03443676577880979 and test_accuracy : 0.989799976348877\n",
      "Epoch 60 - train_loss : 0.011458110820967704 and train_accuracy : 0.9971166849136353\n",
      "Evaluation : test_loss : 0.032238860987126826 and test_accuracy : 0.9901999831199646\n",
      "Epoch 61 - train_loss : 0.011110571451717987 and train_accuracy : 0.9976166486740112\n",
      "Evaluation : test_loss : 0.03254299513064325 and test_accuracy : 0.9906999468803406\n",
      "Epoch 62 - train_loss : 0.010956836171681061 and train_accuracy : 0.9974833726882935\n",
      "Evaluation : test_loss : 0.03220426782499999 and test_accuracy : 0.990399956703186\n",
      "Epoch 63 - train_loss : 0.010314909270770537 and train_accuracy : 0.9977333545684814\n",
      "Evaluation : test_loss : 0.03426707377657294 and test_accuracy : 0.9907999634742737\n",
      "Epoch 64 - train_loss : 0.009257862445277472 and train_accuracy : 0.9970999956130981\n",
      "Evaluation : test_loss : 0.036394884390756485 and test_accuracy : 0.9904999732971191\n",
      "Epoch 65 - train_loss : 0.009277837372307356 and train_accuracy : 0.9981833696365356\n",
      "Evaluation : test_loss : 0.03325028249528259 and test_accuracy : 0.9908999800682068\n",
      "Epoch 66 - train_loss : 0.00870401180582121 and train_accuracy : 0.9980000257492065\n",
      "Evaluation : test_loss : 0.03425909429788589 and test_accuracy : 0.9905999898910522\n",
      "Epoch 67 - train_loss : 0.008384119346737861 and train_accuracy : 0.9977166652679443\n",
      "Evaluation : test_loss : 0.03550880481489003 and test_accuracy : 0.9900999665260315\n",
      "Epoch 68 - train_loss : 0.008371307805646211 and train_accuracy : 0.9980000257492065\n",
      "Evaluation : test_loss : 0.035119450697675345 and test_accuracy : 0.9898999929428101\n",
      "Epoch 69 - train_loss : 0.008552657793431232 and train_accuracy : 0.9987666606903076\n",
      "Evaluation : test_loss : 0.03277609595097601 and test_accuracy : 0.9907999634742737\n",
      "Epoch 70 - train_loss : 0.007426683547479721 and train_accuracy : 0.9987666606903076\n",
      "Evaluation : test_loss : 0.03227576375938952 and test_accuracy : 0.9905999898910522\n",
      "Epoch 71 - train_loss : 0.006947271280417529 and train_accuracy : 0.9987666606903076\n",
      "Evaluation : test_loss : 0.03313549372833222 and test_accuracy : 0.990399956703186\n",
      "Epoch 72 - train_loss : 0.007711490268896644 and train_accuracy : 0.9984999895095825\n",
      "Evaluation : test_loss : 0.034024077001959085 and test_accuracy : 0.990399956703186\n",
      "Epoch 73 - train_loss : 0.0066385765773399425 and train_accuracy : 0.9981333613395691\n",
      "Evaluation : test_loss : 0.035887620272114874 and test_accuracy : 0.9888999462127686\n",
      "Epoch 74 - train_loss : 0.005997744802152738 and train_accuracy : 0.9990666508674622\n",
      "Evaluation : test_loss : 0.0331701715302188 and test_accuracy : 0.9905999898910522\n",
      "Epoch 75 - train_loss : 0.005939514382528917 and train_accuracy : 0.9989333152770996\n",
      "Evaluation : test_loss : 0.0339556107763201 and test_accuracy : 0.9907999634742737\n",
      "Epoch 76 - train_loss : 0.005927082571239832 and train_accuracy : 0.9991000294685364\n",
      "Evaluation : test_loss : 0.03387936521321535 and test_accuracy : 0.9906999468803406\n",
      "Epoch 77 - train_loss : 0.006357588295456177 and train_accuracy : 0.9986333250999451\n",
      "Evaluation : test_loss : 0.03435455290600657 and test_accuracy : 0.9905999898910522\n",
      "Epoch 78 - train_loss : 0.00512289313871103 and train_accuracy : 0.9989666938781738\n",
      "Evaluation : test_loss : 0.0347887912299484 and test_accuracy : 0.9907999634742737\n",
      "Epoch 79 - train_loss : 0.005972449284551355 and train_accuracy : 0.9991999864578247\n",
      "Evaluation : test_loss : 0.03557536085136235 and test_accuracy : 0.9905999898910522\n",
      "Epoch 80 - train_loss : 0.00482588369535127 and train_accuracy : 0.9983833432197571\n",
      "Evaluation : test_loss : 0.03675480606034398 and test_accuracy : 0.9904999732971191\n",
      "Epoch 81 - train_loss : 0.004685285850428045 and train_accuracy : 0.9994333386421204\n",
      "Evaluation : test_loss : 0.035452629718929526 and test_accuracy : 0.9904999732971191\n",
      "Epoch 82 - train_loss : 0.00425286490644794 and train_accuracy : 0.9994166493415833\n",
      "Evaluation : test_loss : 0.036065091658383605 and test_accuracy : 0.9902999997138977\n",
      "Epoch 83 - train_loss : 0.0039999956459117435 and train_accuracy : 0.9985833168029785\n",
      "Evaluation : test_loss : 0.03806878104805946 and test_accuracy : 0.9899999499320984\n",
      "Epoch 84 - train_loss : 0.004131793578562792 and train_accuracy : 0.9993667006492615\n",
      "Evaluation : test_loss : 0.03427348401164636 and test_accuracy : 0.9905999898910522\n",
      "Epoch 85 - train_loss : 0.003879555768799037 and train_accuracy : 0.9989666938781738\n",
      "Evaluation : test_loss : 0.035987627122085544 and test_accuracy : 0.9898999929428101\n",
      "Epoch 86 - train_loss : 0.005746155846766973 and train_accuracy : 0.9986667037010193\n",
      "Evaluation : test_loss : 0.03729964402737096 and test_accuracy : 0.9898999929428101\n",
      "Epoch 87 - train_loss : 0.004222579493944068 and train_accuracy : 0.9994500279426575\n",
      "Evaluation : test_loss : 0.03511591446585953 and test_accuracy : 0.9901999831199646\n",
      "Epoch 88 - train_loss : 0.0029794786363102808 and train_accuracy : 0.999750018119812\n",
      "Evaluation : test_loss : 0.03429475767770782 and test_accuracy : 0.9909999966621399\n",
      "Epoch 89 - train_loss : 0.002798202527628746 and train_accuracy : 0.9994666576385498\n",
      "Evaluation : test_loss : 0.038055243948474524 and test_accuracy : 0.990399956703186\n",
      "Epoch 90 - train_loss : 0.0028898421330571483 and train_accuracy : 0.9996166825294495\n",
      "Evaluation : test_loss : 0.03663797224871814 and test_accuracy : 0.9907999634742737\n",
      "Epoch 91 - train_loss : 0.0025285022022823495 and train_accuracy : 0.999750018119812\n",
      "Evaluation : test_loss : 0.03650591527111828 and test_accuracy : 0.9904999732971191\n",
      "Epoch 92 - train_loss : 0.0029428262775278804 and train_accuracy : 0.9992333650588989\n",
      "Evaluation : test_loss : 0.038070627162232994 and test_accuracy : 0.9904999732971191\n",
      "Epoch 93 - train_loss : 0.0028534694875512892 and train_accuracy : 0.9994666576385498\n",
      "Evaluation : test_loss : 0.03933086548931897 and test_accuracy : 0.9899999499320984\n",
      "Epoch 94 - train_loss : 0.0024200367198015252 and train_accuracy : 0.9997833371162415\n",
      "Evaluation : test_loss : 0.03665174113120884 and test_accuracy : 0.9906999468803406\n",
      "Epoch 95 - train_loss : 0.002145397209824296 and train_accuracy : 0.9998000264167786\n",
      "Evaluation : test_loss : 0.038633403717540205 and test_accuracy : 0.9900999665260315\n",
      "Epoch 96 - train_loss : 0.0021010529499714417 and train_accuracy : 0.9993833303451538\n",
      "Evaluation : test_loss : 0.04014752618968487 and test_accuracy : 0.9899999499320984\n",
      "Epoch 97 - train_loss : 0.0022983908473785657 and train_accuracy : 0.9998000264167786\n",
      "Evaluation : test_loss : 0.03791114541236311 and test_accuracy : 0.9900999665260315\n",
      "Epoch 98 - train_loss : 0.0021175380592467264 and train_accuracy : 0.9994833469390869\n",
      "Evaluation : test_loss : 0.03847771257860586 and test_accuracy : 0.9900999665260315\n",
      "Epoch 99 - train_loss : 0.002414033786772052 and train_accuracy : 0.9992666840553284\n",
      "Evaluation : test_loss : 0.04285703105852008 and test_accuracy : 0.9894999861717224\n",
      "Epoch 100 - train_loss : 0.0030267357079234595 and train_accuracy : 0.9997166991233826\n",
      "Evaluation : test_loss : 0.041979988431558014 and test_accuracy : 0.9898999929428101\n",
      "Epoch 00100: reducing learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁▆▇█████████████████████████████████████</td></tr><tr><td>test_loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▆▇█████████████████████████████████████</td></tr><tr><td>train_loss</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.9899</td></tr><tr><td>test_loss</td><td>0.04198</td></tr><tr><td>train_accuracy</td><td>0.99972</td></tr><tr><td>train_loss</td><td>0.00303</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">LeNet-1-double-CNlayer-run</strong> at: <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/79hjkym3' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/79hjkym3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240308_083951-79hjkym3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LeNet_adv()\n",
    "model = model.to(device)\n",
    "\n",
    "train_loader = DataLoader(train_set,batch_size=batch_hp,shuffle=True,num_workers=8)\n",
    "test_loader = DataLoader(test_set,batch_size=batch_hp,shuffle=True,num_workers=8)\n",
    "train_test_kit = train_test(model = model , train_loader = train_loader, test_loader = test_loader ,project_name=\"CV-assignment-2\",run_name=f\"LeNet-1-double-CNlayer-run\",lr = 0.001,optimizer=\"Adam-vanilla\",iswandb=1)\n",
    "train_test_kit.train(num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample dataset and check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampling = [600,1800,6000,18000,60000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_mnist(x):\n",
    "    transform = ToTensor()\n",
    "    X, y = train_set.data.numpy(), np.array(train_set.targets)\n",
    "\n",
    "    class_indices = [np.where(y == i)[0] for i in range(10)]\n",
    "\n",
    "    sampled_indices = np.concatenate([np.random.choice(indices, x // 10, replace=False) for indices in class_indices])\n",
    "\n",
    "    np.random.shuffle(sampled_indices)\n",
    "\n",
    "    sampled_X = X[sampled_indices]\n",
    "    sampled_y = y[sampled_indices]\n",
    "\n",
    "    return sampled_X, sampled_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetSampled(Dataset):\n",
    "    def __init__(self,X,y,transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        if self.transform:\n",
    "            return self.transform(self.X[idx]),self.y[idx]\n",
    "        else:\n",
    "            return self.X[idx],self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/rkada/wandb/run-20240308_084718-5zq90rup</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/5zq90rup' target=\"_blank\">run-train_set_size-600</a></strong> to <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/5zq90rup' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/5zq90rup</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - train_loss : 2.3423627614974976 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3149996280670164 and test_accuracy : 0.11349999904632568\n",
      "Epoch 2 - train_loss : 2.3133338689804077 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.305329144001007 and test_accuracy : 0.11349999904632568\n",
      "Epoch 3 - train_loss : 2.303249955177307 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3041249752044677 and test_accuracy : 0.0973999947309494\n",
      "Epoch 4 - train_loss : 2.3045566082000732 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3072847723960876 and test_accuracy : 0.10319999605417252\n",
      "Epoch 5 - train_loss : 2.3105592727661133 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.310975658893585 and test_accuracy : 0.10319999605417252\n",
      "Epoch 6 - train_loss : 2.3100253343582153 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.312427306175232 and test_accuracy : 0.10319999605417252\n",
      "Epoch 7 - train_loss : 2.3082977533340454 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.312085711956024 and test_accuracy : 0.10319999605417252\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 8 - train_loss : 2.316137194633484 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.311889672279358 and test_accuracy : 0.10319999605417252\n",
      "Epoch 9 - train_loss : 2.3122007846832275 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3115154027938845 and test_accuracy : 0.10319999605417252\n",
      "Epoch 10 - train_loss : 2.311068296432495 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.311054563522339 and test_accuracy : 0.10319999605417252\n",
      "Epoch 11 - train_loss : 2.3120007514953613 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.310526394844055 and test_accuracy : 0.10319999605417252\n",
      "Epoch 12 - train_loss : 2.305039882659912 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3099968075752257 and test_accuracy : 0.10319999605417252\n",
      "Epoch 13 - train_loss : 2.3068071603775024 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.309519386291504 and test_accuracy : 0.10319999605417252\n",
      "Epoch 14 - train_loss : 2.311169147491455 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3090468645095825 and test_accuracy : 0.10319999605417252\n",
      "Epoch 15 - train_loss : 2.3110398054122925 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3085650324821474 and test_accuracy : 0.10319999605417252\n",
      "Epoch 16 - train_loss : 2.3101900815963745 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3080583095550535 and test_accuracy : 0.10319999605417252\n",
      "Epoch 17 - train_loss : 2.3014800548553467 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3075907230377197 and test_accuracy : 0.10319999605417252\n",
      "Epoch 18 - train_loss : 2.3052735328674316 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3071818351745605 and test_accuracy : 0.10319999605417252\n",
      "Epoch 19 - train_loss : 2.304490327835083 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.306796872615814 and test_accuracy : 0.10319999605417252\n",
      "Epoch 20 - train_loss : 2.3031861782073975 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.306439971923828 and test_accuracy : 0.10319999605417252\n",
      "Epoch 21 - train_loss : 2.3051310777664185 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3061222434043884 and test_accuracy : 0.10319999605417252\n",
      "Epoch 22 - train_loss : 2.301974296569824 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.305859863758087 and test_accuracy : 0.10319999605417252\n",
      "Epoch 23 - train_loss : 2.30468213558197 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.30562219619751 and test_accuracy : 0.10319999605417252\n",
      "Epoch 24 - train_loss : 2.298887610435486 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3054123282432557 and test_accuracy : 0.10319999605417252\n",
      "Epoch 25 - train_loss : 2.3019856214523315 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.305257272720337 and test_accuracy : 0.10319999605417252\n",
      "Epoch 26 - train_loss : 2.304171919822693 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3050980448722838 and test_accuracy : 0.10319999605417252\n",
      "Epoch 27 - train_loss : 2.3018232583999634 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.30496631860733 and test_accuracy : 0.10319999605417252\n",
      "Epoch 28 - train_loss : 2.3030805587768555 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3048584818840028 and test_accuracy : 0.10319999605417252\n",
      "Epoch 29 - train_loss : 2.304540991783142 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.304714858531952 and test_accuracy : 0.10319999605417252\n",
      "Epoch 30 - train_loss : 2.305690288543701 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3045490264892576 and test_accuracy : 0.10319999605417252\n",
      "Epoch 31 - train_loss : 2.303761601448059 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3043712854385374 and test_accuracy : 0.10319999605417252\n",
      "Epoch 32 - train_loss : 2.301969885826111 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3042181372642516 and test_accuracy : 0.10089999437332153\n",
      "Epoch 33 - train_loss : 2.3042986392974854 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3040995359420777 and test_accuracy : 0.10089999437332153\n",
      "Epoch 34 - train_loss : 2.3032456636428833 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.303999900817871 and test_accuracy : 0.10089999437332153\n",
      "Epoch 35 - train_loss : 2.3020856380462646 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3039169788360594 and test_accuracy : 0.10089999437332153\n",
      "Epoch 36 - train_loss : 2.303100824356079 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3038522720336916 and test_accuracy : 0.10089999437332153\n",
      "Epoch 37 - train_loss : 2.302481532096863 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.303804647922516 and test_accuracy : 0.10089999437332153\n",
      "Epoch 38 - train_loss : 2.3059974908828735 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.303729748725891 and test_accuracy : 0.10089999437332153\n",
      "Epoch 39 - train_loss : 2.3052247762680054 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3036226272583007 and test_accuracy : 0.10089999437332153\n",
      "Epoch 40 - train_loss : 2.3032697439193726 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3035075426101685 and test_accuracy : 0.10089999437332153\n",
      "Epoch 41 - train_loss : 2.302439570426941 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3034260153770445 and test_accuracy : 0.10089999437332153\n",
      "Epoch 42 - train_loss : 2.3032681941986084 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3034074187278746 and test_accuracy : 0.10089999437332153\n",
      "Epoch 43 - train_loss : 2.3030859231948853 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.303417921066284 and test_accuracy : 0.10089999437332153\n",
      "Epoch 44 - train_loss : 2.302895426750183 and train_accuracy : 0.12000000476837158\n",
      "Evaluation : test_loss : 2.3034211874008177 and test_accuracy : 0.11899999529123306\n",
      "Epoch 45 - train_loss : 2.3028647899627686 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3034257650375367 and test_accuracy : 0.08919999748468399\n",
      "Epoch 46 - train_loss : 2.3033007383346558 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3034186363220215 and test_accuracy : 0.08919999748468399\n",
      "Epoch 47 - train_loss : 2.302347421646118 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3034106492996216 and test_accuracy : 0.08919999748468399\n",
      "Epoch 48 - train_loss : 2.302929997444153 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3033968448638915 and test_accuracy : 0.08919999748468399\n",
      "Epoch 49 - train_loss : 2.3033515214920044 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.303352451324463 and test_accuracy : 0.08919999748468399\n",
      "Epoch 50 - train_loss : 2.3032569885253906 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3032663822174073 and test_accuracy : 0.08919999748468399\n",
      "Epoch 51 - train_loss : 2.3021923303604126 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3031690239906313 and test_accuracy : 0.10089999437332153\n",
      "Epoch 52 - train_loss : 2.3029227256774902 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.303100347518921 and test_accuracy : 0.0957999974489212\n",
      "Epoch 53 - train_loss : 2.303307890892029 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3030290246009826 and test_accuracy : 0.0957999974489212\n",
      "Epoch 54 - train_loss : 2.302211046218872 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3029629230499267 and test_accuracy : 0.0957999974489212\n",
      "Epoch 55 - train_loss : 2.3031082153320312 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302906668186188 and test_accuracy : 0.0957999974489212\n",
      "Epoch 56 - train_loss : 2.3015798330307007 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3028617024421694 and test_accuracy : 0.0957999974489212\n",
      "Epoch 57 - train_loss : 2.302793860435486 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3028496742248534 and test_accuracy : 0.0957999974489212\n",
      "Epoch 58 - train_loss : 2.302384376525879 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3028504848480225 and test_accuracy : 0.0957999974489212\n",
      "Epoch 59 - train_loss : 2.3019368648529053 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302880251407623 and test_accuracy : 0.10319999605417252\n",
      "Epoch 60 - train_loss : 2.3017871379852295 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302898418903351 and test_accuracy : 0.10319999605417252\n",
      "Epoch 61 - train_loss : 2.301861047744751 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3029170751571657 and test_accuracy : 0.10319999605417252\n",
      "Epoch 62 - train_loss : 2.3022029399871826 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3029346108436584 and test_accuracy : 0.10319999605417252\n",
      "Epoch 63 - train_loss : 2.3027448654174805 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302928864955902 and test_accuracy : 0.10319999605417252\n",
      "Epoch 64 - train_loss : 2.30373477935791 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3028998136520387 and test_accuracy : 0.10319999605417252\n",
      "Epoch 65 - train_loss : 2.3029797077178955 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302858805656433 and test_accuracy : 0.10319999605417252\n",
      "Epoch 66 - train_loss : 2.3025325536727905 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3028150677680967 and test_accuracy : 0.10319999605417252\n",
      "Epoch 67 - train_loss : 2.3030641078948975 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3027544140815737 and test_accuracy : 0.10319999605417252\n",
      "Epoch 68 - train_loss : 2.302363872528076 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3026689529418944 and test_accuracy : 0.10319999605417252\n",
      "Epoch 69 - train_loss : 2.3012888431549072 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3026005029678345 and test_accuracy : 0.10319999605417252\n",
      "Epoch 70 - train_loss : 2.3008569478988647 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302563989162445 and test_accuracy : 0.10319999605417252\n",
      "Epoch 71 - train_loss : 2.3027442693710327 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3025505781173705 and test_accuracy : 0.10319999605417252\n",
      "Epoch 72 - train_loss : 2.303436279296875 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3025411486625673 and test_accuracy : 0.10319999605417252\n",
      "Epoch 73 - train_loss : 2.301610827445984 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3025263428688048 and test_accuracy : 0.10319999605417252\n",
      "Epoch 74 - train_loss : 2.303463578224182 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3024990797042846 and test_accuracy : 0.10319999605417252\n",
      "Epoch 75 - train_loss : 2.303066849708557 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3024672627449037 and test_accuracy : 0.10319999605417252\n",
      "Epoch 76 - train_loss : 2.301526665687561 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302444648742676 and test_accuracy : 0.10319999605417252\n",
      "Epoch 77 - train_loss : 2.30304491519928 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302410328388214 and test_accuracy : 0.11400000005960464\n",
      "Epoch 78 - train_loss : 2.3029712438583374 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3023871898651125 and test_accuracy : 0.11349999904632568\n",
      "Epoch 79 - train_loss : 2.3042303323745728 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3023937582969665 and test_accuracy : 0.11349999904632568\n",
      "Epoch 80 - train_loss : 2.3025896549224854 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.30242258310318 and test_accuracy : 0.11349999904632568\n",
      "Epoch 81 - train_loss : 2.3021332025527954 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3024651646614074 and test_accuracy : 0.11349999904632568\n",
      "Epoch 82 - train_loss : 2.302149772644043 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3025061011314394 and test_accuracy : 0.11509999632835388\n",
      "Epoch 83 - train_loss : 2.302346706390381 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3025612473487853 and test_accuracy : 0.08919999748468399\n",
      "Epoch 84 - train_loss : 2.3026798963546753 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3026215076446532 and test_accuracy : 0.08919999748468399\n",
      "Epoch 85 - train_loss : 2.3019096851348877 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3026785135269163 and test_accuracy : 0.08919999748468399\n",
      "Epoch 86 - train_loss : 2.303236246109009 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3027167439460756 and test_accuracy : 0.08919999748468399\n",
      "Epoch 87 - train_loss : 2.3022667169570923 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3027392864227294 and test_accuracy : 0.08919999748468399\n",
      "Epoch 88 - train_loss : 2.3017534017562866 and train_accuracy : 0.16833333671092987\n",
      "Evaluation : test_loss : 2.302751886844635 and test_accuracy : 0.15209999680519104\n",
      "Epoch 89 - train_loss : 2.30221951007843 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.30277099609375 and test_accuracy : 0.10319999605417252\n",
      "Epoch 90 - train_loss : 2.3029961585998535 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3028014302253723 and test_accuracy : 0.10319999605417252\n",
      "Epoch 91 - train_loss : 2.301792025566101 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302835738658905 and test_accuracy : 0.10319999605417252\n",
      "Epoch 92 - train_loss : 2.30144727230072 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3029114842414855 and test_accuracy : 0.10319999605417252\n",
      "Epoch 93 - train_loss : 2.303743004798889 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3029523849487306 and test_accuracy : 0.0957999974489212\n",
      "Epoch 94 - train_loss : 2.3035452365875244 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302932548522949 and test_accuracy : 0.0957999974489212\n",
      "Epoch 95 - train_loss : 2.303434729576111 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3028710007667543 and test_accuracy : 0.0957999974489212\n",
      "Epoch 96 - train_loss : 2.302408456802368 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.30278400182724 and test_accuracy : 0.0957999974489212\n",
      "Epoch 97 - train_loss : 2.3016473054885864 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302713119983673 and test_accuracy : 0.0957999974489212\n",
      "Epoch 98 - train_loss : 2.3017865419387817 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3026968240737915 and test_accuracy : 0.0957999974489212\n",
      "Epoch 99 - train_loss : 2.3025814294815063 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302708387374878 and test_accuracy : 0.0957999974489212\n",
      "Epoch 100 - train_loss : 2.304252028465271 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302697229385376 and test_accuracy : 0.0957999974489212\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▇▃▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄█▁▁▄▃▃▄▄▄▄▄▄▄▇▇▇▁▁▄▄▃▃▃</td></tr><tr><td>test_loss</td><td>█▂▇▆▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▁▂▄▃▂▃▂▂▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.0958</td></tr><tr><td>test_loss</td><td>2.3027</td></tr><tr><td>train_accuracy</td><td>0.1</td></tr><tr><td>train_loss</td><td>2.30425</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run-train_set_size-600</strong> at: <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/5zq90rup' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/5zq90rup</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240308_084718-5zq90rup/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/rkada/wandb/run-20240308_084921-j2a842v5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/j2a842v5' target=\"_blank\">run-train_set_size-1800</a></strong> to <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/j2a842v5' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/j2a842v5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - train_loss : 2.341588795185089 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.311350679397583 and test_accuracy : 0.0957999974489212\n",
      "Epoch 2 - train_loss : 2.307619333267212 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.303173565864563 and test_accuracy : 0.11349999904632568\n",
      "Epoch 3 - train_loss : 2.3047712445259094 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3080500960350037 and test_accuracy : 0.10099999606609344\n",
      "Epoch 4 - train_loss : 2.308018445968628 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3088416337966917 and test_accuracy : 0.10099999606609344\n",
      "Epoch 5 - train_loss : 2.306749641895294 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3048771262168883 and test_accuracy : 0.10099999606609344\n",
      "Epoch 6 - train_loss : 2.304201662540436 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3021276593208313 and test_accuracy : 0.10099999606609344\n",
      "Epoch 7 - train_loss : 2.303602159023285 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302085518836975 and test_accuracy : 0.11349999904632568\n",
      "Epoch 8 - train_loss : 2.3030055165290833 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3027833819389345 and test_accuracy : 0.0957999974489212\n",
      "Epoch 9 - train_loss : 2.3033353090286255 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.303110861778259 and test_accuracy : 0.10089999437332153\n",
      "Epoch 10 - train_loss : 2.303985059261322 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3034167766571043 and test_accuracy : 0.10089999437332153\n",
      "Epoch 11 - train_loss : 2.3037869334220886 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3027815937995912 and test_accuracy : 0.10319999605417252\n",
      "Epoch 12 - train_loss : 2.3028913736343384 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.303049087524414 and test_accuracy : 0.08919999748468399\n",
      "Epoch 00012: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 13 - train_loss : 2.3026758432388306 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302971971035004 and test_accuracy : 0.08919999748468399\n",
      "Epoch 14 - train_loss : 2.3026316165924072 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302939736843109 and test_accuracy : 0.08919999748468399\n",
      "Epoch 15 - train_loss : 2.3026901483535767 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3028838276863097 and test_accuracy : 0.08919999748468399\n",
      "Epoch 16 - train_loss : 2.3024967908859253 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3027910351753236 and test_accuracy : 0.08919999748468399\n",
      "Epoch 17 - train_loss : 2.3026241064071655 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302744197845459 and test_accuracy : 0.08919999748468399\n",
      "Epoch 18 - train_loss : 2.30254864692688 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302662420272827 and test_accuracy : 0.08919999748468399\n",
      "Epoch 19 - train_loss : 2.3024404644966125 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3025627732276917 and test_accuracy : 0.08919999748468399\n",
      "Epoch 20 - train_loss : 2.302468001842499 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3024148821830748 and test_accuracy : 0.08919999748468399\n",
      "Epoch 21 - train_loss : 2.3024200201034546 and train_accuracy : 0.10333333909511566\n",
      "Evaluation : test_loss : 2.3023446440696715 and test_accuracy : 0.10589999705553055\n",
      "Epoch 22 - train_loss : 2.3024330139160156 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302287685871124 and test_accuracy : 0.10279999673366547\n",
      "Epoch 23 - train_loss : 2.3024197816848755 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3022566080093383 and test_accuracy : 0.10279999673366547\n",
      "Epoch 24 - train_loss : 2.3024001121520996 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3022372722625732 and test_accuracy : 0.10279999673366547\n",
      "Epoch 25 - train_loss : 2.3024429082870483 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3022072315216064 and test_accuracy : 0.10279999673366547\n",
      "Epoch 26 - train_loss : 2.3024536967277527 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3022205352783205 and test_accuracy : 0.10279999673366547\n",
      "Epoch 27 - train_loss : 2.3024669885635376 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3022398114204408 and test_accuracy : 0.10279999673366547\n",
      "Epoch 28 - train_loss : 2.3023858070373535 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302278923988342 and test_accuracy : 0.10279999673366547\n",
      "Epoch 29 - train_loss : 2.3023467659950256 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.30228590965271 and test_accuracy : 0.10279999673366547\n",
      "Epoch 30 - train_loss : 2.302372634410858 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302321803569794 and test_accuracy : 0.10279999673366547\n",
      "Epoch 31 - train_loss : 2.3023502230644226 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302344334125519 and test_accuracy : 0.08919999748468399\n",
      "Epoch 32 - train_loss : 2.3023895621299744 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.30230633020401 and test_accuracy : 0.08919999748468399\n",
      "Epoch 33 - train_loss : 2.3023170828819275 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302321457862854 and test_accuracy : 0.08919999748468399\n",
      "Epoch 34 - train_loss : 2.3023309111595154 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.30231374502182 and test_accuracy : 0.10319999605417252\n",
      "Epoch 35 - train_loss : 2.302339792251587 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3023159980773924 and test_accuracy : 0.10319999605417252\n",
      "Epoch 36 - train_loss : 2.302300989627838 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3022714972496034 and test_accuracy : 0.10319999605417252\n",
      "Epoch 37 - train_loss : 2.302326023578644 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3022664546966554 and test_accuracy : 0.10279999673366547\n",
      "Epoch 38 - train_loss : 2.3023141026496887 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3022603034973144 and test_accuracy : 0.10279999673366547\n",
      "Epoch 39 - train_loss : 2.302250564098358 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302266073226929 and test_accuracy : 0.10279999673366547\n",
      "Epoch 40 - train_loss : 2.302241563796997 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3022785425186156 and test_accuracy : 0.10279999673366547\n",
      "Epoch 41 - train_loss : 2.3022955656051636 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3022608757019043 and test_accuracy : 0.10279999673366547\n",
      "Epoch 42 - train_loss : 2.3022703528404236 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302276885509491 and test_accuracy : 0.10279999673366547\n",
      "Epoch 43 - train_loss : 2.302229166030884 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3022502183914186 and test_accuracy : 0.10279999673366547\n",
      "Epoch 44 - train_loss : 2.30226469039917 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3022379159927366 and test_accuracy : 0.10279999673366547\n",
      "Epoch 45 - train_loss : 2.3022079467773438 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302231800556183 and test_accuracy : 0.10279999673366547\n",
      "Epoch 46 - train_loss : 2.302207887172699 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3021739602088926 and test_accuracy : 0.10279999673366547\n",
      "Epoch 47 - train_loss : 2.302156090736389 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.30217604637146 and test_accuracy : 0.0982000008225441\n",
      "Epoch 48 - train_loss : 2.3021299242973328 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3022397994995116 and test_accuracy : 0.0982000008225441\n",
      "Epoch 49 - train_loss : 2.302142560482025 and train_accuracy : 0.17555555701255798\n",
      "Evaluation : test_loss : 2.3022457122802735 and test_accuracy : 0.1696999967098236\n",
      "Epoch 50 - train_loss : 2.302108883857727 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3022497653961183 and test_accuracy : 0.0973999947309494\n",
      "Epoch 51 - train_loss : 2.3020735383033752 and train_accuracy : 0.1294444501399994\n",
      "Evaluation : test_loss : 2.30220023393631 and test_accuracy : 0.11490000039339066\n",
      "Epoch 52 - train_loss : 2.3020644783973694 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3022212982177734 and test_accuracy : 0.0973999947309494\n",
      "Epoch 53 - train_loss : 2.3021200299263 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302137351036072 and test_accuracy : 0.0973999947309494\n",
      "Epoch 54 - train_loss : 2.3020570874214172 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3020834922790527 and test_accuracy : 0.0973999947309494\n",
      "Epoch 55 - train_loss : 2.3019882440567017 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3019973754882814 and test_accuracy : 0.0973999947309494\n",
      "Epoch 56 - train_loss : 2.3019530177116394 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3019028425216677 and test_accuracy : 0.0973999947309494\n",
      "Epoch 57 - train_loss : 2.3019726872444153 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3018097639083863 and test_accuracy : 0.0973999947309494\n",
      "Epoch 58 - train_loss : 2.3019391298294067 and train_accuracy : 0.10999999940395355\n",
      "Evaluation : test_loss : 2.301735556125641 and test_accuracy : 0.10379999876022339\n",
      "Epoch 59 - train_loss : 2.301862955093384 and train_accuracy : 0.23277778923511505\n",
      "Evaluation : test_loss : 2.301710879802704 and test_accuracy : 0.2328999936580658\n",
      "Epoch 60 - train_loss : 2.3018693923950195 and train_accuracy : 0.12833333015441895\n",
      "Evaluation : test_loss : 2.3017091512680055 and test_accuracy : 0.11889999359846115\n",
      "Epoch 61 - train_loss : 2.301847219467163 and train_accuracy : 0.18611112236976624\n",
      "Evaluation : test_loss : 2.3016756176948547 and test_accuracy : 0.18539999425411224\n",
      "Epoch 62 - train_loss : 2.3017855286598206 and train_accuracy : 0.16333334147930145\n",
      "Evaluation : test_loss : 2.301675832271576 and test_accuracy : 0.16749998927116394\n",
      "Epoch 63 - train_loss : 2.3017799258232117 and train_accuracy : 0.2849999964237213\n",
      "Evaluation : test_loss : 2.301714849472046 and test_accuracy : 0.2815999984741211\n",
      "Epoch 64 - train_loss : 2.301728129386902 and train_accuracy : 0.17499999701976776\n",
      "Evaluation : test_loss : 2.3016345500946045 and test_accuracy : 0.17710000276565552\n",
      "Epoch 65 - train_loss : 2.3016690611839294 and train_accuracy : 0.11166667193174362\n",
      "Evaluation : test_loss : 2.301569712162018 and test_accuracy : 0.11249999701976776\n",
      "Epoch 66 - train_loss : 2.3016052842140198 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3014546036720276 and test_accuracy : 0.10319999605417252\n",
      "Epoch 67 - train_loss : 2.301523745059967 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3014179706573485 and test_accuracy : 0.10319999605417252\n",
      "Epoch 68 - train_loss : 2.3014769554138184 and train_accuracy : 0.17777778208255768\n",
      "Evaluation : test_loss : 2.301278805732727 and test_accuracy : 0.1906999945640564\n",
      "Epoch 69 - train_loss : 2.301424741744995 and train_accuracy : 0.11222222447395325\n",
      "Evaluation : test_loss : 2.3011583209037783 and test_accuracy : 0.125\n",
      "Epoch 70 - train_loss : 2.3013673424720764 and train_accuracy : 0.11500000208616257\n",
      "Evaluation : test_loss : 2.301084518432617 and test_accuracy : 0.13189999759197235\n",
      "Epoch 71 - train_loss : 2.30141943693161 and train_accuracy : 0.13722223043441772\n",
      "Evaluation : test_loss : 2.301000726222992 and test_accuracy : 0.15160000324249268\n",
      "Epoch 72 - train_loss : 2.301346480846405 and train_accuracy : 0.10999999940395355\n",
      "Evaluation : test_loss : 2.300929605960846 and test_accuracy : 0.12269999831914902\n",
      "Epoch 73 - train_loss : 2.301295220851898 and train_accuracy : 0.13388888537883759\n",
      "Evaluation : test_loss : 2.3008987307548523 and test_accuracy : 0.14549998939037323\n",
      "Epoch 74 - train_loss : 2.3011686205863953 and train_accuracy : 0.1322222203016281\n",
      "Evaluation : test_loss : 2.300841438770294 and test_accuracy : 0.14429999887943268\n",
      "Epoch 75 - train_loss : 2.3010902404785156 and train_accuracy : 0.11444444954395294\n",
      "Evaluation : test_loss : 2.3007931232452394 and test_accuracy : 0.12729999423027039\n",
      "Epoch 76 - train_loss : 2.3009918332099915 and train_accuracy : 0.17555555701255798\n",
      "Evaluation : test_loss : 2.3007917284965513 and test_accuracy : 0.18569999933242798\n",
      "Epoch 77 - train_loss : 2.300969421863556 and train_accuracy : 0.2566666603088379\n",
      "Evaluation : test_loss : 2.30075089931488 and test_accuracy : 0.25939998030662537\n",
      "Epoch 78 - train_loss : 2.3008363246917725 and train_accuracy : 0.2433333396911621\n",
      "Evaluation : test_loss : 2.300662302970886 and test_accuracy : 0.25049999356269836\n",
      "Epoch 79 - train_loss : 2.3007695078849792 and train_accuracy : 0.2611111104488373\n",
      "Evaluation : test_loss : 2.300627887248993 and test_accuracy : 0.25669997930526733\n",
      "Epoch 80 - train_loss : 2.3006784915924072 and train_accuracy : 0.25\n",
      "Evaluation : test_loss : 2.300555694103241 and test_accuracy : 0.2450999915599823\n",
      "Epoch 81 - train_loss : 2.300607681274414 and train_accuracy : 0.22500000894069672\n",
      "Evaluation : test_loss : 2.3004768013954164 and test_accuracy : 0.22179999947547913\n",
      "Epoch 82 - train_loss : 2.300410211086273 and train_accuracy : 0.22611111402511597\n",
      "Evaluation : test_loss : 2.3002782225608827 and test_accuracy : 0.23649999499320984\n",
      "Epoch 83 - train_loss : 2.3003602623939514 and train_accuracy : 0.21111111342906952\n",
      "Evaluation : test_loss : 2.300137937068939 and test_accuracy : 0.22019998729228973\n",
      "Epoch 84 - train_loss : 2.3002899289131165 and train_accuracy : 0.20222222805023193\n",
      "Evaluation : test_loss : 2.299982476234436 and test_accuracy : 0.21369999647140503\n",
      "Epoch 85 - train_loss : 2.3000340461730957 and train_accuracy : 0.2244444489479065\n",
      "Evaluation : test_loss : 2.299832046031952 and test_accuracy : 0.23359999060630798\n",
      "Epoch 86 - train_loss : 2.2999165654182434 and train_accuracy : 0.2294444441795349\n",
      "Evaluation : test_loss : 2.2996520519256594 and test_accuracy : 0.23889999091625214\n",
      "Epoch 87 - train_loss : 2.2997577786445618 and train_accuracy : 0.1877777874469757\n",
      "Evaluation : test_loss : 2.2994495630264282 and test_accuracy : 0.19569998979568481\n",
      "Epoch 88 - train_loss : 2.299760580062866 and train_accuracy : 0.17888888716697693\n",
      "Evaluation : test_loss : 2.299251365661621 and test_accuracy : 0.1891999989748001\n",
      "Epoch 89 - train_loss : 2.2995123863220215 and train_accuracy : 0.2199999988079071\n",
      "Evaluation : test_loss : 2.2991127133369447 and test_accuracy : 0.22089999914169312\n",
      "Epoch 90 - train_loss : 2.2994239926338196 and train_accuracy : 0.21611112356185913\n",
      "Evaluation : test_loss : 2.2989211201667787 and test_accuracy : 0.2207999974489212\n",
      "Epoch 91 - train_loss : 2.2992889285087585 and train_accuracy : 0.19555556774139404\n",
      "Evaluation : test_loss : 2.298692297935486 and test_accuracy : 0.20349998772144318\n",
      "Epoch 92 - train_loss : 2.2989463806152344 and train_accuracy : 0.24833333492279053\n",
      "Evaluation : test_loss : 2.2985181331634523 and test_accuracy : 0.2637999951839447\n",
      "Epoch 93 - train_loss : 2.2988376021385193 and train_accuracy : 0.26277777552604675\n",
      "Evaluation : test_loss : 2.298322522640228 and test_accuracy : 0.27379998564720154\n",
      "Epoch 94 - train_loss : 2.298550605773926 and train_accuracy : 0.2805555760860443\n",
      "Evaluation : test_loss : 2.2981329798698424 and test_accuracy : 0.28939998149871826\n",
      "Epoch 95 - train_loss : 2.298361122608185 and train_accuracy : 0.25111111998558044\n",
      "Evaluation : test_loss : 2.2978830218315123 and test_accuracy : 0.26080000400543213\n",
      "Epoch 96 - train_loss : 2.298179864883423 and train_accuracy : 0.23444445431232452\n",
      "Evaluation : test_loss : 2.29759703874588 and test_accuracy : 0.24459999799728394\n",
      "Epoch 97 - train_loss : 2.297806739807129 and train_accuracy : 0.28388890624046326\n",
      "Evaluation : test_loss : 2.2973310708999635 and test_accuracy : 0.28849998116493225\n",
      "Epoch 98 - train_loss : 2.297535538673401 and train_accuracy : 0.29666668176651\n",
      "Evaluation : test_loss : 2.2970786809921266 and test_accuracy : 0.29600000381469727\n",
      "Epoch 99 - train_loss : 2.297246813774109 and train_accuracy : 0.27166667580604553\n",
      "Evaluation : test_loss : 2.2967612743377686 and test_accuracy : 0.27869999408721924\n",
      "Epoch 100 - train_loss : 2.296926438808441 and train_accuracy : 0.2455555647611618\n",
      "Evaluation : test_loss : 2.296442723274231 and test_accuracy : 0.25529998540878296\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▄▂▁▁▆▄▄▁▂▂▃▇▇▆▅▅▆▇██▇</td></tr><tr><td>test_loss</td><td>█▆▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▂▁▁▆▄▄▁▁▁▂▇▇▆▅▄▆▇██▇</td></tr><tr><td>train_loss</td><td>█▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.2553</td></tr><tr><td>test_loss</td><td>2.29644</td></tr><tr><td>train_accuracy</td><td>0.24556</td></tr><tr><td>train_loss</td><td>2.29693</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run-train_set_size-1800</strong> at: <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/j2a842v5' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/j2a842v5</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240308_084921-j2a842v5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/rkada/wandb/run-20240308_085129-c54q3lgz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/c54q3lgz' target=\"_blank\">run-train_set_size-6000</a></strong> to <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/c54q3lgz' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/c54q3lgz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - train_loss : 2.312535027662913 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3083515524864198 and test_accuracy : 0.10319999605417252\n",
      "Epoch 2 - train_loss : 2.3059268792470298 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3022884845733644 and test_accuracy : 0.10089999437332153\n",
      "Epoch 3 - train_loss : 2.304729441801707 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.303195261955261 and test_accuracy : 0.0982000008225441\n",
      "Epoch 4 - train_loss : 2.3040839234987893 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302027499675751 and test_accuracy : 0.10319999605417252\n",
      "Epoch 5 - train_loss : 2.303304354349772 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.302642583847046 and test_accuracy : 0.09799999743700027\n",
      "Epoch 6 - train_loss : 2.3028904596964517 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3004603028297423 and test_accuracy : 0.10300000011920929\n",
      "Epoch 7 - train_loss : 2.30089008808136 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.298823797702789 and test_accuracy : 0.08919999748468399\n",
      "Epoch 8 - train_loss : 2.296742618083954 and train_accuracy : 0.27783334255218506\n",
      "Evaluation : test_loss : 2.2900930643081665 and test_accuracy : 0.2906999886035919\n",
      "Epoch 9 - train_loss : 2.2811896999677024 and train_accuracy : 0.28299999237060547\n",
      "Evaluation : test_loss : 2.258411502838135 and test_accuracy : 0.2985000014305115\n",
      "Epoch 10 - train_loss : 2.2297299901644387 and train_accuracy : 0.4156666696071625\n",
      "Evaluation : test_loss : 2.1667781829833985 and test_accuracy : 0.44349998235702515\n",
      "Epoch 11 - train_loss : 2.104889929294586 and train_accuracy : 0.42516666650772095\n",
      "Evaluation : test_loss : 1.9932738602161408 and test_accuracy : 0.4456000030040741\n",
      "Epoch 12 - train_loss : 1.9178506731987 and train_accuracy : 0.4754999876022339\n",
      "Evaluation : test_loss : 1.784409725666046 and test_accuracy : 0.4810999929904938\n",
      "Epoch 13 - train_loss : 1.7160839438438416 and train_accuracy : 0.5566666722297668\n",
      "Evaluation : test_loss : 1.5819524466991424 and test_accuracy : 0.5613999962806702\n",
      "Epoch 14 - train_loss : 1.5178784529368083 and train_accuracy : 0.6236666440963745\n",
      "Evaluation : test_loss : 1.3966543316841125 and test_accuracy : 0.6317999958992004\n",
      "Epoch 15 - train_loss : 1.342653860648473 and train_accuracy : 0.6591666340827942\n",
      "Evaluation : test_loss : 1.2398674547672273 and test_accuracy : 0.6717999577522278\n",
      "Epoch 16 - train_loss : 1.2002408504486084 and train_accuracy : 0.6819999814033508\n",
      "Evaluation : test_loss : 1.1134475767612457 and test_accuracy : 0.6954999566078186\n",
      "Epoch 17 - train_loss : 1.0874101171890895 and train_accuracy : 0.7139999866485596\n",
      "Evaluation : test_loss : 1.0147510468959808 and test_accuracy : 0.7224999666213989\n",
      "Epoch 18 - train_loss : 0.9989621390899023 and train_accuracy : 0.7268333435058594\n",
      "Evaluation : test_loss : 0.9389587610960006 and test_accuracy : 0.7335000038146973\n",
      "Epoch 19 - train_loss : 0.9274498720963796 and train_accuracy : 0.7423333525657654\n",
      "Evaluation : test_loss : 0.876732787489891 and test_accuracy : 0.7484999895095825\n",
      "Epoch 20 - train_loss : 0.8684005737304688 and train_accuracy : 0.7566666603088379\n",
      "Evaluation : test_loss : 0.8235309302806855 and test_accuracy : 0.7610999941825867\n",
      "Epoch 21 - train_loss : 0.8175443857908249 and train_accuracy : 0.7699999809265137\n",
      "Evaluation : test_loss : 0.7758016526699066 and test_accuracy : 0.7770000100135803\n",
      "Epoch 22 - train_loss : 0.7726795027653376 and train_accuracy : 0.7896666526794434\n",
      "Evaluation : test_loss : 0.7338502824306488 and test_accuracy : 0.7910999655723572\n",
      "Epoch 23 - train_loss : 0.7322588413953781 and train_accuracy : 0.8026666641235352\n",
      "Evaluation : test_loss : 0.701385173201561 and test_accuracy : 0.8026999831199646\n",
      "Epoch 24 - train_loss : 0.6979266554117203 and train_accuracy : 0.815833330154419\n",
      "Evaluation : test_loss : 0.6686480283737183 and test_accuracy : 0.8126999735832214\n",
      "Epoch 25 - train_loss : 0.6639479994773865 and train_accuracy : 0.8219999670982361\n",
      "Evaluation : test_loss : 0.6484687000513076 and test_accuracy : 0.8197999596595764\n",
      "Epoch 26 - train_loss : 0.636947825551033 and train_accuracy : 0.8326666355133057\n",
      "Evaluation : test_loss : 0.6143507450819016 and test_accuracy : 0.8313999772071838\n",
      "Epoch 27 - train_loss : 0.6057225416103998 and train_accuracy : 0.843833327293396\n",
      "Evaluation : test_loss : 0.5888536691665649 and test_accuracy : 0.8396999835968018\n",
      "Epoch 28 - train_loss : 0.5779347022374471 and train_accuracy : 0.8431666493415833\n",
      "Evaluation : test_loss : 0.5700699180364609 and test_accuracy : 0.8369999527931213\n",
      "Epoch 29 - train_loss : 0.5543516129255295 and train_accuracy : 0.8578333258628845\n",
      "Evaluation : test_loss : 0.538289800286293 and test_accuracy : 0.849399983882904\n",
      "Epoch 30 - train_loss : 0.531596432129542 and train_accuracy : 0.856499969959259\n",
      "Evaluation : test_loss : 0.5192700803279877 and test_accuracy : 0.8533999919891357\n",
      "Epoch 31 - train_loss : 0.5094921117027601 and train_accuracy : 0.8638333082199097\n",
      "Evaluation : test_loss : 0.5013506710529327 and test_accuracy : 0.8592999577522278\n",
      "Epoch 32 - train_loss : 0.48794135202964145 and train_accuracy : 0.8706666827201843\n",
      "Evaluation : test_loss : 0.48009024411439893 and test_accuracy : 0.8643999695777893\n",
      "Epoch 33 - train_loss : 0.46861016501983005 and train_accuracy : 0.875\n",
      "Evaluation : test_loss : 0.46500993221998216 and test_accuracy : 0.8679999709129333\n",
      "Epoch 34 - train_loss : 0.44901171574989956 and train_accuracy : 0.8801666498184204\n",
      "Evaluation : test_loss : 0.4483540952205658 and test_accuracy : 0.8718000054359436\n",
      "Epoch 35 - train_loss : 0.43351079026858014 and train_accuracy : 0.8848333358764648\n",
      "Evaluation : test_loss : 0.4333160310983658 and test_accuracy : 0.8761999607086182\n",
      "Epoch 36 - train_loss : 0.4194134200612704 and train_accuracy : 0.8886666297912598\n",
      "Evaluation : test_loss : 0.4228213667869568 and test_accuracy : 0.8777999877929688\n",
      "Epoch 37 - train_loss : 0.40442806482315063 and train_accuracy : 0.8901666402816772\n",
      "Evaluation : test_loss : 0.4078574001789093 and test_accuracy : 0.8830999732017517\n",
      "Epoch 38 - train_loss : 0.39287174741427106 and train_accuracy : 0.893666684627533\n",
      "Evaluation : test_loss : 0.3984041064977646 and test_accuracy : 0.886199951171875\n",
      "Epoch 39 - train_loss : 0.38268523663282394 and train_accuracy : 0.8933333158493042\n",
      "Evaluation : test_loss : 0.3887979030609131 and test_accuracy : 0.8863999843597412\n",
      "Epoch 40 - train_loss : 0.37201429158449173 and train_accuracy : 0.9003333449363708\n",
      "Evaluation : test_loss : 0.3790712893009186 and test_accuracy : 0.8883000016212463\n",
      "Epoch 41 - train_loss : 0.3601233859856923 and train_accuracy : 0.9013333320617676\n",
      "Evaluation : test_loss : 0.37329932898283 and test_accuracy : 0.8876999616622925\n",
      "Epoch 42 - train_loss : 0.3512074078122775 and train_accuracy : 0.906166672706604\n",
      "Evaluation : test_loss : 0.36166643500328066 and test_accuracy : 0.8933999538421631\n",
      "Epoch 43 - train_loss : 0.34380151828130084 and train_accuracy : 0.9045000076293945\n",
      "Evaluation : test_loss : 0.3566048786044121 and test_accuracy : 0.8955999612808228\n",
      "Epoch 44 - train_loss : 0.3335072596867879 and train_accuracy : 0.9078333377838135\n",
      "Evaluation : test_loss : 0.34629035741090775 and test_accuracy : 0.8988999724388123\n",
      "Epoch 45 - train_loss : 0.32562458018461865 and train_accuracy : 0.9091666340827942\n",
      "Evaluation : test_loss : 0.33754896819591523 and test_accuracy : 0.8996999859809875\n",
      "Epoch 46 - train_loss : 0.32102325807015103 and train_accuracy : 0.9133332967758179\n",
      "Evaluation : test_loss : 0.33187998831272125 and test_accuracy : 0.901699960231781\n",
      "Epoch 47 - train_loss : 0.3096712455153465 and train_accuracy : 0.9121666550636292\n",
      "Evaluation : test_loss : 0.3261337488889694 and test_accuracy : 0.905299961566925\n",
      "Epoch 48 - train_loss : 0.30595944325129193 and train_accuracy : 0.9136666655540466\n",
      "Evaluation : test_loss : 0.3194334119558334 and test_accuracy : 0.9053999781608582\n",
      "Epoch 49 - train_loss : 0.2958097718656063 and train_accuracy : 0.9161666631698608\n",
      "Evaluation : test_loss : 0.31551236659288406 and test_accuracy : 0.9066999554634094\n",
      "Epoch 50 - train_loss : 0.29039029280344647 and train_accuracy : 0.9183333516120911\n",
      "Evaluation : test_loss : 0.30896822065114976 and test_accuracy : 0.90829998254776\n",
      "Epoch 51 - train_loss : 0.2837904430925846 and train_accuracy : 0.9210000038146973\n",
      "Evaluation : test_loss : 0.30660357400774957 and test_accuracy : 0.9101999998092651\n",
      "Epoch 52 - train_loss : 0.2785835775236289 and train_accuracy : 0.918666660785675\n",
      "Evaluation : test_loss : 0.2991936609148979 and test_accuracy : 0.911899983882904\n",
      "Epoch 53 - train_loss : 0.27624716733892757 and train_accuracy : 0.9193333387374878\n",
      "Evaluation : test_loss : 0.2927223853766918 and test_accuracy : 0.911899983882904\n",
      "Epoch 54 - train_loss : 0.26629379640022915 and train_accuracy : 0.9239999651908875\n",
      "Evaluation : test_loss : 0.2884676031768322 and test_accuracy : 0.913100004196167\n",
      "Epoch 55 - train_loss : 0.2623838360110919 and train_accuracy : 0.9243333339691162\n",
      "Evaluation : test_loss : 0.28604408726096153 and test_accuracy : 0.9145999550819397\n",
      "Epoch 56 - train_loss : 0.25638819734255475 and train_accuracy : 0.9244999885559082\n",
      "Evaluation : test_loss : 0.28528911992907524 and test_accuracy : 0.9138000011444092\n",
      "Epoch 57 - train_loss : 0.2513879102965196 and train_accuracy : 0.9264999628067017\n",
      "Evaluation : test_loss : 0.2786098539829254 and test_accuracy : 0.9162999987602234\n",
      "Epoch 58 - train_loss : 0.24765565122167268 and train_accuracy : 0.9271666407585144\n",
      "Evaluation : test_loss : 0.27247231975197794 and test_accuracy : 0.9193999767303467\n",
      "Epoch 59 - train_loss : 0.24393184234698614 and train_accuracy : 0.9288333058357239\n",
      "Evaluation : test_loss : 0.2708335712552071 and test_accuracy : 0.9187999963760376\n",
      "Epoch 60 - train_loss : 0.23850818102558455 and train_accuracy : 0.9304999709129333\n",
      "Evaluation : test_loss : 0.26636656150221827 and test_accuracy : 0.9192999601364136\n",
      "Epoch 61 - train_loss : 0.23419931158423424 and train_accuracy : 0.9298333525657654\n",
      "Evaluation : test_loss : 0.26757566034793856 and test_accuracy : 0.9211999773979187\n",
      "Epoch 62 - train_loss : 0.2308487705886364 and train_accuracy : 0.9293333292007446\n",
      "Evaluation : test_loss : 0.26184423118829725 and test_accuracy : 0.9210000038146973\n",
      "Epoch 63 - train_loss : 0.22627220302820206 and train_accuracy : 0.9340000152587891\n",
      "Evaluation : test_loss : 0.2576237514615059 and test_accuracy : 0.9236999750137329\n",
      "Epoch 64 - train_loss : 0.22351383417844772 and train_accuracy : 0.9353333115577698\n",
      "Evaluation : test_loss : 0.2542404502630234 and test_accuracy : 0.9236999750137329\n",
      "Epoch 65 - train_loss : 0.22063194091121355 and train_accuracy : 0.9365000128746033\n",
      "Evaluation : test_loss : 0.25074100121855736 and test_accuracy : 0.924299955368042\n",
      "Epoch 66 - train_loss : 0.21774787083268166 and train_accuracy : 0.9393333196640015\n",
      "Evaluation : test_loss : 0.24897056072950363 and test_accuracy : 0.9247999787330627\n",
      "Epoch 67 - train_loss : 0.21185011665026346 and train_accuracy : 0.9391666650772095\n",
      "Evaluation : test_loss : 0.24457821175456046 and test_accuracy : 0.9266999959945679\n",
      "Epoch 68 - train_loss : 0.20935052136580148 and train_accuracy : 0.9369999766349792\n",
      "Evaluation : test_loss : 0.25089971497654917 and test_accuracy : 0.9222999811172485\n",
      "Epoch 69 - train_loss : 0.20801957820852598 and train_accuracy : 0.937833309173584\n",
      "Evaluation : test_loss : 0.2447194956243038 and test_accuracy : 0.925599992275238\n",
      "Epoch 70 - train_loss : 0.2045419787367185 and train_accuracy : 0.940666675567627\n",
      "Evaluation : test_loss : 0.24191542118787765 and test_accuracy : 0.9275999665260315\n",
      "Epoch 71 - train_loss : 0.19864878555138907 and train_accuracy : 0.9438333511352539\n",
      "Evaluation : test_loss : 0.23389313220977784 and test_accuracy : 0.9286999702453613\n",
      "Epoch 72 - train_loss : 0.19406983132163683 and train_accuracy : 0.9455000162124634\n",
      "Evaluation : test_loss : 0.23009839355945588 and test_accuracy : 0.9289999604225159\n",
      "Epoch 73 - train_loss : 0.19200037295619646 and train_accuracy : 0.9465000033378601\n",
      "Evaluation : test_loss : 0.22883935868740082 and test_accuracy : 0.9300999641418457\n",
      "Epoch 74 - train_loss : 0.18906853968898454 and train_accuracy : 0.9444999694824219\n",
      "Evaluation : test_loss : 0.22723292782902718 and test_accuracy : 0.9303999543190002\n",
      "Epoch 75 - train_loss : 0.18498888984322548 and train_accuracy : 0.9471666812896729\n",
      "Evaluation : test_loss : 0.22600923106074333 and test_accuracy : 0.9302999973297119\n",
      "Epoch 76 - train_loss : 0.18403086438775063 and train_accuracy : 0.9461666345596313\n",
      "Evaluation : test_loss : 0.22417382895946503 and test_accuracy : 0.9305999875068665\n",
      "Epoch 77 - train_loss : 0.1813130502899488 and train_accuracy : 0.9478332996368408\n",
      "Evaluation : test_loss : 0.22373297363519667 and test_accuracy : 0.9320999979972839\n",
      "Epoch 78 - train_loss : 0.1789690082271894 and train_accuracy : 0.9496666789054871\n",
      "Evaluation : test_loss : 0.2206920087337494 and test_accuracy : 0.9328999519348145\n",
      "Epoch 79 - train_loss : 0.17611576740940413 and train_accuracy : 0.9481666684150696\n",
      "Evaluation : test_loss : 0.2191193975508213 and test_accuracy : 0.9334999918937683\n",
      "Epoch 80 - train_loss : 0.17535508424043655 and train_accuracy : 0.9491666555404663\n",
      "Evaluation : test_loss : 0.21786968931555747 and test_accuracy : 0.9334999918937683\n",
      "Epoch 81 - train_loss : 0.17153445382912955 and train_accuracy : 0.9526666402816772\n",
      "Evaluation : test_loss : 0.2125624231994152 and test_accuracy : 0.9340999722480774\n",
      "Epoch 82 - train_loss : 0.1679141769806544 and train_accuracy : 0.953666627407074\n",
      "Evaluation : test_loss : 0.21081078574061393 and test_accuracy : 0.9352999925613403\n",
      "Epoch 83 - train_loss : 0.16615348557631174 and train_accuracy : 0.953166663646698\n",
      "Evaluation : test_loss : 0.20911801904439925 and test_accuracy : 0.9352999925613403\n",
      "Epoch 84 - train_loss : 0.16444895416498184 and train_accuracy : 0.9566666483879089\n",
      "Evaluation : test_loss : 0.2059710904955864 and test_accuracy : 0.9359999895095825\n",
      "Epoch 85 - train_loss : 0.163007952272892 and train_accuracy : 0.9558333158493042\n",
      "Evaluation : test_loss : 0.20532141551375388 and test_accuracy : 0.9361000061035156\n",
      "Epoch 86 - train_loss : 0.16009985903898874 and train_accuracy : 0.9570000171661377\n",
      "Evaluation : test_loss : 0.20224594622850417 and test_accuracy : 0.9365999698638916\n",
      "Epoch 87 - train_loss : 0.157114556680123 and train_accuracy : 0.953499972820282\n",
      "Evaluation : test_loss : 0.2057746596634388 and test_accuracy : 0.936199963092804\n",
      "Epoch 88 - train_loss : 0.15819205964605013 and train_accuracy : 0.9573333263397217\n",
      "Evaluation : test_loss : 0.20078717470169066 and test_accuracy : 0.9389999508857727\n",
      "Epoch 89 - train_loss : 0.15311001986265182 and train_accuracy : 0.9570000171661377\n",
      "Evaluation : test_loss : 0.19922401756048203 and test_accuracy : 0.9386000037193298\n",
      "Epoch 90 - train_loss : 0.1511070461322864 and train_accuracy : 0.9581666588783264\n",
      "Evaluation : test_loss : 0.19854413866996765 and test_accuracy : 0.937999963760376\n",
      "Epoch 91 - train_loss : 0.14928615962465605 and train_accuracy : 0.9593333005905151\n",
      "Evaluation : test_loss : 0.19576987773180007 and test_accuracy : 0.9393999576568604\n",
      "Epoch 92 - train_loss : 0.14675407546261945 and train_accuracy : 0.9595000147819519\n",
      "Evaluation : test_loss : 0.1945183604955673 and test_accuracy : 0.9398999810218811\n",
      "Epoch 93 - train_loss : 0.1454402624318997 and train_accuracy : 0.9599999785423279\n",
      "Evaluation : test_loss : 0.19201042354106904 and test_accuracy : 0.9409999847412109\n",
      "Epoch 94 - train_loss : 0.14278508660693964 and train_accuracy : 0.9608333110809326\n",
      "Evaluation : test_loss : 0.19027329683303834 and test_accuracy : 0.9412999749183655\n",
      "Epoch 95 - train_loss : 0.142068970327576 and train_accuracy : 0.9614999890327454\n",
      "Evaluation : test_loss : 0.18884178400039672 and test_accuracy : 0.94159996509552\n",
      "Epoch 96 - train_loss : 0.13856722973287106 and train_accuracy : 0.9621666669845581\n",
      "Evaluation : test_loss : 0.1871810957789421 and test_accuracy : 0.9429999589920044\n",
      "Epoch 97 - train_loss : 0.13730850567420325 and train_accuracy : 0.9614999890327454\n",
      "Evaluation : test_loss : 0.18811016604304315 and test_accuracy : 0.9419999718666077\n",
      "Epoch 98 - train_loss : 0.13634729323287806 and train_accuracy : 0.9629999995231628\n",
      "Evaluation : test_loss : 0.18534545600414276 and test_accuracy : 0.942799985408783\n",
      "Epoch 99 - train_loss : 0.1337754831959804 and train_accuracy : 0.9643332958221436\n",
      "Evaluation : test_loss : 0.18731931149959563 and test_accuracy : 0.9430999755859375\n",
      "Epoch 100 - train_loss : 0.1332491139570872 and train_accuracy : 0.9641666412353516\n",
      "Evaluation : test_loss : 0.1838502362370491 and test_accuracy : 0.9423999786376953\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁▁▁▃▄▅▆▆▇▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>test_loss</td><td>████▇▆▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▁▁▂▄▅▆▆▆▇▇▇▇▇▇▇▇███████████████████████</td></tr><tr><td>train_loss</td><td>████▇▆▄▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.9424</td></tr><tr><td>test_loss</td><td>0.18385</td></tr><tr><td>train_accuracy</td><td>0.96417</td></tr><tr><td>train_loss</td><td>0.13325</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run-train_set_size-6000</strong> at: <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/c54q3lgz' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/c54q3lgz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240308_085129-c54q3lgz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/rkada/wandb/run-20240308_085414-jgyqli0j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/jgyqli0j' target=\"_blank\">run-train_set_size-18000</a></strong> to <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/jgyqli0j' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/jgyqli0j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - train_loss : 2.3098587327533298 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3022602438926696 and test_accuracy : 0.10279999673366547\n",
      "Epoch 2 - train_loss : 2.3040473461151123 and train_accuracy : 0.10000000149011612\n",
      "Evaluation : test_loss : 2.3029294490814207 and test_accuracy : 0.0973999947309494\n",
      "Epoch 3 - train_loss : 2.2928610377841525 and train_accuracy : 0.2872222363948822\n",
      "Evaluation : test_loss : 2.2568326354026795 and test_accuracy : 0.3034999966621399\n",
      "Epoch 4 - train_loss : 2.101136608256234 and train_accuracy : 0.38883334398269653\n",
      "Evaluation : test_loss : 1.8651157855987548 and test_accuracy : 0.40289998054504395\n",
      "Epoch 5 - train_loss : 1.6389732029702928 and train_accuracy : 0.597777783870697\n",
      "Evaluation : test_loss : 1.360921812057495 and test_accuracy : 0.6085999608039856\n",
      "Epoch 6 - train_loss : 1.1893251803186204 and train_accuracy : 0.7064444422721863\n",
      "Evaluation : test_loss : 0.9902430653572083 and test_accuracy : 0.7224999666213989\n",
      "Epoch 7 - train_loss : 0.914926184548272 and train_accuracy : 0.756944477558136\n",
      "Evaluation : test_loss : 0.7996996849775314 and test_accuracy : 0.7702999711036682\n",
      "Epoch 8 - train_loss : 0.7601763589514626 and train_accuracy : 0.7972222566604614\n",
      "Evaluation : test_loss : 0.674136283993721 and test_accuracy : 0.8036999702453613\n",
      "Epoch 9 - train_loss : 0.6514030032687717 and train_accuracy : 0.8346666693687439\n",
      "Evaluation : test_loss : 0.581119829416275 and test_accuracy : 0.8414999842643738\n",
      "Epoch 10 - train_loss : 0.5673787097136179 and train_accuracy : 0.8540000319480896\n",
      "Evaluation : test_loss : 0.5037248075008393 and test_accuracy : 0.8611999750137329\n",
      "Epoch 11 - train_loss : 0.49703876425822574 and train_accuracy : 0.8694999814033508\n",
      "Evaluation : test_loss : 0.45428020507097244 and test_accuracy : 0.8729999661445618\n",
      "Epoch 12 - train_loss : 0.4467088331778844 and train_accuracy : 0.8837777972221375\n",
      "Evaluation : test_loss : 0.3998092606663704 and test_accuracy : 0.8880999684333801\n",
      "Epoch 13 - train_loss : 0.4009091945158111 and train_accuracy : 0.8915555477142334\n",
      "Evaluation : test_loss : 0.3672261297702789 and test_accuracy : 0.8937999606132507\n",
      "Epoch 14 - train_loss : 0.3693404189414448 and train_accuracy : 0.9013888835906982\n",
      "Evaluation : test_loss : 0.3378760263323784 and test_accuracy : 0.9041999578475952\n",
      "Epoch 15 - train_loss : 0.34560444288783604 and train_accuracy : 0.9021111130714417\n",
      "Evaluation : test_loss : 0.3204027026891708 and test_accuracy : 0.903499960899353\n",
      "Epoch 16 - train_loss : 0.32076330358783406 and train_accuracy : 0.909500002861023\n",
      "Evaluation : test_loss : 0.2983099237084389 and test_accuracy : 0.911899983882904\n",
      "Epoch 17 - train_loss : 0.30162908964686924 and train_accuracy : 0.9154999852180481\n",
      "Evaluation : test_loss : 0.2783864766359329 and test_accuracy : 0.9169999957084656\n",
      "Epoch 18 - train_loss : 0.2866804483864043 and train_accuracy : 0.918666660785675\n",
      "Evaluation : test_loss : 0.2662358283996582 and test_accuracy : 0.9212999939918518\n",
      "Epoch 19 - train_loss : 0.2719917578829659 and train_accuracy : 0.9221110939979553\n",
      "Evaluation : test_loss : 0.2531079322099686 and test_accuracy : 0.9232999682426453\n",
      "Epoch 20 - train_loss : 0.25817056083016926 and train_accuracy : 0.9264444708824158\n",
      "Evaluation : test_loss : 0.24308007210493088 and test_accuracy : 0.9283999800682068\n",
      "Epoch 21 - train_loss : 0.24703132692310545 and train_accuracy : 0.9284444451332092\n",
      "Evaluation : test_loss : 0.23234187439084053 and test_accuracy : 0.9294999837875366\n",
      "Epoch 22 - train_loss : 0.23752701489461792 and train_accuracy : 0.9293333292007446\n",
      "Evaluation : test_loss : 0.2269232042133808 and test_accuracy : 0.9300999641418457\n",
      "Epoch 23 - train_loss : 0.22735019690460628 and train_accuracy : 0.9363889098167419\n",
      "Evaluation : test_loss : 0.21043671220541 and test_accuracy : 0.9352999925613403\n",
      "Epoch 24 - train_loss : 0.2173852961924341 and train_accuracy : 0.9380000233650208\n",
      "Evaluation : test_loss : 0.20758952721953391 and test_accuracy : 0.9363999962806702\n",
      "Epoch 25 - train_loss : 0.20902653162678084 and train_accuracy : 0.9398888945579529\n",
      "Evaluation : test_loss : 0.19679286628961562 and test_accuracy : 0.9391999840736389\n",
      "Epoch 26 - train_loss : 0.20067662414577273 and train_accuracy : 0.9406111240386963\n",
      "Evaluation : test_loss : 0.19532840475440025 and test_accuracy : 0.94159996509552\n",
      "Epoch 27 - train_loss : 0.19428899180557993 and train_accuracy : 0.9438333511352539\n",
      "Evaluation : test_loss : 0.1845768854022026 and test_accuracy : 0.9429999589920044\n",
      "Epoch 28 - train_loss : 0.1864857864048746 and train_accuracy : 0.9465555548667908\n",
      "Evaluation : test_loss : 0.17859922349452972 and test_accuracy : 0.9455999732017517\n",
      "Epoch 29 - train_loss : 0.18074333460794556 and train_accuracy : 0.9482777714729309\n",
      "Evaluation : test_loss : 0.17188454195857047 and test_accuracy : 0.9472000002861023\n",
      "Epoch 30 - train_loss : 0.17520591368277869 and train_accuracy : 0.9481111168861389\n",
      "Evaluation : test_loss : 0.1714625246822834 and test_accuracy : 0.948699951171875\n",
      "Epoch 31 - train_loss : 0.17052454004685083 and train_accuracy : 0.951888918876648\n",
      "Evaluation : test_loss : 0.16236922070384024 and test_accuracy : 0.9485999941825867\n",
      "Epoch 32 - train_loss : 0.1647302479379707 and train_accuracy : 0.9536111354827881\n",
      "Evaluation : test_loss : 0.16082653403282166 and test_accuracy : 0.9501999616622925\n",
      "Epoch 33 - train_loss : 0.1573500877453221 and train_accuracy : 0.9541110992431641\n",
      "Evaluation : test_loss : 0.15643043518066407 and test_accuracy : 0.9517999887466431\n",
      "Epoch 34 - train_loss : 0.1532453749742773 and train_accuracy : 0.9566110968589783\n",
      "Evaluation : test_loss : 0.15020826198160647 and test_accuracy : 0.9538999795913696\n",
      "Epoch 35 - train_loss : 0.14917419147160318 and train_accuracy : 0.957277774810791\n",
      "Evaluation : test_loss : 0.15024575106799604 and test_accuracy : 0.9530999660491943\n",
      "Epoch 36 - train_loss : 0.14449548286696276 and train_accuracy : 0.9596666693687439\n",
      "Evaluation : test_loss : 0.14277073480188845 and test_accuracy : 0.957099974155426\n",
      "Epoch 37 - train_loss : 0.14027717316316235 and train_accuracy : 0.9603333473205566\n",
      "Evaluation : test_loss : 0.1382258240133524 and test_accuracy : 0.9583999514579773\n",
      "Epoch 38 - train_loss : 0.13811994613044792 and train_accuracy : 0.96061110496521\n",
      "Evaluation : test_loss : 0.1368449956178665 and test_accuracy : 0.9590999484062195\n",
      "Epoch 39 - train_loss : 0.13333762043880093 and train_accuracy : 0.9625555872917175\n",
      "Evaluation : test_loss : 0.13308093175292016 and test_accuracy : 0.960599958896637\n",
      "Epoch 40 - train_loss : 0.12884915164775318 and train_accuracy : 0.9633889198303223\n",
      "Evaluation : test_loss : 0.1341113768517971 and test_accuracy : 0.9589999914169312\n",
      "Epoch 41 - train_loss : 0.12708511079351106 and train_accuracy : 0.9634444713592529\n",
      "Evaluation : test_loss : 0.13247045800089835 and test_accuracy : 0.9610999822616577\n",
      "Epoch 42 - train_loss : 0.1226605193482505 and train_accuracy : 0.9667778015136719\n",
      "Evaluation : test_loss : 0.12332546152174473 and test_accuracy : 0.9619999527931213\n",
      "Epoch 43 - train_loss : 0.11939244179262055 and train_accuracy : 0.9658333659172058\n",
      "Evaluation : test_loss : 0.12521432489156722 and test_accuracy : 0.9610999822616577\n",
      "Epoch 44 - train_loss : 0.11774079625805219 and train_accuracy : 0.9657222032546997\n",
      "Evaluation : test_loss : 0.12139938324689865 and test_accuracy : 0.9645999670028687\n",
      "Epoch 45 - train_loss : 0.11244094785716799 and train_accuracy : 0.9680555462837219\n",
      "Evaluation : test_loss : 0.12031460292637348 and test_accuracy : 0.9639999866485596\n",
      "Epoch 46 - train_loss : 0.11007278847197692 and train_accuracy : 0.9694444537162781\n",
      "Evaluation : test_loss : 0.11411439813673496 and test_accuracy : 0.9650999903678894\n",
      "Epoch 47 - train_loss : 0.10634589961005582 and train_accuracy : 0.9697777628898621\n",
      "Evaluation : test_loss : 0.11020161397755146 and test_accuracy : 0.9660999774932861\n",
      "Epoch 48 - train_loss : 0.10455620350937049 and train_accuracy : 0.9710000157356262\n",
      "Evaluation : test_loss : 0.10936874784529209 and test_accuracy : 0.9659000039100647\n",
      "Epoch 49 - train_loss : 0.10345695747269525 and train_accuracy : 0.9716111421585083\n",
      "Evaluation : test_loss : 0.10699373446404933 and test_accuracy : 0.9667999744415283\n",
      "Epoch 50 - train_loss : 0.09980315715074539 and train_accuracy : 0.971500039100647\n",
      "Evaluation : test_loss : 0.10912106931209564 and test_accuracy : 0.9666000008583069\n",
      "Epoch 51 - train_loss : 0.09773703581757015 and train_accuracy : 0.9699444770812988\n",
      "Evaluation : test_loss : 0.11376959234476089 and test_accuracy : 0.9630999565124512\n",
      "Epoch 52 - train_loss : 0.09408227302547958 and train_accuracy : 0.9740000367164612\n",
      "Evaluation : test_loss : 0.10357488431036473 and test_accuracy : 0.9687999486923218\n",
      "Epoch 53 - train_loss : 0.09177814361949761 and train_accuracy : 0.9743888974189758\n",
      "Evaluation : test_loss : 0.10133226923644542 and test_accuracy : 0.9690999984741211\n",
      "Epoch 54 - train_loss : 0.08851083326670858 and train_accuracy : 0.9750000238418579\n",
      "Evaluation : test_loss : 0.09767589699476957 and test_accuracy : 0.9688999652862549\n",
      "Epoch 55 - train_loss : 0.08930035597748226 and train_accuracy : 0.9740000367164612\n",
      "Evaluation : test_loss : 0.10036954898387193 and test_accuracy : 0.9686999917030334\n",
      "Epoch 56 - train_loss : 0.08543008327898052 and train_accuracy : 0.9764444828033447\n",
      "Evaluation : test_loss : 0.09619062468409538 and test_accuracy : 0.9705999493598938\n",
      "Epoch 57 - train_loss : 0.08396456607927878 and train_accuracy : 0.9764444828033447\n",
      "Evaluation : test_loss : 0.0992213811725378 and test_accuracy : 0.9675999879837036\n",
      "Epoch 58 - train_loss : 0.0813428589867221 and train_accuracy : 0.9781111478805542\n",
      "Evaluation : test_loss : 0.09211798645555973 and test_accuracy : 0.9710999727249146\n",
      "Epoch 59 - train_loss : 0.0790747922534744 and train_accuracy : 0.9785555601119995\n",
      "Evaluation : test_loss : 0.09055643212050199 and test_accuracy : 0.9721999764442444\n",
      "Epoch 60 - train_loss : 0.07797984126955271 and train_accuracy : 0.97688889503479\n",
      "Evaluation : test_loss : 0.09322751685976982 and test_accuracy : 0.9716999530792236\n",
      "Epoch 61 - train_loss : 0.07652644792364703 and train_accuracy : 0.9788889288902283\n",
      "Evaluation : test_loss : 0.08978034015744925 and test_accuracy : 0.9717999696731567\n",
      "Epoch 62 - train_loss : 0.07342316479318672 and train_accuracy : 0.979722261428833\n",
      "Evaluation : test_loss : 0.09044186659157276 and test_accuracy : 0.9714999794960022\n",
      "Epoch 63 - train_loss : 0.0730046954833799 and train_accuracy : 0.9812222123146057\n",
      "Evaluation : test_loss : 0.08637791350483895 and test_accuracy : 0.9727999567985535\n",
      "Epoch 64 - train_loss : 0.07043667003098461 and train_accuracy : 0.9806111454963684\n",
      "Evaluation : test_loss : 0.08766389656811953 and test_accuracy : 0.972000002861023\n",
      "Epoch 65 - train_loss : 0.0688242395925853 and train_accuracy : 0.9815000295639038\n",
      "Evaluation : test_loss : 0.08496665712445975 and test_accuracy : 0.9732999801635742\n",
      "Epoch 66 - train_loss : 0.06826852199931939 and train_accuracy : 0.9794444441795349\n",
      "Evaluation : test_loss : 0.09257526472210884 and test_accuracy : 0.9700999855995178\n",
      "Epoch 67 - train_loss : 0.06730314054422909 and train_accuracy : 0.9816111326217651\n",
      "Evaluation : test_loss : 0.08653991930186748 and test_accuracy : 0.9723999500274658\n",
      "Epoch 68 - train_loss : 0.06474894047197369 and train_accuracy : 0.983222246170044\n",
      "Evaluation : test_loss : 0.08052814770489931 and test_accuracy : 0.9749999642372131\n",
      "Epoch 69 - train_loss : 0.06227949561758174 and train_accuracy : 0.9836111068725586\n",
      "Evaluation : test_loss : 0.07997419498860836 and test_accuracy : 0.9740999937057495\n",
      "Epoch 70 - train_loss : 0.06337741208780143 and train_accuracy : 0.983055591583252\n",
      "Evaluation : test_loss : 0.08302507568150759 and test_accuracy : 0.9741999506950378\n",
      "Epoch 71 - train_loss : 0.061649151146411896 and train_accuracy : 0.9823333621025085\n",
      "Evaluation : test_loss : 0.08431244380772114 and test_accuracy : 0.9728999733924866\n",
      "Epoch 72 - train_loss : 0.059409975022491485 and train_accuracy : 0.984499990940094\n",
      "Evaluation : test_loss : 0.07810922805219889 and test_accuracy : 0.9753999710083008\n",
      "Epoch 73 - train_loss : 0.0577506163261003 and train_accuracy : 0.9847778081893921\n",
      "Evaluation : test_loss : 0.08254819251596927 and test_accuracy : 0.974299967288971\n",
      "Epoch 74 - train_loss : 0.057218524213466376 and train_accuracy : 0.9835555553436279\n",
      "Evaluation : test_loss : 0.08179785683751106 and test_accuracy : 0.974299967288971\n",
      "Epoch 75 - train_loss : 0.05568310064781043 and train_accuracy : 0.98416668176651\n",
      "Evaluation : test_loss : 0.07732337601482868 and test_accuracy : 0.976099967956543\n",
      "Epoch 76 - train_loss : 0.053794675765352115 and train_accuracy : 0.9847222566604614\n",
      "Evaluation : test_loss : 0.07694502174854279 and test_accuracy : 0.9758999943733215\n",
      "Epoch 77 - train_loss : 0.05286832572892308 and train_accuracy : 0.9847778081893921\n",
      "Evaluation : test_loss : 0.07727111652493476 and test_accuracy : 0.9749999642372131\n",
      "Epoch 78 - train_loss : 0.05210057304551204 and train_accuracy : 0.9866111278533936\n",
      "Evaluation : test_loss : 0.07505653519183397 and test_accuracy : 0.976699948310852\n",
      "Epoch 79 - train_loss : 0.051093025184753865 and train_accuracy : 0.9874444603919983\n",
      "Evaluation : test_loss : 0.07279992057010531 and test_accuracy : 0.9767999649047852\n",
      "Epoch 80 - train_loss : 0.04784501726842589 and train_accuracy : 0.987500011920929\n",
      "Evaluation : test_loss : 0.07131236176937819 and test_accuracy : 0.9770999550819397\n",
      "Epoch 81 - train_loss : 0.04951480470804705 and train_accuracy : 0.9885555505752563\n",
      "Evaluation : test_loss : 0.07083291634917259 and test_accuracy : 0.9783999919891357\n",
      "Epoch 82 - train_loss : 0.04719831965242823 and train_accuracy : 0.987500011920929\n",
      "Evaluation : test_loss : 0.07266911044716835 and test_accuracy : 0.9771999716758728\n",
      "Epoch 83 - train_loss : 0.04588932300814324 and train_accuracy : 0.9882222414016724\n",
      "Evaluation : test_loss : 0.07455954384058713 and test_accuracy : 0.975600004196167\n",
      "Epoch 84 - train_loss : 0.04514903295785189 and train_accuracy : 0.9894999861717224\n",
      "Evaluation : test_loss : 0.07114608641713857 and test_accuracy : 0.9775999784469604\n",
      "Epoch 85 - train_loss : 0.042874329102536045 and train_accuracy : 0.9891666769981384\n",
      "Evaluation : test_loss : 0.07174225449562073 and test_accuracy : 0.9782999753952026\n",
      "Epoch 86 - train_loss : 0.04251202056184411 and train_accuracy : 0.9904444813728333\n",
      "Evaluation : test_loss : 0.07089903932064771 and test_accuracy : 0.9774999618530273\n",
      "Epoch 87 - train_loss : 0.042280266992747784 and train_accuracy : 0.9908888936042786\n",
      "Evaluation : test_loss : 0.06849077735096216 and test_accuracy : 0.9781999588012695\n",
      "Epoch 88 - train_loss : 0.040911453439750604 and train_accuracy : 0.9892222285270691\n",
      "Evaluation : test_loss : 0.07267934121191502 and test_accuracy : 0.9758999943733215\n",
      "Epoch 89 - train_loss : 0.040264691691845655 and train_accuracy : 0.988444447517395\n",
      "Evaluation : test_loss : 0.07233627568930387 and test_accuracy : 0.9770999550819397\n",
      "Epoch 90 - train_loss : 0.04043326180221306 and train_accuracy : 0.9887778162956238\n",
      "Evaluation : test_loss : 0.06889167968183756 and test_accuracy : 0.9792999625205994\n",
      "Epoch 91 - train_loss : 0.03864412082152234 and train_accuracy : 0.991944432258606\n",
      "Evaluation : test_loss : 0.06682894509285689 and test_accuracy : 0.9783999919891357\n",
      "Epoch 92 - train_loss : 0.03726651560929087 and train_accuracy : 0.991944432258606\n",
      "Evaluation : test_loss : 0.06683982815593481 and test_accuracy : 0.9790999889373779\n",
      "Epoch 93 - train_loss : 0.03649173935668336 and train_accuracy : 0.9903888702392578\n",
      "Evaluation : test_loss : 0.06796097103506327 and test_accuracy : 0.9788999557495117\n",
      "Epoch 94 - train_loss : 0.036910922887424626 and train_accuracy : 0.9894999861717224\n",
      "Evaluation : test_loss : 0.07152078561484813 and test_accuracy : 0.9769999980926514\n",
      "Epoch 95 - train_loss : 0.035387032872272864 and train_accuracy : 0.9926666617393494\n",
      "Evaluation : test_loss : 0.0674650008790195 and test_accuracy : 0.9781000018119812\n",
      "Epoch 96 - train_loss : 0.034355004162838064 and train_accuracy : 0.9932777881622314\n",
      "Evaluation : test_loss : 0.06611759932711721 and test_accuracy : 0.9791999459266663\n",
      "Epoch 97 - train_loss : 0.034092673359231815 and train_accuracy : 0.9930000305175781\n",
      "Evaluation : test_loss : 0.06659551337361336 and test_accuracy : 0.9789999723434448\n",
      "Epoch 98 - train_loss : 0.032158276790546045 and train_accuracy : 0.9928889274597168\n",
      "Evaluation : test_loss : 0.06627795789390803 and test_accuracy : 0.9786999821662903\n",
      "Epoch 99 - train_loss : 0.032053044686714806 and train_accuracy : 0.9930000305175781\n",
      "Evaluation : test_loss : 0.06633308064192533 and test_accuracy : 0.9791999459266663\n",
      "Epoch 100 - train_loss : 0.030834364756527875 and train_accuracy : 0.9930000305175781\n",
      "Evaluation : test_loss : 0.06509742699563503 and test_accuracy : 0.9782999753952026\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁▃▆▇▇▇▇█████████████████████████████████</td></tr><tr><td>test_loss</td><td>██▄▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▂▆▆▇▇▇▇▇███████████████████████████████</td></tr><tr><td>train_loss</td><td>██▅▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.9783</td></tr><tr><td>test_loss</td><td>0.0651</td></tr><tr><td>train_accuracy</td><td>0.993</td></tr><tr><td>train_loss</td><td>0.03083</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run-train_set_size-18000</strong> at: <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/jgyqli0j' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/jgyqli0j</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240308_085414-jgyqli0j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m LeNet()\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 6\u001b[0m X,y \u001b[38;5;241m=\u001b[39m \u001b[43msample_mnist\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampling_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m train_set_ \u001b[38;5;241m=\u001b[39m DatasetSampled(X,y,transform\u001b[38;5;241m=\u001b[39mToTensor())\n\u001b[1;32m      8\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_set_,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m,shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m, in \u001b[0;36msample_mnist\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      3\u001b[0m X, y \u001b[38;5;241m=\u001b[39m train_set\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy(), np\u001b[38;5;241m.\u001b[39marray(train_set\u001b[38;5;241m.\u001b[39mtargets)\n\u001b[1;32m      5\u001b[0m class_indices \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mwhere(y \u001b[38;5;241m==\u001b[39m i)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m)]\n\u001b[0;32m----> 7\u001b[0m sampled_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(indices, x \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m10\u001b[39m, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m indices \u001b[38;5;129;01min\u001b[39;00m class_indices])\n\u001b[1;32m      9\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(sampled_indices)\n\u001b[1;32m     11\u001b[0m sampled_X \u001b[38;5;241m=\u001b[39m X[sampled_indices]\n",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m X, y \u001b[38;5;241m=\u001b[39m train_set\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy(), np\u001b[38;5;241m.\u001b[39marray(train_set\u001b[38;5;241m.\u001b[39mtargets)\n\u001b[1;32m      5\u001b[0m class_indices \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mwhere(y \u001b[38;5;241m==\u001b[39m i)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m)]\n\u001b[0;32m----> 7\u001b[0m sampled_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m indices \u001b[38;5;129;01min\u001b[39;00m class_indices])\n\u001b[1;32m      9\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(sampled_indices)\n\u001b[1;32m     11\u001b[0m sampled_X \u001b[38;5;241m=\u001b[39m X[sampled_indices]\n",
      "File \u001b[0;32mmtrand.pyx:984\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "for sampling_size in train_sampling:\n",
    "    \n",
    "    model = LeNet()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    X,y = sample_mnist(sampling_size)\n",
    "    train_set_ = DatasetSampled(X,y,transform=ToTensor())\n",
    "    train_loader = DataLoader(train_set_,batch_size=500,shuffle=True)\n",
    "    test_loader = DataLoader(test_set,batch_size=500,shuffle=True)\n",
    "\n",
    "    train_test_kit = train_test(model = model , train_loader = train_loader, test_loader = test_loader ,project_name=\"CV-assignment-2\",run_name=f\"run-train_set_size-{sampling_size}\",lr = 0.001,optimizer=\"Adam-vanilla\",iswandb=1)\n",
    "    train_test_kit.train(num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/rkada/wandb/run-20240308_095105-218swexn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/218swexn' target=\"_blank\">run-train_set_size-60000</a></strong> to <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/218swexn' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/218swexn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - train_loss : 2.299263121684392 and train_accuracy : 0.2266666740179062\n",
      "Evaluation : test_loss : 2.2408687829971314 and test_accuracy : 0.23339998722076416\n",
      "Epoch 2 - train_loss : 1.4317157094677289 and train_accuracy : 0.7478166818618774\n",
      "Evaluation : test_loss : 0.8510778307914734 and test_accuracy : 0.7562999725341797\n",
      "Epoch 3 - train_loss : 0.6706655859947205 and train_accuracy : 0.8606166839599609\n",
      "Evaluation : test_loss : 0.5015702798962594 and test_accuracy : 0.8657000064849854\n",
      "Epoch 4 - train_loss : 0.426322714984417 and train_accuracy : 0.8974166512489319\n",
      "Evaluation : test_loss : 0.3477271094918251 and test_accuracy : 0.9009999632835388\n",
      "Epoch 5 - train_loss : 0.32156705198188623 and train_accuracy : 0.9168166518211365\n",
      "Evaluation : test_loss : 0.2769922465085983 and test_accuracy : 0.917199969291687\n",
      "Epoch 6 - train_loss : 0.2660189662128687 and train_accuracy : 0.925433337688446\n",
      "Evaluation : test_loss : 0.2376519463956356 and test_accuracy : 0.9289999604225159\n",
      "Epoch 7 - train_loss : 0.23038690090179442 and train_accuracy : 0.9356499910354614\n",
      "Evaluation : test_loss : 0.20944651812314988 and test_accuracy : 0.9365999698638916\n",
      "Epoch 8 - train_loss : 0.20387474869688352 and train_accuracy : 0.942716658115387\n",
      "Evaluation : test_loss : 0.18137423172593117 and test_accuracy : 0.9430999755859375\n",
      "Epoch 9 - train_loss : 0.18277708167831103 and train_accuracy : 0.9479333162307739\n",
      "Evaluation : test_loss : 0.1670071393251419 and test_accuracy : 0.9491999745368958\n",
      "Epoch 10 - train_loss : 0.16534314714372159 and train_accuracy : 0.9524333477020264\n",
      "Evaluation : test_loss : 0.15184344984591008 and test_accuracy : 0.9545999765396118\n",
      "Epoch 11 - train_loss : 0.15153989860167105 and train_accuracy : 0.9544833302497864\n",
      "Evaluation : test_loss : 0.14499088898301124 and test_accuracy : 0.9547999501228333\n",
      "Epoch 12 - train_loss : 0.13989755567163228 and train_accuracy : 0.9600499868392944\n",
      "Evaluation : test_loss : 0.13081470057368277 and test_accuracy : 0.9592999815940857\n",
      "Epoch 13 - train_loss : 0.1295637569700678 and train_accuracy : 0.9596166610717773\n",
      "Evaluation : test_loss : 0.13095076866447924 and test_accuracy : 0.9596999883651733\n",
      "Epoch 14 - train_loss : 0.12094972605506579 and train_accuracy : 0.9662333726882935\n",
      "Evaluation : test_loss : 0.11509649157524109 and test_accuracy : 0.965499997138977\n",
      "Epoch 15 - train_loss : 0.11217015764365594 and train_accuracy : 0.9678833484649658\n",
      "Evaluation : test_loss : 0.10575327686965466 and test_accuracy : 0.967799961566925\n",
      "Epoch 16 - train_loss : 0.10559471612796187 and train_accuracy : 0.9700666666030884\n",
      "Evaluation : test_loss : 0.09984218329191208 and test_accuracy : 0.9698999524116516\n",
      "Epoch 17 - train_loss : 0.09865806816766659 and train_accuracy : 0.9715166687965393\n",
      "Evaluation : test_loss : 0.09547542221844196 and test_accuracy : 0.9703999757766724\n",
      "Epoch 18 - train_loss : 0.09461730448529124 and train_accuracy : 0.9728500247001648\n",
      "Evaluation : test_loss : 0.0951620802283287 and test_accuracy : 0.9715999960899353\n",
      "Epoch 19 - train_loss : 0.08797568595036864 and train_accuracy : 0.973716676235199\n",
      "Evaluation : test_loss : 0.08979429099708795 and test_accuracy : 0.9727999567985535\n",
      "Epoch 20 - train_loss : 0.08411693402255575 and train_accuracy : 0.975600004196167\n",
      "Evaluation : test_loss : 0.08347835019230843 and test_accuracy : 0.9753999710083008\n",
      "Epoch 21 - train_loss : 0.08040188010782004 and train_accuracy : 0.9779000282287598\n",
      "Evaluation : test_loss : 0.07922456972301006 and test_accuracy : 0.9757999777793884\n",
      "Epoch 22 - train_loss : 0.07573124896734953 and train_accuracy : 0.9786666631698608\n",
      "Evaluation : test_loss : 0.0755139585584402 and test_accuracy : 0.9769999980926514\n",
      "Epoch 23 - train_loss : 0.0723952781719466 and train_accuracy : 0.9794999957084656\n",
      "Evaluation : test_loss : 0.07438607588410377 and test_accuracy : 0.9774999618530273\n",
      "Epoch 24 - train_loss : 0.0695527751930058 and train_accuracy : 0.980650007724762\n",
      "Evaluation : test_loss : 0.06900724805891514 and test_accuracy : 0.9777999520301819\n",
      "Epoch 25 - train_loss : 0.06678115806231896 and train_accuracy : 0.9815833568572998\n",
      "Evaluation : test_loss : 0.06883005108684301 and test_accuracy : 0.9793999791145325\n",
      "Epoch 26 - train_loss : 0.06388583068425456 and train_accuracy : 0.9815999865531921\n",
      "Evaluation : test_loss : 0.06718601565808058 and test_accuracy : 0.9787999987602234\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Taking train set of original 60000 images\n",
    "\"\"\"\n",
    "model = LeNet()\n",
    "model = model.to(device)\n",
    "    \n",
    "train_loader = DataLoader(train_set,batch_size=500,shuffle=True)\n",
    "test_loader = DataLoader(test_set,batch_size=500,shuffle=True)\n",
    "\n",
    "train_test_kit = train_test(model = model , train_loader = train_loader, test_loader = test_loader ,project_name=\"CV-assignment-2\",run_name=f\"run-train_set_size-{sampling_size}\",lr = 0.001,optimizer=\"Adam-vanilla\",iswandb=1)\n",
    "train_test_kit.train(num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace CNN model with Transformer Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a ViT based model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViT(nn.Module):\n",
    "    def __init__(self,image_shape=(28,28),patch_size=14,hd=32,outd=10,nhead=4,n_layers=2):\n",
    "        super(ViT,self).__init__()\n",
    "        self.image_shape = image_shape\n",
    "        self.patch_size = patch_size\n",
    "        self.patch_pixels = patch_size*patch_size\n",
    "        self.num_patches = (image_shape[0]//patch_size) ** 2\n",
    "        self.hd = hd\n",
    "        self.outd = outd\n",
    "\n",
    "        self.LinearProjection = nn.Linear(self.patch_pixels,self.hd)\n",
    "        # For CLS encoding\n",
    "        self.CLS = nn.Parameter(torch.rand(1,self.hd))\n",
    "\n",
    "        # For POS embedding\n",
    "        self.POS = torch.rand(1+self.num_patches, self.hd).to(device)\n",
    "        \n",
    "        self.transformer_encoder = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=self.hd, nhead=nhead, dim_feedforward=self.hd,dropout=0.2,batch_first=True), num_layers=n_layers)\n",
    "\n",
    "        # MLP head\n",
    "        assert self.hd//2 >= outd\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.Linear(self.hd,self.hd//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.hd//2,self.outd)\n",
    "        ) \n",
    "    \n",
    "    def forward(self,input):\n",
    "        patches = input.unfold(2, self.patch_size, self.patch_size).unfold(3, self.patch_size, self.patch_size)\n",
    "        patches = patches.reshape(input.size(0),-1,self.patch_size, self.patch_size)\n",
    "        patches = patches.view(input.size(0),-1,self.patch_size*self.patch_size)\n",
    "\n",
    "        N = input.shape[0]\n",
    "        emb = self.LinearProjection(patches)\n",
    "        emb_cls = self.CLS.repeat(N,1,1)\n",
    "        emb = torch.cat([emb_cls,emb],dim=1)\n",
    "        \n",
    "        emb_pos = self.POS.repeat(N,1,1)\n",
    "        \n",
    "        final_input = emb+emb_pos\n",
    "        \n",
    "        output_after_attn = self.transformer_encoder(final_input)\n",
    "        final_output = self.mlp_head(output_after_attn[:,0,:])\n",
    "        \n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set,batch_size=batch_size,shuffle=True,num_workers=8)\n",
    "test_loader = DataLoader(test_set,batch_size=batch_size,shuffle=True,num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "model = ViT()\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "train_test_kit = train_test(model = model , train_loader = train_loader, test_loader = test_loader ,project_name=\"CV-assignment-2\",run_name=\"VIT\",lr = 0.01,optimizer=\"Adam-vanilla\",iswandb=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrohan-victorious108\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/rkada/wandb/run-20240308_155831-uags4f2y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/uags4f2y' target=\"_blank\">VIT</a></strong> to <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/uags4f2y' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/uags4f2y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - train_loss : 0.7834948495030403 and train_accuracy : 0.9026666879653931\n",
      "Evaluation : test_loss : 0.33476534187793733 and test_accuracy : 0.9001999497413635\n",
      "Epoch 2 - train_loss : 0.3054900505890449 and train_accuracy : 0.9240500330924988\n",
      "Evaluation : test_loss : 0.2586559742689133 and test_accuracy : 0.9243999719619751\n",
      "Epoch 3 - train_loss : 0.24315277350445588 and train_accuracy : 0.9266499876976013\n",
      "Evaluation : test_loss : 0.24625566676259042 and test_accuracy : 0.9277999997138977\n",
      "Epoch 4 - train_loss : 0.2144388347864151 and train_accuracy : 0.938800036907196\n",
      "Evaluation : test_loss : 0.20212580636143684 and test_accuracy : 0.9388999938964844\n",
      "Epoch 5 - train_loss : 0.19699109022816022 and train_accuracy : 0.948116660118103\n",
      "Evaluation : test_loss : 0.18753774613142013 and test_accuracy : 0.9458999633789062\n",
      "Epoch 6 - train_loss : 0.18877268619835377 and train_accuracy : 0.9454833269119263\n",
      "Evaluation : test_loss : 0.19167326092720033 and test_accuracy : 0.9409999847412109\n",
      "Epoch 7 - train_loss : 0.18128387915591399 and train_accuracy : 0.9493499994277954\n",
      "Evaluation : test_loss : 0.17535106539726258 and test_accuracy : 0.9491999745368958\n",
      "Epoch 8 - train_loss : 0.17377514050652584 and train_accuracy : 0.9491333365440369\n",
      "Evaluation : test_loss : 0.18413587138056756 and test_accuracy : 0.9448999762535095\n",
      "Epoch 9 - train_loss : 0.16792822424322368 and train_accuracy : 0.9545833468437195\n",
      "Evaluation : test_loss : 0.16536499187350273 and test_accuracy : 0.9494999647140503\n",
      "Epoch 10 - train_loss : 0.1657425575579206 and train_accuracy : 0.9517833590507507\n",
      "Evaluation : test_loss : 0.17624083012342454 and test_accuracy : 0.9461999535560608\n",
      "Epoch 11 - train_loss : 0.16709782605369886 and train_accuracy : 0.9518666863441467\n",
      "Evaluation : test_loss : 0.1805246237665415 and test_accuracy : 0.948699951171875\n",
      "Epoch 12 - train_loss : 0.16280803351352613 and train_accuracy : 0.9544166922569275\n",
      "Evaluation : test_loss : 0.17679970972239972 and test_accuracy : 0.9472000002861023\n",
      "Epoch 13 - train_loss : 0.15972143268833558 and train_accuracy : 0.9526333212852478\n",
      "Evaluation : test_loss : 0.17595454528927804 and test_accuracy : 0.946899950504303\n",
      "Epoch 14 - train_loss : 0.17291203780720632 and train_accuracy : 0.9557499885559082\n",
      "Evaluation : test_loss : 0.16523659341037272 and test_accuracy : 0.9515999555587769\n",
      "Epoch 15 - train_loss : 0.16460001915693284 and train_accuracy : 0.9531833529472351\n",
      "Evaluation : test_loss : 0.17476473264396192 and test_accuracy : 0.949999988079071\n",
      "Epoch 16 - train_loss : 0.16028363841275375 and train_accuracy : 0.9542333483695984\n",
      "Evaluation : test_loss : 0.1693979199975729 and test_accuracy : 0.949999988079071\n",
      "Epoch 17 - train_loss : 0.15864736133565505 and train_accuracy : 0.9519333243370056\n",
      "Evaluation : test_loss : 0.1791766956448555 and test_accuracy : 0.9465999603271484\n",
      "Epoch 18 - train_loss : 0.15532754516849914 and train_accuracy : 0.9534333348274231\n",
      "Evaluation : test_loss : 0.17355203218758106 and test_accuracy : 0.9497999548912048\n",
      "Epoch 19 - train_loss : 0.15987600684165953 and train_accuracy : 0.95128333568573\n",
      "Evaluation : test_loss : 0.17541005536913873 and test_accuracy : 0.9480999708175659\n",
      "Epoch 20 - train_loss : 0.15836071309943994 and train_accuracy : 0.9565333724021912\n",
      "Evaluation : test_loss : 0.15946815945208073 and test_accuracy : 0.95169997215271\n",
      "Epoch 21 - train_loss : 0.16973186725129683 and train_accuracy : 0.9539833664894104\n",
      "Evaluation : test_loss : 0.1614753257483244 and test_accuracy : 0.9524999856948853\n",
      "Epoch 22 - train_loss : 0.18012840176622072 and train_accuracy : 0.9459166526794434\n",
      "Evaluation : test_loss : 0.19442548081278802 and test_accuracy : 0.9424999952316284\n",
      "Epoch 00022: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 23 - train_loss : 0.13538629841059446 and train_accuracy : 0.9629166722297668\n",
      "Evaluation : test_loss : 0.13331852070987224 and test_accuracy : 0.9614999890327454\n",
      "Epoch 24 - train_loss : 0.11911296664426724 and train_accuracy : 0.9650833606719971\n",
      "Evaluation : test_loss : 0.12715357281267642 and test_accuracy : 0.9628999829292297\n",
      "Epoch 25 - train_loss : 0.11279625815028946 and train_accuracy : 0.9664000272750854\n",
      "Evaluation : test_loss : 0.13269212022423743 and test_accuracy : 0.9617999792098999\n",
      "Epoch 26 - train_loss : 0.10974187438065806 and train_accuracy : 0.9677833318710327\n",
      "Evaluation : test_loss : 0.12071826085448265 and test_accuracy : 0.9641000032424927\n",
      "Epoch 27 - train_loss : 0.10813548729444543 and train_accuracy : 0.9681167006492615\n",
      "Evaluation : test_loss : 0.12648240104317665 and test_accuracy : 0.9619999527931213\n",
      "Epoch 28 - train_loss : 0.10626607590044539 and train_accuracy : 0.9693166613578796\n",
      "Evaluation : test_loss : 0.1234066229313612 and test_accuracy : 0.9629999995231628\n",
      "Epoch 29 - train_loss : 0.10356200831010938 and train_accuracy : 0.9691500067710876\n",
      "Evaluation : test_loss : 0.11932982802391053 and test_accuracy : 0.9650999903678894\n",
      "Epoch 30 - train_loss : 0.10093222884461284 and train_accuracy : 0.9696500301361084\n",
      "Evaluation : test_loss : 0.11938488595187664 and test_accuracy : 0.9644999504089355\n",
      "Epoch 31 - train_loss : 0.09908783119171857 and train_accuracy : 0.9702500104904175\n",
      "Evaluation : test_loss : 0.12089881524443627 and test_accuracy : 0.9641000032424927\n",
      "Epoch 32 - train_loss : 0.09974220631023248 and train_accuracy : 0.9711166620254517\n",
      "Evaluation : test_loss : 0.1169588703662157 and test_accuracy : 0.9649999737739563\n",
      "Epoch 33 - train_loss : 0.09839091030880809 and train_accuracy : 0.9717333316802979\n",
      "Evaluation : test_loss : 0.12030472941696643 and test_accuracy : 0.9624999761581421\n",
      "Epoch 34 - train_loss : 0.09668422353764375 and train_accuracy : 0.9706833362579346\n",
      "Evaluation : test_loss : 0.11725370474159717 and test_accuracy : 0.9667999744415283\n",
      "Epoch 35 - train_loss : 0.09591302915165821 and train_accuracy : 0.9717167019844055\n",
      "Evaluation : test_loss : 0.1161990188062191 and test_accuracy : 0.9667999744415283\n",
      "Epoch 36 - train_loss : 0.09274684811631838 and train_accuracy : 0.972000002861023\n",
      "Evaluation : test_loss : 0.11824510879814625 and test_accuracy : 0.965999960899353\n",
      "Epoch 37 - train_loss : 0.09166432575633128 and train_accuracy : 0.9717833399772644\n",
      "Evaluation : test_loss : 0.11870717220008373 and test_accuracy : 0.9657999873161316\n",
      "Epoch 38 - train_loss : 0.09285787735134363 and train_accuracy : 0.9728833436965942\n",
      "Evaluation : test_loss : 0.11600120142102241 and test_accuracy : 0.967199981212616\n",
      "Epoch 39 - train_loss : 0.09074406021585067 and train_accuracy : 0.9726666808128357\n",
      "Evaluation : test_loss : 0.12181533351540566 and test_accuracy : 0.965499997138977\n",
      "Epoch 40 - train_loss : 0.09094311920925975 and train_accuracy : 0.9730166792869568\n",
      "Evaluation : test_loss : 0.11954967118799686 and test_accuracy : 0.9637999534606934\n",
      "Epoch 41 - train_loss : 0.08976912386715412 and train_accuracy : 0.9733666777610779\n",
      "Evaluation : test_loss : 0.11659393794834613 and test_accuracy : 0.9668999910354614\n",
      "Epoch 42 - train_loss : 0.08718073215956489 and train_accuracy : 0.9733666777610779\n",
      "Evaluation : test_loss : 0.11520195677876473 and test_accuracy : 0.9668999910354614\n",
      "Epoch 43 - train_loss : 0.08854608082522948 and train_accuracy : 0.9726999998092651\n",
      "Evaluation : test_loss : 0.11109643019735813 and test_accuracy : 0.9672999978065491\n",
      "Epoch 44 - train_loss : 0.09052384744087855 and train_accuracy : 0.9727666974067688\n",
      "Evaluation : test_loss : 0.12379671819508076 and test_accuracy : 0.9632999897003174\n",
      "Epoch 45 - train_loss : 0.0884367039737602 and train_accuracy : 0.9742333292961121\n",
      "Evaluation : test_loss : 0.11230732016265392 and test_accuracy : 0.965999960899353\n",
      "Epoch 46 - train_loss : 0.08884723788748185 and train_accuracy : 0.9730833172798157\n",
      "Evaluation : test_loss : 0.11587676182389259 and test_accuracy : 0.9664999842643738\n",
      "Epoch 00046: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 47 - train_loss : 0.08201144843672713 and train_accuracy : 0.9743333458900452\n",
      "Evaluation : test_loss : 0.12012294009327888 and test_accuracy : 0.9648999571800232\n",
      "Epoch 48 - train_loss : 0.08044661208987236 and train_accuracy : 0.9752166867256165\n",
      "Evaluation : test_loss : 0.11543233804404736 and test_accuracy : 0.967199981212616\n",
      "Epoch 49 - train_loss : 0.08093383548160395 and train_accuracy : 0.9753167033195496\n",
      "Evaluation : test_loss : 0.11036827228963375 and test_accuracy : 0.9686999917030334\n",
      "Epoch 50 - train_loss : 0.0811502169041584 and train_accuracy : 0.9752833247184753\n",
      "Evaluation : test_loss : 0.11459662094712257 and test_accuracy : 0.9662999510765076\n",
      "Epoch 51 - train_loss : 0.07958036760489146 and train_accuracy : 0.9757833480834961\n",
      "Evaluation : test_loss : 0.11440774723887444 and test_accuracy : 0.965399980545044\n",
      "Epoch 52 - train_loss : 0.08009553393349052 and train_accuracy : 0.9758666753768921\n",
      "Evaluation : test_loss : 0.1218734212219715 and test_accuracy : 0.9650999903678894\n",
      "Epoch 53 - train_loss : 0.07902777393658957 and train_accuracy : 0.9750833511352539\n",
      "Evaluation : test_loss : 0.1109328044578433 and test_accuracy : 0.9677000045776367\n",
      "Epoch 54 - train_loss : 0.07959996992722154 and train_accuracy : 0.975849986076355\n",
      "Evaluation : test_loss : 0.12207391262054443 and test_accuracy : 0.967799961566925\n",
      "Epoch 55 - train_loss : 0.08136869578932722 and train_accuracy : 0.9758999943733215\n",
      "Evaluation : test_loss : 0.11876082140952349 and test_accuracy : 0.9690999984741211\n",
      "Epoch 56 - train_loss : 0.07975758640095591 and train_accuracy : 0.9759333729743958\n",
      "Evaluation : test_loss : 0.11169432513415814 and test_accuracy : 0.9695999622344971\n",
      "Epoch 57 - train_loss : 0.07965584316601355 and train_accuracy : 0.975766658782959\n",
      "Evaluation : test_loss : 0.11071960460394621 and test_accuracy : 0.9666999578475952\n",
      "Epoch 58 - train_loss : 0.07754258625209332 and train_accuracy : 0.9747999906539917\n",
      "Evaluation : test_loss : 0.11025692932307721 and test_accuracy : 0.9677000045776367\n",
      "Epoch 59 - train_loss : 0.07994645281384388 and train_accuracy : 0.9763833284378052\n",
      "Evaluation : test_loss : 0.11249614991247654 and test_accuracy : 0.9681999683380127\n",
      "Epoch 60 - train_loss : 0.07800549461195866 and train_accuracy : 0.9753167033195496\n",
      "Evaluation : test_loss : 0.11944818608462811 and test_accuracy : 0.9661999940872192\n",
      "Epoch 61 - train_loss : 0.077263783927386 and train_accuracy : 0.9764167070388794\n",
      "Evaluation : test_loss : 0.10818695537745952 and test_accuracy : 0.9660999774932861\n",
      "Epoch 62 - train_loss : 0.07679532608017325 and train_accuracy : 0.9759833216667175\n",
      "Evaluation : test_loss : 0.11480940654873847 and test_accuracy : 0.9660999774932861\n",
      "Epoch 63 - train_loss : 0.0766084983634452 and train_accuracy : 0.9773333668708801\n",
      "Evaluation : test_loss : 0.11590641420334577 and test_accuracy : 0.9662999510765076\n",
      "Epoch 64 - train_loss : 0.07879094178788364 and train_accuracy : 0.9764167070388794\n",
      "Evaluation : test_loss : 0.10634417943656445 and test_accuracy : 0.9692999720573425\n",
      "Epoch 65 - train_loss : 0.07839950403819482 and train_accuracy : 0.9768166542053223\n",
      "Evaluation : test_loss : 0.11275058351457119 and test_accuracy : 0.9680999517440796\n",
      "Epoch 66 - train_loss : 0.0788011157574753 and train_accuracy : 0.977316677570343\n",
      "Evaluation : test_loss : 0.10492333583533764 and test_accuracy : 0.9685999751091003\n",
      "Epoch 67 - train_loss : 0.07412666504581769 and train_accuracy : 0.9761333465576172\n",
      "Evaluation : test_loss : 0.11788854710757732 and test_accuracy : 0.9666999578475952\n",
      "Epoch 68 - train_loss : 0.07640786205107968 and train_accuracy : 0.9765000343322754\n",
      "Evaluation : test_loss : 0.11533807665109634 and test_accuracy : 0.9670999646186829\n",
      "Epoch 69 - train_loss : 0.07978410767391324 and train_accuracy : 0.9767333269119263\n",
      "Evaluation : test_loss : 0.11080248877406121 and test_accuracy : 0.9681999683380127\n",
      "Epoch 70 - train_loss : 0.07615021116410693 and train_accuracy : 0.9758333563804626\n",
      "Evaluation : test_loss : 0.10827516689896584 and test_accuracy : 0.9673999547958374\n",
      "Epoch 71 - train_loss : 0.07668909806137283 and train_accuracy : 0.9764167070388794\n",
      "Evaluation : test_loss : 0.1128706892952323 and test_accuracy : 0.9678999781608582\n",
      "Epoch 72 - train_loss : 0.07876888262107969 and train_accuracy : 0.9763666987419128\n",
      "Evaluation : test_loss : 0.11258448101580143 and test_accuracy : 0.9673999547958374\n",
      "Epoch 73 - train_loss : 0.07436933073525627 and train_accuracy : 0.9758666753768921\n",
      "Evaluation : test_loss : 0.10566322915256024 and test_accuracy : 0.9695999622344971\n",
      "Epoch 74 - train_loss : 0.07683926215395331 and train_accuracy : 0.9770833253860474\n",
      "Evaluation : test_loss : 0.11212309822440147 and test_accuracy : 0.9667999744415283\n",
      "Epoch 75 - train_loss : 0.07579183384465675 and train_accuracy : 0.9763166904449463\n",
      "Evaluation : test_loss : 0.11458260640501976 and test_accuracy : 0.965499997138977\n",
      "Epoch 76 - train_loss : 0.074822765449062 and train_accuracy : 0.9771833419799805\n",
      "Evaluation : test_loss : 0.10522376690059901 and test_accuracy : 0.9681999683380127\n",
      "Epoch 77 - train_loss : 0.07557140318676829 and train_accuracy : 0.9753167033195496\n",
      "Evaluation : test_loss : 0.11031857393682003 and test_accuracy : 0.9672999978065491\n",
      "Epoch 78 - train_loss : 0.07756166753048697 and train_accuracy : 0.9769499897956848\n",
      "Evaluation : test_loss : 0.11379718035459518 and test_accuracy : 0.9680999517440796\n",
      "Epoch 79 - train_loss : 0.077504032664001 and train_accuracy : 0.9767000079154968\n",
      "Evaluation : test_loss : 0.11437506079673768 and test_accuracy : 0.9661999940872192\n",
      "Epoch 80 - train_loss : 0.07658768643935522 and train_accuracy : 0.9768666625022888\n",
      "Evaluation : test_loss : 0.10995123349130154 and test_accuracy : 0.9691999554634094\n",
      "Epoch 81 - train_loss : 0.07622791516284148 and train_accuracy : 0.9763833284378052\n",
      "Evaluation : test_loss : 0.11015544161200523 and test_accuracy : 0.9681999683380127\n",
      "Epoch 82 - train_loss : 0.07581150314460199 and train_accuracy : 0.9772500395774841\n",
      "Evaluation : test_loss : 0.11189561299979686 and test_accuracy : 0.9684000015258789\n",
      "Epoch 83 - train_loss : 0.07679255353286862 and train_accuracy : 0.9761000275611877\n",
      "Evaluation : test_loss : 0.11316716354340314 and test_accuracy : 0.9663999676704407\n",
      "Epoch 84 - train_loss : 0.07492933285733064 and train_accuracy : 0.9771666526794434\n",
      "Evaluation : test_loss : 0.10872997455298901 and test_accuracy : 0.968999981880188\n",
      "Epoch 85 - train_loss : 0.07636180678382516 and train_accuracy : 0.975683331489563\n",
      "Evaluation : test_loss : 0.11242114529013633 and test_accuracy : 0.9664999842643738\n",
      "Epoch 86 - train_loss : 0.07513096267357469 and train_accuracy : 0.9763500094413757\n",
      "Evaluation : test_loss : 0.11186721399426461 and test_accuracy : 0.9680999517440796\n",
      "Epoch 87 - train_loss : 0.07518227960293491 and train_accuracy : 0.9765666723251343\n",
      "Evaluation : test_loss : 0.11047282926738262 and test_accuracy : 0.9690999984741211\n",
      "Epoch 88 - train_loss : 0.07569735680396358 and train_accuracy : 0.9767667055130005\n",
      "Evaluation : test_loss : 0.11246451660990715 and test_accuracy : 0.967199981212616\n",
      "Epoch 89 - train_loss : 0.07633595755323767 and train_accuracy : 0.9779833555221558\n",
      "Evaluation : test_loss : 0.10887362416833639 and test_accuracy : 0.9691999554634094\n",
      "Epoch 90 - train_loss : 0.07460046994189422 and train_accuracy : 0.9764167070388794\n",
      "Evaluation : test_loss : 0.10713527332991361 and test_accuracy : 0.9686999917030334\n",
      "Epoch 91 - train_loss : 0.07643238514040908 and train_accuracy : 0.9768333435058594\n",
      "Evaluation : test_loss : 0.11647803448140621 and test_accuracy : 0.9649999737739563\n",
      "Epoch 92 - train_loss : 0.07312444361547629 and train_accuracy : 0.9768000245094299\n",
      "Evaluation : test_loss : 0.11475648060441017 and test_accuracy : 0.9679999947547913\n",
      "Epoch 93 - train_loss : 0.07526143742725253 and train_accuracy : 0.9761166572570801\n",
      "Evaluation : test_loss : 0.1109247263520956 and test_accuracy : 0.9695000052452087\n",
      "Epoch 94 - train_loss : 0.07377921181420485 and train_accuracy : 0.9765999913215637\n",
      "Evaluation : test_loss : 0.1148650199174881 and test_accuracy : 0.9684999585151672\n",
      "Epoch 95 - train_loss : 0.07576846747348706 and train_accuracy : 0.9772666692733765\n",
      "Evaluation : test_loss : 0.11469027884304524 and test_accuracy : 0.9663999676704407\n",
      "Epoch 96 - train_loss : 0.07389001852522294 and train_accuracy : 0.9767166972160339\n",
      "Evaluation : test_loss : 0.10981471799314022 and test_accuracy : 0.9695999622344971\n",
      "Epoch 97 - train_loss : 0.07338459587966402 and train_accuracy : 0.9769999980926514\n",
      "Evaluation : test_loss : 0.11663685999810695 and test_accuracy : 0.9664999842643738\n",
      "Epoch 98 - train_loss : 0.07325365897268057 and train_accuracy : 0.9772666692733765\n",
      "Evaluation : test_loss : 0.1145711973309517 and test_accuracy : 0.9672999978065491\n",
      "Epoch 99 - train_loss : 0.07345559300544362 and train_accuracy : 0.9775000214576721\n",
      "Evaluation : test_loss : 0.11375092472881079 and test_accuracy : 0.9684000015258789\n",
      "Epoch 100 - train_loss : 0.0748528454452753 and train_accuracy : 0.9767000079154968\n",
      "Evaluation : test_loss : 0.1166088916361332 and test_accuracy : 0.9661999940872192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁▄▅▆▆▆▆▆▆▇▇▇▇████▇██████████████████████</td></tr><tr><td>test_loss</td><td>█▅▄▃▃▃▃▃▃▂▁▂▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▃▅▅▆▆▆▆▆▇▇▇▇▇▇█████████████████████████</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.9662</td></tr><tr><td>test_loss</td><td>0.11661</td></tr><tr><td>train_accuracy</td><td>0.9767</td></tr><tr><td>train_loss</td><td>0.07485</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">VIT</strong> at: <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/uags4f2y' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/uags4f2y</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240308_155831-uags4f2y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_test_kit.train(num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample MNIST for 6000 images in train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = sample_mnist(6000)\n",
    "train_set_ = DatasetSampled(X,y,transform=ToTensor())\n",
    "train_loader = DataLoader(train_set_,batch_size=500,shuffle=True)\n",
    "test_loader = DataLoader(test_set,batch_size=500,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "model = ViT()\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "train_test_kit = train_test(model = model , train_loader = train_loader, test_loader = test_loader ,project_name=\"CV-assignment-2\",run_name=\"VIT_6k\",lr = 0.01,optimizer=\"Adam-vanilla\",iswandb=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrohan-victorious108\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home2/rkada/wandb/run-20240308_184449-988bsubk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/988bsubk' target=\"_blank\">VIT_6k</a></strong> to <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/988bsubk' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/988bsubk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - train_loss : 2.2128734389940896 and train_accuracy : 0.3101666569709778\n",
      "Evaluation : test_loss : 1.9505979776382447 and test_accuracy : 0.32029998302459717\n",
      "Epoch 2 - train_loss : 1.6174294749895732 and train_accuracy : 0.6231666803359985\n",
      "Evaluation : test_loss : 1.1875273168087006 and test_accuracy : 0.6345999836921692\n",
      "Epoch 3 - train_loss : 0.9616126269102097 and train_accuracy : 0.7459999918937683\n",
      "Evaluation : test_loss : 0.7434821933507919 and test_accuracy : 0.7461000084877014\n",
      "Epoch 4 - train_loss : 0.6841866075992584 and train_accuracy : 0.7914999723434448\n",
      "Evaluation : test_loss : 0.6229469776153564 and test_accuracy : 0.7925999760627747\n",
      "Epoch 5 - train_loss : 0.543172225356102 and train_accuracy : 0.8343333005905151\n",
      "Evaluation : test_loss : 0.5288290202617645 and test_accuracy : 0.836899995803833\n",
      "Epoch 6 - train_loss : 0.4688128779331843 and train_accuracy : 0.859333336353302\n",
      "Evaluation : test_loss : 0.48680906891822817 and test_accuracy : 0.8507999777793884\n",
      "Epoch 7 - train_loss : 0.41899847984313965 and train_accuracy : 0.8740000128746033\n",
      "Evaluation : test_loss : 0.4181159511208534 and test_accuracy : 0.8726999759674072\n",
      "Epoch 8 - train_loss : 0.3932465463876724 and train_accuracy : 0.8891666531562805\n",
      "Evaluation : test_loss : 0.3964281901717186 and test_accuracy : 0.8789999485015869\n",
      "Epoch 9 - train_loss : 0.35092482964197796 and train_accuracy : 0.890666663646698\n",
      "Evaluation : test_loss : 0.38008552938699725 and test_accuracy : 0.8860999941825867\n",
      "Epoch 10 - train_loss : 0.3213397165139516 and train_accuracy : 0.906166672706604\n",
      "Evaluation : test_loss : 0.35803290605545046 and test_accuracy : 0.8902999758720398\n",
      "Epoch 11 - train_loss : 0.31423861533403397 and train_accuracy : 0.9113333225250244\n",
      "Evaluation : test_loss : 0.36021805703639986 and test_accuracy : 0.8937000036239624\n",
      "Epoch 12 - train_loss : 0.28872472792863846 and train_accuracy : 0.9173333048820496\n",
      "Evaluation : test_loss : 0.3286559030413628 and test_accuracy : 0.9030999541282654\n",
      "Epoch 13 - train_loss : 0.2702745919426282 and train_accuracy : 0.9185000061988831\n",
      "Evaluation : test_loss : 0.3409852087497711 and test_accuracy : 0.8950999975204468\n",
      "Epoch 14 - train_loss : 0.25619226942459744 and train_accuracy : 0.9271666407585144\n",
      "Evaluation : test_loss : 0.3334703162312508 and test_accuracy : 0.8987999558448792\n",
      "Epoch 15 - train_loss : 0.2467478265364965 and train_accuracy : 0.9248332977294922\n",
      "Evaluation : test_loss : 0.3416431449353695 and test_accuracy : 0.9012999534606934\n",
      "Epoch 16 - train_loss : 0.23531406993667284 and train_accuracy : 0.9354999661445618\n",
      "Evaluation : test_loss : 0.31929637491703033 and test_accuracy : 0.9021999835968018\n",
      "Epoch 17 - train_loss : 0.22815376023451486 and train_accuracy : 0.9331666827201843\n",
      "Evaluation : test_loss : 0.2973130591213703 and test_accuracy : 0.9108999967575073\n",
      "Epoch 18 - train_loss : 0.20996556927760443 and train_accuracy : 0.9391666650772095\n",
      "Evaluation : test_loss : 0.2983777217566967 and test_accuracy : 0.9107999801635742\n",
      "Epoch 19 - train_loss : 0.2099833625058333 and train_accuracy : 0.9338333010673523\n",
      "Evaluation : test_loss : 0.32308728247880936 and test_accuracy : 0.9073999524116516\n",
      "Epoch 20 - train_loss : 0.19778483981887499 and train_accuracy : 0.9419999718666077\n",
      "Evaluation : test_loss : 0.29560261145234107 and test_accuracy : 0.9125999808311462\n",
      "Epoch 21 - train_loss : 0.18495099494854608 and train_accuracy : 0.9418333172798157\n",
      "Evaluation : test_loss : 0.2964527979493141 and test_accuracy : 0.9136999845504761\n",
      "Epoch 22 - train_loss : 0.17796297123034796 and train_accuracy : 0.9353333115577698\n",
      "Evaluation : test_loss : 0.32885552495718 and test_accuracy : 0.9057999849319458\n",
      "Epoch 23 - train_loss : 0.18068150679270426 and train_accuracy : 0.9361666440963745\n",
      "Evaluation : test_loss : 0.3176481768488884 and test_accuracy : 0.9068999886512756\n",
      "Epoch 24 - train_loss : 0.19388063624501228 and train_accuracy : 0.9350000023841858\n",
      "Evaluation : test_loss : 0.3141229622066021 and test_accuracy : 0.9073999524116516\n",
      "Epoch 25 - train_loss : 0.18537464986244837 and train_accuracy : 0.950166642665863\n",
      "Evaluation : test_loss : 0.3007354371249676 and test_accuracy : 0.9110999703407288\n",
      "Epoch 26 - train_loss : 0.17057403673728308 and train_accuracy : 0.9461666345596313\n",
      "Evaluation : test_loss : 0.29983518943190574 and test_accuracy : 0.9126999974250793\n",
      "Epoch 27 - train_loss : 0.1681016031652689 and train_accuracy : 0.9493333101272583\n",
      "Evaluation : test_loss : 0.2893682271242142 and test_accuracy : 0.9203999638557434\n",
      "Epoch 28 - train_loss : 0.1636787305275599 and train_accuracy : 0.9543333053588867\n",
      "Evaluation : test_loss : 0.2944002941250801 and test_accuracy : 0.9185000061988831\n",
      "Epoch 29 - train_loss : 0.16193542256951332 and train_accuracy : 0.9476666450500488\n",
      "Evaluation : test_loss : 0.27826624885201456 and test_accuracy : 0.9230999946594238\n",
      "Epoch 30 - train_loss : 0.16333157444993654 and train_accuracy : 0.9468333125114441\n",
      "Evaluation : test_loss : 0.302033556252718 and test_accuracy : 0.9160999655723572\n",
      "Epoch 31 - train_loss : 0.1467526157697042 and train_accuracy : 0.9571666717529297\n",
      "Evaluation : test_loss : 0.27966060414910315 and test_accuracy : 0.9211999773979187\n",
      "Epoch 32 - train_loss : 0.15025484437743822 and train_accuracy : 0.9598333239555359\n",
      "Evaluation : test_loss : 0.2783466711640358 and test_accuracy : 0.9217000007629395\n",
      "Epoch 33 - train_loss : 0.1362097313006719 and train_accuracy : 0.9506666660308838\n",
      "Evaluation : test_loss : 0.3172731019556522 and test_accuracy : 0.9170999526977539\n",
      "Epoch 34 - train_loss : 0.1382829900830984 and train_accuracy : 0.9476666450500488\n",
      "Evaluation : test_loss : 0.3151494741439819 and test_accuracy : 0.9134999513626099\n",
      "Epoch 35 - train_loss : 0.15864529212315878 and train_accuracy : 0.956333339214325\n",
      "Evaluation : test_loss : 0.28497755974531175 and test_accuracy : 0.9218999743461609\n",
      "Epoch 36 - train_loss : 0.13940335251390934 and train_accuracy : 0.9596666693687439\n",
      "Evaluation : test_loss : 0.2883961573243141 and test_accuracy : 0.9186999797821045\n",
      "Epoch 37 - train_loss : 0.13020563932756582 and train_accuracy : 0.9616666436195374\n",
      "Evaluation : test_loss : 0.3006967231631279 and test_accuracy : 0.9210999608039856\n",
      "Epoch 38 - train_loss : 0.1229350318511327 and train_accuracy : 0.9628333449363708\n",
      "Evaluation : test_loss : 0.2881948322057724 and test_accuracy : 0.920199990272522\n",
      "Epoch 39 - train_loss : 0.13230145101745924 and train_accuracy : 0.9606666564941406\n",
      "Evaluation : test_loss : 0.2951209619641304 and test_accuracy : 0.9217999577522278\n",
      "Epoch 40 - train_loss : 0.12852228494981924 and train_accuracy : 0.9601666331291199\n",
      "Evaluation : test_loss : 0.3056079939007759 and test_accuracy : 0.9150999784469604\n",
      "Epoch 41 - train_loss : 0.11840732333560784 and train_accuracy : 0.9638333320617676\n",
      "Evaluation : test_loss : 0.2851311482489109 and test_accuracy : 0.9246000051498413\n",
      "Epoch 42 - train_loss : 0.12230007226268451 and train_accuracy : 0.9605000019073486\n",
      "Evaluation : test_loss : 0.3054251365363598 and test_accuracy : 0.9195999503135681\n",
      "Epoch 43 - train_loss : 0.11580307595431805 and train_accuracy : 0.9629999995231628\n",
      "Evaluation : test_loss : 0.29902990609407426 and test_accuracy : 0.9199000000953674\n",
      "Epoch 44 - train_loss : 0.12116006451348464 and train_accuracy : 0.9695000052452087\n",
      "Evaluation : test_loss : 0.2803840316832066 and test_accuracy : 0.9264000058174133\n",
      "Epoch 45 - train_loss : 0.11711158603429794 and train_accuracy : 0.9573333263397217\n",
      "Evaluation : test_loss : 0.3042929045855999 and test_accuracy : 0.9194999933242798\n",
      "Epoch 46 - train_loss : 0.12574626132845879 and train_accuracy : 0.9578333497047424\n",
      "Evaluation : test_loss : 0.3125355549156666 and test_accuracy : 0.914199948310852\n",
      "Epoch 47 - train_loss : 0.12235965890189011 and train_accuracy : 0.9603333473205566\n",
      "Evaluation : test_loss : 0.31350132152438165 and test_accuracy : 0.9172999858856201\n",
      "Epoch 00047: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch 48 - train_loss : 0.10845363264282544 and train_accuracy : 0.9731666445732117\n",
      "Evaluation : test_loss : 0.26866156831383703 and test_accuracy : 0.9300999641418457\n",
      "Epoch 49 - train_loss : 0.08073645892242591 and train_accuracy : 0.9766666293144226\n",
      "Evaluation : test_loss : 0.26228484883904457 and test_accuracy : 0.9299999475479126\n",
      "Epoch 50 - train_loss : 0.07235249814887841 and train_accuracy : 0.9783332943916321\n",
      "Evaluation : test_loss : 0.25719950571656225 and test_accuracy : 0.9321999549865723\n",
      "Epoch 51 - train_loss : 0.0678681197265784 and train_accuracy : 0.9804999828338623\n",
      "Evaluation : test_loss : 0.26202816516160965 and test_accuracy : 0.9315999746322632\n",
      "Epoch 52 - train_loss : 0.06487278081476688 and train_accuracy : 0.981499969959259\n",
      "Evaluation : test_loss : 0.251895248144865 and test_accuracy : 0.9333999752998352\n",
      "Epoch 53 - train_loss : 0.056345396054287754 and train_accuracy : 0.9808333516120911\n",
      "Evaluation : test_loss : 0.24996570199728013 and test_accuracy : 0.9314999580383301\n",
      "Epoch 54 - train_loss : 0.06507468534012635 and train_accuracy : 0.9835000038146973\n",
      "Evaluation : test_loss : 0.252577880769968 and test_accuracy : 0.932699978351593\n",
      "Epoch 55 - train_loss : 0.06034390659381946 and train_accuracy : 0.9839999675750732\n",
      "Evaluation : test_loss : 0.2392535038292408 and test_accuracy : 0.9383999705314636\n",
      "Epoch 56 - train_loss : 0.05646300253768762 and train_accuracy : 0.984666645526886\n",
      "Evaluation : test_loss : 0.25036168918013574 and test_accuracy : 0.9343000054359436\n",
      "Epoch 57 - train_loss : 0.05360291774074236 and train_accuracy : 0.9835000038146973\n",
      "Evaluation : test_loss : 0.254522030800581 and test_accuracy : 0.9339999556541443\n",
      "Epoch 58 - train_loss : 0.04741542041301727 and train_accuracy : 0.9838333129882812\n",
      "Evaluation : test_loss : 0.25002804324030875 and test_accuracy : 0.9347999691963196\n",
      "Epoch 59 - train_loss : 0.05539786256849766 and train_accuracy : 0.9819999933242798\n",
      "Evaluation : test_loss : 0.2516957715153694 and test_accuracy : 0.9334999918937683\n",
      "Epoch 60 - train_loss : 0.05175567325204611 and train_accuracy : 0.9851666688919067\n",
      "Evaluation : test_loss : 0.2461602956056595 and test_accuracy : 0.9371999502182007\n",
      "Epoch 61 - train_loss : 0.04922205132121841 and train_accuracy : 0.9835000038146973\n",
      "Evaluation : test_loss : 0.2616769582033157 and test_accuracy : 0.9339999556541443\n",
      "Epoch 62 - train_loss : 0.04701386655991276 and train_accuracy : 0.9886666536331177\n",
      "Evaluation : test_loss : 0.25551898777484894 and test_accuracy : 0.9368999600410461\n",
      "Epoch 63 - train_loss : 0.05426128053416809 and train_accuracy : 0.984333336353302\n",
      "Evaluation : test_loss : 0.2600060306489468 and test_accuracy : 0.9335999488830566\n",
      "Epoch 64 - train_loss : 0.04227071922893325 and train_accuracy : 0.9826666712760925\n",
      "Evaluation : test_loss : 0.2530249904841185 and test_accuracy : 0.9351999759674072\n",
      "Epoch 65 - train_loss : 0.04825153620913625 and train_accuracy : 0.9833333492279053\n",
      "Evaluation : test_loss : 0.25046610161662103 and test_accuracy : 0.9362999796867371\n",
      "Epoch 66 - train_loss : 0.04553435742855072 and train_accuracy : 0.9851666688919067\n",
      "Evaluation : test_loss : 0.2550773501396179 and test_accuracy : 0.9339999556541443\n",
      "Epoch 67 - train_loss : 0.04536500216151277 and train_accuracy : 0.9873332977294922\n",
      "Evaluation : test_loss : 0.25270665660500524 and test_accuracy : 0.9362999796867371\n",
      "Epoch 68 - train_loss : 0.04457082770143946 and train_accuracy : 0.987500011920929\n",
      "Evaluation : test_loss : 0.24813302382826805 and test_accuracy : 0.9375999569892883\n",
      "Epoch 00068: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch 69 - train_loss : 0.045757736855496965 and train_accuracy : 0.9869999885559082\n",
      "Evaluation : test_loss : 0.26142963767051697 and test_accuracy : 0.9368999600410461\n",
      "Epoch 70 - train_loss : 0.04450362377489606 and train_accuracy : 0.9863333106040955\n",
      "Evaluation : test_loss : 0.25370035991072654 and test_accuracy : 0.9366999864578247\n",
      "Epoch 71 - train_loss : 0.041836909018456936 and train_accuracy : 0.9873332977294922\n",
      "Evaluation : test_loss : 0.2568561598658562 and test_accuracy : 0.9335999488830566\n",
      "Epoch 72 - train_loss : 0.044039592457314335 and train_accuracy : 0.9863333106040955\n",
      "Evaluation : test_loss : 0.2521884188055992 and test_accuracy : 0.9364999532699585\n",
      "Epoch 73 - train_loss : 0.04733466977874438 and train_accuracy : 0.9886666536331177\n",
      "Evaluation : test_loss : 0.25170821473002436 and test_accuracy : 0.9353999495506287\n",
      "Epoch 74 - train_loss : 0.03814022180934747 and train_accuracy : 0.9878333210945129\n",
      "Evaluation : test_loss : 0.2544731110334396 and test_accuracy : 0.9372999668121338\n",
      "Epoch 75 - train_loss : 0.04279709359010061 and train_accuracy : 0.9868333339691162\n",
      "Evaluation : test_loss : 0.25153028815984724 and test_accuracy : 0.9368000030517578\n",
      "Epoch 76 - train_loss : 0.03903021741037568 and train_accuracy : 0.987666666507721\n",
      "Evaluation : test_loss : 0.2648352399468422 and test_accuracy : 0.9343999624252319\n",
      "Epoch 77 - train_loss : 0.042240249924361706 and train_accuracy : 0.9869999885559082\n",
      "Evaluation : test_loss : 0.24209108129143714 and test_accuracy : 0.9391999840736389\n",
      "Epoch 78 - train_loss : 0.044492024617890515 and train_accuracy : 0.9866666793823242\n",
      "Evaluation : test_loss : 0.2545698069036007 and test_accuracy : 0.9376999735832214\n",
      "Epoch 79 - train_loss : 0.038270897387216486 and train_accuracy : 0.984833300113678\n",
      "Evaluation : test_loss : 0.2521399758756161 and test_accuracy : 0.9396999478340149\n",
      "Epoch 80 - train_loss : 0.04417594041054448 and train_accuracy : 0.9864999651908875\n",
      "Evaluation : test_loss : 0.25736345499753954 and test_accuracy : 0.9350000023841858\n",
      "Epoch 81 - train_loss : 0.04149747220799327 and train_accuracy : 0.9879999756813049\n",
      "Evaluation : test_loss : 0.2685053780674934 and test_accuracy : 0.934499979019165\n",
      "Epoch 82 - train_loss : 0.037180200374374785 and train_accuracy : 0.9889999628067017\n",
      "Evaluation : test_loss : 0.24789498448371888 and test_accuracy : 0.9381999969482422\n",
      "Epoch 83 - train_loss : 0.037638371965537466 and train_accuracy : 0.9871666431427002\n",
      "Evaluation : test_loss : 0.25388204455375674 and test_accuracy : 0.9386000037193298\n",
      "Epoch 84 - train_loss : 0.04190993246932825 and train_accuracy : 0.9863333106040955\n",
      "Evaluation : test_loss : 0.25702076628804205 and test_accuracy : 0.9346999526023865\n",
      "Epoch 85 - train_loss : 0.042402018482486405 and train_accuracy : 0.9884999990463257\n",
      "Evaluation : test_loss : 0.25363967940211296 and test_accuracy : 0.9350999593734741\n",
      "Epoch 86 - train_loss : 0.038293715411176286 and train_accuracy : 0.9871666431427002\n",
      "Evaluation : test_loss : 0.2542239993810654 and test_accuracy : 0.9375\n",
      "Epoch 87 - train_loss : 0.041010342383136354 and train_accuracy : 0.9886666536331177\n",
      "Evaluation : test_loss : 0.25616191402077676 and test_accuracy : 0.9361000061035156\n",
      "Epoch 88 - train_loss : 0.042124403485407434 and train_accuracy : 0.9868333339691162\n",
      "Evaluation : test_loss : 0.24653869196772576 and test_accuracy : 0.9382999539375305\n",
      "Epoch 89 - train_loss : 0.03993575476730863 and train_accuracy : 0.9861666560173035\n",
      "Evaluation : test_loss : 0.2558332037180662 and test_accuracy : 0.9352999925613403\n",
      "Epoch 90 - train_loss : 0.04303148544083039 and train_accuracy : 0.9871666431427002\n",
      "Evaluation : test_loss : 0.2609081417322159 and test_accuracy : 0.9350999593734741\n",
      "Epoch 91 - train_loss : 0.03845898744960626 and train_accuracy : 0.9860000014305115\n",
      "Evaluation : test_loss : 0.25514529794454577 and test_accuracy : 0.9348999857902527\n",
      "Epoch 92 - train_loss : 0.0399017323118945 and train_accuracy : 0.9864999651908875\n",
      "Evaluation : test_loss : 0.2557700753211975 and test_accuracy : 0.9375\n",
      "Epoch 93 - train_loss : 0.037132354297985636 and train_accuracy : 0.9868333339691162\n",
      "Evaluation : test_loss : 0.2440113864839077 and test_accuracy : 0.9394999742507935\n",
      "Epoch 94 - train_loss : 0.04402365147446593 and train_accuracy : 0.9873332977294922\n",
      "Evaluation : test_loss : 0.2528597377240658 and test_accuracy : 0.9386000037193298\n",
      "Epoch 95 - train_loss : 0.040567745454609394 and train_accuracy : 0.9868333339691162\n",
      "Evaluation : test_loss : 0.246366236358881 and test_accuracy : 0.9396999478340149\n",
      "Epoch 96 - train_loss : 0.04573021518687407 and train_accuracy : 0.9873332977294922\n",
      "Evaluation : test_loss : 0.24813610315322876 and test_accuracy : 0.9357999563217163\n",
      "Epoch 97 - train_loss : 0.0392730594612658 and train_accuracy : 0.9864999651908875\n",
      "Evaluation : test_loss : 0.25171938762068746 and test_accuracy : 0.9394999742507935\n",
      "Epoch 98 - train_loss : 0.04106123186647892 and train_accuracy : 0.9881666302680969\n",
      "Evaluation : test_loss : 0.25520038455724714 and test_accuracy : 0.9345999956130981\n",
      "Epoch 99 - train_loss : 0.039547331320742764 and train_accuracy : 0.9891666769981384\n",
      "Evaluation : test_loss : 0.2644822642207146 and test_accuracy : 0.9347999691963196\n",
      "Epoch 100 - train_loss : 0.03953967879836758 and train_accuracy : 0.987500011920929\n",
      "Evaluation : test_loss : 0.2500955544412136 and test_accuracy : 0.9382999539375305\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁▆▇▇▇▇██████████████████████████████████</td></tr><tr><td>test_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▅▇▇▇▇▇▇█▇██████████████████████████████</td></tr><tr><td>train_loss</td><td>█▄▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.9383</td></tr><tr><td>test_loss</td><td>0.2501</td></tr><tr><td>train_accuracy</td><td>0.9875</td></tr><tr><td>train_loss</td><td>0.03954</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">VIT_6k</strong> at: <a href='https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/988bsubk' target=\"_blank\">https://wandb.ai/rohan-victorious108/CV-assignment-2/runs/988bsubk</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240308_184449-988bsubk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_test_kit.train(num_epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Training set size increases, Transformer is able to pay attention to the local context via the self attention mechanism and also since the examples it sees increases the Transformer's ability to capture local features.The classification accuracies with 60K Sized Image Dataset is higher than those obtained with 6K Sized Dataset. The corresponding accuracies obtained are as follows - 96.62% for 60000 images, 93.82% for 6000 images on test set. It is because Transformers are Data Hungry and require large datasets for the well functioning of Self-Attention Mechanism.\n",
    "\n",
    "We observe that corresponding accuracies are higher in case of CNNs because CNNs are computationally efficient and capture the Local Features in a very fast manner compared to Transformers. It is because Self-Attention requires a very huge amount of time compared to Convolutional Operators.\n",
    "\n",
    "The convergence rates for CNN are higher than that of Transformer but over a large run it is generally observed that transformer performs better that CNN model.This is generally because CNN well captures the local features but it also has inductive biases, which helps it to fit on the data and not generalize well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data loaders and datasets\n",
    "2. Creating the ViT class.\n",
    "3. The activation functions were a major challenge, faced difficulties in training without them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
